from datetime import datetime
import os
import re
import math  # æ·»åŠ è¿™è¡Œ
from collections import defaultdict
import json  # æ·»åŠ  json å¯¼å…¥

from matplotlib.dates import relativedelta

from component.cop_relation_rebuild_module import (
    save_file,
    split_countries,
    parse_date,
    rebuild_relations,
    load_companies,
    load_supply_chain_data,
    build_company_to_country,
    )

from component.company_supplyChain import SupplyRelation, Company
from datetime import timedelta
import pandas as pd
from typing import List

# è·¯å¾„é›†åˆ#
path_dic = {'company': r'.\è°ƒç”¨æ–‡ä»¶\ç”¨äºè¡Œä¸šåˆ†ç±»åˆ†æçš„å¯è§†åŒ–è¡¨\å¤„ç†åçš„jsonæ–‡ä»¶\company.json',
            'supply_chain': r'.\è°ƒç”¨æ–‡ä»¶\ç”¨äºè¡Œä¸šåˆ†ç±»åˆ†æçš„å¯è§†åŒ–è¡¨\å¤„ç†åçš„jsonæ–‡ä»¶\supply_relations.json',
            'complete_sc': r'.\è°ƒç”¨æ–‡ä»¶\ç”¨äºè¡Œä¸šåˆ†ç±»åˆ†æçš„å¯è§†åŒ–è¡¨\å¤„ç†åçš„jsonæ–‡ä»¶'
            }

def load_industry_code_mapping(json_path):
    """
    è¯»å–è¡Œä¸šä»£ç JSONæ–‡ä»¶ï¼Œå½¢æˆè¡Œä¸šä»£ç åˆ°æè¿°çš„æ˜ å°„å­—å…¸
    
    å‚æ•°è¯´æ˜ï¼š
    - json_path: industry_code.jsonæ–‡ä»¶çš„è·¯å¾„
    
    è¿”å›å€¼ï¼š
    - industry_mapping: å­—å…¸ï¼Œé”®ä¸ºè¡Œä¸šä»£ç (INDUSTRY_ID)ï¼Œå€¼ä¸ºè¡Œä¸šæè¿°(DESCRIPTION)
    
    ä½¿ç”¨ç¤ºä¾‹ï¼š
    industry_mapping = load_industry_code_mapping(r".\è°ƒç”¨æ–‡ä»¶\ç”¨äºè¡Œä¸šåˆ†ç±»åˆ†æçš„å¯è§†åŒ–è¡¨\industry_code.json")
    print(industry_mapping.get("01", "æœªçŸ¥è¡Œä¸š"))  # è¾“å‡ºï¼šæŒ‡å¯¹å„ç§å†œä½œç‰©çš„ç§æ¤
    """
    try:
        with open(json_path, "r", encoding="utf-8") as f:
            industry_data = json.load(f)
        
        # æ„å»ºè¡Œä¸šä»£ç åˆ°æè¿°çš„æ˜ å°„å­—å…¸
        industry_mapping = {}
        for item in industry_data:
            industry_id = item.get("INDUSTRY_ID", "")
            description = item.get("DESCRIPTION", "")
            industry_mapping[industry_id] = description
        
        print(f"æˆåŠŸåŠ è½½è¡Œä¸šä»£ç æ˜ å°„ï¼Œå…±{len(industry_mapping)}ä¸ªè¡Œä¸šä»£ç ")
        return industry_mapping
        
    except FileNotFoundError:
        print(f"æ–‡ä»¶æœªæ‰¾åˆ°: {json_path}")
        return {}
    except json.JSONDecodeError as e:
        print(f"JSONè§£æé”™è¯¯: {e}")
        return {}
    except Exception as e:
        print(f"åŠ è½½è¡Œä¸šä»£ç æ˜ å°„æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return {}

industry_code_path = r".\è°ƒç”¨æ–‡ä»¶\ç”¨äºè¡Œä¸šåˆ†ç±»åˆ†æçš„å¯è§†åŒ–è¡¨\industry_code.json"
industry_mapping = load_industry_code_mapping(industry_code_path)

def extract_country_mapping():
    """
    ä»å›½å®¶åœ°ç†åæ ‡ä¸­æå–å›½å®¶ç®€ç§°åˆ°å›½å®¶åçš„æ˜ å°„å­—å…¸
    
    è¿”å›å€¼ï¼š
    - country_name_mapping: å­—å…¸ï¼Œé”®ä¸ºå›½å®¶ç®€ç§°ï¼Œå€¼ä¸ºå›½å®¶åç§°
    """
    country_name_mapping = {
        # ä¸»æƒå›½å®¶
        "CN": "ä¸­å›½",
        "CN_2": "ä¸­å›½ä½ç½®2",
        "AE": "é˜¿æ‹‰ä¼¯è”åˆé…‹é•¿å›½",
        "AF": "é˜¿å¯Œæ±—",
        "AL": "é˜¿å°”å·´å°¼äºš",
        "AR": "é˜¿æ ¹å»·",
        "AT": "å¥¥åœ°åˆ©",
        "AU": "æ¾³å¤§åˆ©äºš",
        "AZ": "é˜¿å¡æ‹œç–†",
        "BA": "æ³¢é»‘",
        "BD": "å­ŸåŠ æ‹‰å›½",
        "BE": "æ¯”åˆ©æ—¶",
        "BF": "å¸ƒåŸºçº³æ³•ç´¢",
        "BG": "ä¿åŠ åˆ©äºš",
        "BO": "ç»åˆ©ç»´äºš",
        "BR": "å·´è¥¿",
        "CA": "åŠ æ‹¿å¤§",
        "CD": "åˆšæœæ°‘ä¸»å…±å’Œå›½",
        "CH": "ç‘å£«",
        "CL": "æ™ºåˆ©",
        "CO": "å“¥ä¼¦æ¯”äºš",
        "CU": "å¤å·´",
        "CZ": "æ·å…‹",
        "DE": "å¾·å›½",
        "DK": "ä¸¹éº¦",
        "DZ": "é˜¿å°”åŠåˆ©äºš",
        "EC": "å„ç“œå¤šå°”",
        "EG": "åŸƒåŠ",
        "ES": "è¥¿ç­ç‰™",
        "FI": "èŠ¬å…°",
        "FR": "æ³•å›½",
        "GB": "è‹±å›½",
        "GE": "æ ¼é²å‰äºš",
        "GH": "åŠ çº³",
        "GR": "å¸Œè…Š",
        "GT": "å±åœ°é©¬æ‹‰",
        "HN": "æ´ªéƒ½æ‹‰æ–¯",
        "HR": "å…‹ç½—åœ°äºš",
        "HU": "åŒˆç‰™åˆ©",
        "ID": "å°åº¦å°¼è¥¿äºš",
        "IE": "çˆ±å°”å…°",
        "IL": "ä»¥è‰²åˆ—",
        "IN": "å°åº¦",
        "IQ": "ä¼Šæ‹‰å…‹",
        "IR": "ä¼Šæœ—",
        "IS": "å†°å²›",
        "IT": "æ„å¤§åˆ©",
        "JM": "ç‰™ä¹°åŠ ",
        "JO": "çº¦æ—¦",
        "JP": "æ—¥æœ¬",
        "KE": "è‚¯å°¼äºš",
        "KR": "éŸ©å›½",
        "KW": "ç§‘å¨ç‰¹",
        "KZ": "å“ˆè¨å…‹æ–¯å¦",
        "LB": "é»å·´å«©",
        "LK": "æ–¯é‡Œå…°å¡",
        "MA": "æ‘©æ´›å“¥",
        "MX": "å¢¨è¥¿å“¥",
        "MY": "é©¬æ¥è¥¿äºš",
        "NG": "å°¼æ—¥åˆ©äºš",
        "NL": "è·å…°",
        "NO": "æŒªå¨",
        "NP": "å°¼æ³Šå°”",
        "NZ": "æ–°è¥¿å…°",
        "PE": "ç§˜é²",
        "PH": "è²å¾‹å®¾",
        "PK": "å·´åŸºæ–¯å¦",
        "PL": "æ³¢å…°",
        "PR": "æ³¢å¤šé»å„",
        "PT": "è‘¡è„ç‰™",
        "PY": "å·´æ‹‰åœ­",
        "QA": "å¡å¡”å°”",
        "RO": "ç½—é©¬å°¼äºš",
        "RU": "ä¿„ç½—æ–¯",
        "SA": "æ²™ç‰¹é˜¿æ‹‰ä¼¯",
        "SE": "ç‘å…¸",
        "SG": "æ–°åŠ å¡",
        "TH": "æ³°å›½",
        "TN": "çªå°¼æ–¯",
        "TR": "åœŸè€³å…¶",
        "TW": "å°æ¹¾åœ°åŒº",
        "UA": "ä¹Œå…‹å…°",
        "US": "ç¾å›½",
        "UY": "ä¹Œæ‹‰åœ­",
        "VE": "å§”å†…ç‘æ‹‰",
        "VN": "è¶Šå—",
        "ZA": "å—é",
        "ZW": "æ´¥å·´å¸ƒéŸ¦",
        "HK": "é¦™æ¸¯",
        "MO": "æ¾³é—¨",
        
        # æ–°å¢ä¸»æƒå›½å®¶
        "AD": "å®‰é“å°”",
        "AG": "å®‰æç“œå’Œå·´å¸ƒè¾¾",
        "AM": "äºšç¾å°¼äºš",
        "AO": "å®‰å“¥æ‹‰",
        "AW": "é˜¿é²å·´",
        "BB": "å·´å·´å¤šæ–¯",
        "BH": "å·´æ—",
        "BJ": "è´å®",
        "BN": "æ–‡è±",
        "BS": "å·´å“ˆé©¬",
        "BT": "ä¸ä¸¹",
        "BW": "åšèŒ¨ç“¦çº³",
        "BZ": "ä¼¯åˆ©å…¹",
        "CF": "ä¸­éå…±å’Œå›½",
        "CI": "ç§‘ç‰¹è¿ªç“¦",
        "CM": "å–€éº¦éš†",
        "CV": "ä½›å¾—è§’",
        "CY": "å¡æµ¦è·¯æ–¯",
        "DJ": "å‰å¸ƒæ",
        "DM": "å¤šç±³å°¼å…‹",
        "ER": "å„ç«‹ç‰¹é‡Œäºš",
        "ET": "åŸƒå¡ä¿„æ¯”äºš",
        "FJ": "æ–æµ",
        "FM": "å¯†å…‹ç½—å°¼è¥¿äºš",
        "GA": "åŠ è“¬",
        "GD": "æ ¼æ—çº³è¾¾",
        "GG": "æ ¹è¥¿å²›",
        "GM": "å†ˆæ¯”äºš",
        "GQ": "èµ¤é“å‡ å†…äºš",
        "GY": "åœ­äºšé‚£",
        "HT": "æµ·åœ°",
        "JE": "æ³½è¥¿å²›",
        "KM": "ç§‘æ‘©ç½—",
        "LA": "è€æŒ",
        "LI": "åˆ—æ”¯æ•¦å£«ç™»",
        "LR": "åˆ©æ¯”é‡Œäºš",
        "LS": "è±ç´¢æ‰˜",
        "LU": "å¢æ£®å ¡",
        "LV": "æ‹‰è„±ç»´äºš",
        "MC": "æ‘©çº³å“¥",
        "MD": "æ‘©å°”å¤šç“¦",
        "MG": "é©¬è¾¾åŠ æ–¯åŠ ",
        "MK": "åŒ—é©¬å…¶é¡¿",
        "ML": "é©¬é‡Œ",
        "MR": "æ¯›é‡Œå¡”å°¼äºš",
        "MU": "æ¯›é‡Œæ±‚æ–¯",
        "MV": "é©¬å°”ä»£å¤«",
        "MW": "é©¬æ‹‰ç»´",
        "NA": "çº³ç±³æ¯”äºš",
        "NE": "å°¼æ—¥å°”",
        "PG": "å·´å¸ƒäºšæ–°å‡ å†…äºš",
        "RW": "å¢æ—ºè¾¾",
        "SC": "å¡èˆŒå°”",
        "SL": "å¡æ‹‰åˆ©æ˜‚",
        "SM": "åœ£é©¬åŠ›è¯º",
        "SN": "å¡å†…åŠ å°”",
        "SO": "ç´¢é©¬é‡Œ",
        "SR": "è‹é‡Œå—",
        "ST": "åœ£å¤šç¾å’Œæ™®æ—è¥¿æ¯”",
        "SY": "å™åˆ©äºš",
        "SZ": "æ–¯å¨å£«å…°",
        "TD": "ä¹å¾—",
        "TL": "ä¸œå¸æ±¶",
        "TM": "åœŸåº“æ›¼æ–¯å¦",
        "TO": "æ±¤åŠ ",
        "TV": "å›¾ç“¦å¢",
        "TZ": "å¦æ¡‘å°¼äºš",
        "UZ": "ä¹Œå…¹åˆ«å…‹æ–¯å¦",
        "VU": "ç“¦åŠªé˜¿å›¾",
        "WS": "è¨æ‘©äºš",
        
        # ç‰¹æ®Šåœ°åŒº
        "VG": "è‹±å±ç»´å°”äº¬ç¾¤å²›",
        "KY": "å¼€æ›¼ç¾¤å²›",
        "BM": "ç™¾æ…•å¤§",
        "FO": "æ³•ç½—ç¾¤å²›",
        "GF": "æ³•å±åœ­äºšé‚£",
        "GL": "æ ¼é™µå…°",
        "PF": "æ³•å±æ³¢åˆ©å°¼è¥¿äºš",
        "RE": "ç•™å°¼æ±ª",
        "VI": "ç¾å±ç»´å°”äº¬ç¾¤å²›",
        
        # ç‰¹æ®Šæ ‡è®°
        "Multi_Nations": "å¤šå›½å…±æœ‰åŒºåŸŸ",
        "Nation_Not_Found": "æ— æ³•è¯†åˆ«çš„ä»£ç "
    }
    
    return country_name_mapping

country_name_mapping = extract_country_mapping()

def get_country_name(country_code, country_mapping=None):
    """
    æ ¹æ®å›½å®¶ç®€ç§°è·å–å›½å®¶åç§°
    
    å‚æ•°è¯´æ˜ï¼š
    - country_code: å›½å®¶ç®€ç§°
    - country_mapping: å›½å®¶æ˜ å°„å­—å…¸ï¼ˆå¯é€‰ï¼‰
    
    è¿”å›å€¼ï¼š
    - å›½å®¶åç§°å­—ç¬¦ä¸²ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å›åŸå§‹ä»£ç 
    """
    if country_mapping is None:
        country_mapping = extract_country_mapping()
    
    return country_mapping.get(country_code, country_code)

# ä½¿ç”¨ç¤ºä¾‹
country_name_mapping = extract_country_mapping()

# æµ‹è¯•ç¤ºä¾‹
print("=== å›½å®¶ç®€ç§°åˆ°åç§°æ˜ å°„ç¤ºä¾‹ ===")
test_codes = ["CN", "US", "JP", "DE", "GB", "FR", "KR", "IN"]
for code in test_codes:
    name = get_country_name(code, country_name_mapping)
    print(f"{code} -> {name}")

print(f"\næ€»å…±åŒ…å« {len(country_name_mapping)} ä¸ªå›½å®¶/åœ°åŒº")

# åŠ è½½å…¬å¸æ•°æ®
companies = load_companies(path_dic["company"])


for idx, company in enumerate(companies.values()):
    print(f"å…¬å¸IDï¼š{company.id}ï¼Œå›½å®¶ï¼š{company.country}ï¼Œä¸Šå¸‚çŠ¶æ€ï¼š{company.listed}")
    if idx > 10:
        break
# æ„å»ºå…¬å¸-å›½å®¶æ˜ å°„è¡¨
company_to_country = build_company_to_country(companies)
# é‡æ–°æ„å»ºåŒ…å«ä¸­å›½èŠ‚ç‚¹çš„ä¾›åº”é“¾å…³ç³»
# é€šè¿‡è¯»å– supply_chains_with_industry_codes.json é‡æ–°æ„å»º supply_chains_contains_cn_node
import json

def load_supply_chains_from_json(json_path, companies):
    """
    ä»JSONæ–‡ä»¶åŠ è½½ä¾›åº”é“¾æ•°æ®å¹¶é‡æ–°æ„å»ºSupplyRelationå¯¹è±¡
    """
    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)
    chains = []
    for chain_data in data:
        chain = []
        for rel_dict in chain_data:
            from_co = companies.get(rel_dict["from_co_id"])
            to_co = companies.get(rel_dict["to_co_id"])
            if not from_co or not to_co:
                continue
            
            # åˆ›å»ºSupplyRelationå¯¹è±¡ï¼Œä½¿ç”¨æ­£ç¡®çš„datetimeå¯¼å…¥
            rel = SupplyRelation(
                from_co=from_co,
                to_co=to_co,
                start=datetime.strptime(rel_dict["start"], "%Y-%m-%d") if rel_dict["start"] else None,
                end=datetime.strptime(rel_dict["end"], "%Y-%m-%d") if rel_dict["end"] else None
            )
            
            # å•ç‹¬è®¾ç½®statuså±æ€§
            rel.status = rel_dict["status"]
            
            # è®¾ç½®industry_codeså±æ€§
            rel.industry_codes = rel_dict.get("industry_codes")
            
            chain.append(rel)
        if chain:
            chains.append(chain)
    return chains

json_path = r".\è°ƒç”¨æ–‡ä»¶\ç”¨äºè¡Œä¸šåˆ†ç±»åˆ†æçš„å¯è§†åŒ–è¡¨\supply_chains_with_industry_codes.json"
supply_chains_contains_cn_node = load_supply_chains_from_json(json_path, companies)

print(f"é‡æ–°æ„å»ºåï¼ŒåŒ…å«ä¸­å›½èŠ‚ç‚¹çš„ä¾›åº”é“¾æ•°é‡: {len(supply_chains_contains_cn_node)}")


def analyze_industry_vulnerability(supply_chains_contains_cn_node, calculation_method='separate', min_threshold=50):
    """
    åˆ†æä¸åŒè¡Œä¸šçš„ä¾›åº”é“¾è„†å¼±æ€§ï¼ˆåŸºäºé•¿ä¾›åº”é“¾åˆ†æï¼‰
    
    :param calculation_method: è®¡ç®—æ–¹æ³•
        - 'separate': æ–­è£‚ç‡å’Œè½¬ç§»ç‡åˆ†åˆ«è®¡ç®—ï¼ˆåŸæ–¹æ³•ï¼‰
        - 'sequential': è½¬ç§»ç‡åŸºäºæ–­è£‚æ•°è®¡ç®—ï¼ˆæ‚¨æè®®çš„æ–¹æ³•ï¼‰
    :param min_threshold: æœ€å°æ ·æœ¬æ•°é˜ˆå€¼ï¼Œåªæœ‰å½“è½¬ç§»æ•°å’Œæ–­è£‚æ•°éƒ½è¶…è¿‡æ­¤å€¼æ—¶æ‰çº³å…¥æœ€ç»ˆè¯„åˆ¤
    """
    
    # ç»Ÿè®¡æ–­è£‚å’Œè½¬ç§»çš„é•¿ä¾›åº”é“¾
    break_chains = []  # åŒ…å«æ–­è£‚çš„é•¿ä¾›åº”é“¾
    transfer_chains = []  # åŒ…å«è½¬ç§»çš„é•¿ä¾›åº”é“¾
    
    # ç¬¬ä¸€æ­¥ï¼šè¯†åˆ«æ–­è£‚å’Œè½¬ç§»çš„é•¿ä¾›åº”é“¾
    for chain in supply_chains_contains_cn_node:
        has_break = False
        has_transfer = False
        
        for rel in chain:
            if isinstance(rel, SupplyRelation):
                if rel.status == 'permanent_break':
                    has_break = True
                elif rel.status == 'transfer':
                    has_transfer = True
        
        if has_break:
            break_chains.append(chain)
        if has_transfer:
            transfer_chains.append(chain)
    
    # ç¬¬äºŒæ­¥ï¼šç»Ÿè®¡å„è¡Œä¸šåœ¨æ–­è£‚ä¾›åº”é“¾ä¸­çš„å‡ºç°æ¬¡æ•°
    industry_break_count = defaultdict(int)
    for chain in break_chains:
        affected_industries = set()  # ä½¿ç”¨seté¿å…åŒä¸€é“¾ä¸­åŒä¸€è¡Œä¸šé‡å¤è®¡ç®—
        
        for rel in chain:
            if isinstance(rel, SupplyRelation) and rel.industry_codes:
                if rel.industry_codes != 'Line_Not_Found' and rel.industry_codes is not None:
                    for industry_code in rel.industry_codes:
                        affected_industries.add(industry_code)
        
        # æ¯ä¸ªå—å½±å“çš„è¡Œä¸šåœ¨è¿™ä¸ªæ–­è£‚é“¾ä¸­è®¡æ•°+1
        for industry_code in affected_industries:
            industry_break_count[industry_code] += 1
    
    # ç¬¬ä¸‰æ­¥ï¼šç»Ÿè®¡å„è¡Œä¸šåœ¨è½¬ç§»ä¾›åº”é“¾ä¸­çš„å‡ºç°æ¬¡æ•°
    industry_transfer_count = defaultdict(int)
    for chain in transfer_chains:
        affected_industries = set()  # ä½¿ç”¨seté¿å…åŒä¸€é“¾ä¸­åŒä¸€è¡Œä¸šé‡å¤è®¡ç®—
        
        for rel in chain:
            if isinstance(rel, SupplyRelation) and rel.industry_codes:
                if rel.industry_codes != 'Line_Not_Found' and rel.industry_codes is not None:
                    for industry_code in rel.industry_codes:
                        affected_industries.add(industry_code)
        
        # æ¯ä¸ªå—å½±å“çš„è¡Œä¸šåœ¨è¿™ä¸ªè½¬ç§»é“¾ä¸­è®¡æ•°+1
        for industry_code in affected_industries:
            industry_transfer_count[industry_code] += 1
    
    # ç¬¬å››æ­¥ï¼šåº”ç”¨æœ€å°æ ·æœ¬æ•°è¿‡æ»¤å¹¶è®¡ç®—å„è¡Œä¸šçš„è„†å¼±æ€§æŒ‡æ ‡
    vulnerability_analysis = {}
    excluded_industries = []  # è®°å½•è¢«æ’é™¤çš„è¡Œä¸š
    
    # è·å–æ‰€æœ‰æ¶‰åŠçš„è¡Œä¸šä»£ç 
    all_industries = set(industry_break_count.keys()) | set(industry_transfer_count.keys())
    
    total_break_chains = len(break_chains)
    total_transfer_chains = len(transfer_chains)
    
    for industry_code in all_industries:
        break_count = industry_break_count.get(industry_code, 0)
        transfer_count = industry_transfer_count.get(industry_code, 0)
        
        # åº”ç”¨æœ€å°æ ·æœ¬æ•°è¿‡æ»¤
        if break_count < min_threshold and transfer_count < min_threshold:
            excluded_industries.append({
                'industry_code': industry_code,
                'break_count': break_count,
                'transfer_count': transfer_count,
                'reason': f'æ–­è£‚æ•°({break_count})å’Œè½¬ç§»æ•°({transfer_count})å‡å°äº{min_threshold}'
            })
            continue
        
        if calculation_method == 'separate':
            # åŸæ–¹æ³•ï¼šåˆ†åˆ«è®¡ç®—å æ¯”
            vulnerability_analysis[industry_code] = {
                'total_break_chains': break_count,
                'total_transfer_chains': transfer_count,
                'break_rate': break_count / total_break_chains if total_break_chains > 0 else 0,
                'transfer_rate': transfer_count / total_transfer_chains if total_transfer_chains > 0 else 0,
                'calculation_method': 'separate',
                'meets_threshold': True
            }
        elif calculation_method == 'sequential':
            # æ–°æ–¹æ³•ï¼šè½¬ç§»ç‡åŸºäºè¯¥è¡Œä¸šçš„æ–­è£‚æ•°è®¡ç®—
            vulnerability_analysis[industry_code] = {
                'total_break_chains': break_count,
                'total_transfer_chains': transfer_count,
                'break_rate': break_count / total_break_chains if total_break_chains > 0 else 0,
                'transfer_rate': transfer_count / break_count if break_count > 0 else 0,  # å…³é”®ä¿®æ”¹
                'transfer_adaptation_ratio': transfer_count / break_count if break_count > 0 else 0,  # æ›´æ˜ç¡®çš„å‘½å
                'calculation_method': 'sequential',
                'meets_threshold': True
            }
    
    print(f"ç»Ÿè®¡ç»“æœï¼ˆè®¡ç®—æ–¹æ³•: {calculation_method}ï¼Œæœ€å°æ ·æœ¬æ•°é˜ˆå€¼: {min_threshold}ï¼‰ï¼š")
    print(f"  æ–­è£‚ä¾›åº”é“¾æ€»æ•°: {total_break_chains}")
    print(f"  è½¬ç§»ä¾›åº”é“¾æ€»æ•°: {total_transfer_chains}")
    print(f"  åŸå§‹æ¶‰åŠè¡Œä¸šæ€»æ•°: {len(all_industries)}")
    print(f"  ç¬¦åˆé˜ˆå€¼çš„è¡Œä¸šæ•°: {len(vulnerability_analysis)}")
    print(f"  è¢«æ’é™¤çš„è¡Œä¸šæ•°: {len(excluded_industries)}")
    
    if calculation_method == 'sequential':
        print(f"  æ³¨æ„ï¼šè½¬ç§»ç‡ = è¯¥è¡Œä¸šè½¬ç§»é“¾æ•° / è¯¥è¡Œä¸šæ–­è£‚é“¾æ•°")
        print(f"  è½¬ç§»ç‡ > 1 è¡¨ç¤ºè¯¥è¡Œä¸šè½¬ç§»é“¾æ•°è¶…è¿‡æ–­è£‚é“¾æ•°")
    
    # æ˜¾ç¤ºä¸€äº›è¢«æ’é™¤çš„è¡Œä¸šç¤ºä¾‹
    if excluded_industries:
        print(f"\nè¢«æ’é™¤çš„è¡Œä¸šç¤ºä¾‹ï¼ˆå‰10ä¸ªï¼‰:")
        for i, excluded in enumerate(excluded_industries[:10]):
            print(f"  {i+1}. è¡Œä¸š{excluded['industry_code']}: {excluded['reason']}")
        if len(excluded_industries) > 10:
            print(f"  ...è¿˜æœ‰{len(excluded_industries) - 10}ä¸ªè¡Œä¸šè¢«æ’é™¤")
    
    return vulnerability_analysis, excluded_industries

def analyze_industry_geography(supply_chains_contains_cn_node, company_to_country):
    """
    åˆ†æè½¬å‘ä¸­å›½å’Œä»ä¸­å›½è½¬å‡ºçš„ä¾›åº”é“¾è¡Œä¸šåˆ†ç±»
    
    è®¡ç®—åŸç†è¯´æ˜ï¼š
    - éå†æ‰€æœ‰åŒ…å«ä¸­å›½èŠ‚ç‚¹çš„ä¾›åº”é“¾é“¾è·¯ï¼Œè¯†åˆ«åŒ…å« 'transfer' çŠ¶æ€çš„ä¾›åº”é“¾ã€‚
    - é‡ç‚¹åˆ†æä¸¤ä¸ªæ–¹å‘çš„è½¬ç§»ï¼š
      1. è½¬å‘ä¸­å›½ï¼šå…¶ä»–å›½å®¶ -> ä¸­å›½ï¼ˆCN/HK/MOï¼‰
      2. ä»ä¸­å›½è½¬å‡ºï¼šä¸­å›½ï¼ˆCN/HK/MOï¼‰ -> å…¶ä»–å›½å®¶
    - ç»Ÿè®¡æ¯ä¸ªè½¬ç§»æ–¹å‘çš„è¡Œä¸šåˆ†å¸ƒå’Œç›®æ ‡å›½å®¶åˆ†å¸ƒ
    - CNã€HKã€MOç»Ÿä¸€è§†ä¸ºä¸­å›½åœ°åŒº

    å‘ˆç°å†…å®¹è¯´æ˜ï¼š
    - è¿”å›å€¼åŒ…å«ï¼š
      1. 'to_china_analysis': è½¬å‘ä¸­å›½çš„ä¾›åº”é“¾è¡Œä¸šåˆ†æ
      2. 'from_china_analysis': ä»ä¸­å›½è½¬å‡ºçš„ä¾›åº”é“¾è¡Œä¸šåˆ†æ
      3. 'china_bilateral_summary': åŒå‘è½¬ç§»ç»Ÿè®¡æ‘˜è¦
    """
    
    # å®šä¹‰ä¸­å›½åœ°åŒºä»£ç ï¼ˆåŒ…æ‹¬é¦™æ¸¯ã€æ¾³é—¨ï¼‰
    china_codes = {'CN', 'HK', 'MO', 'China', 'Hong Kong', 'Macau'}
    
    # å®šä¹‰æ— æ•ˆå›½å®¶ä»£ç é›†åˆ
    invalid_countries = {
        'Unknown_Empty', 'Unknown_None', 'Unknown', 'Nation_Not_Found', 
        '', None, 'null', 'NULL', 'N/A', 'na', 'NA'
    }
    
    # ç¬¬ä¸€æ­¥ï¼šè¯†åˆ«åŒ…å«è½¬ç§»å…³ç³»çš„ä¾›åº”é“¾
    transfer_chains = []
    for chain in supply_chains_contains_cn_node:
        has_transfer = False
        for rel in chain:
            if isinstance(rel, SupplyRelation) and rel.status == 'transfer':
                has_transfer = True
                break
        if has_transfer:
            transfer_chains.append(chain)
    
    print(f"åŒ…å«è½¬ç§»å…³ç³»çš„ä¾›åº”é“¾æ•°é‡: {len(transfer_chains)}")
    
    # ç¬¬äºŒæ­¥ï¼šåˆ†æè½¬å‘ä¸­å›½å’Œä»ä¸­å›½è½¬å‡ºçš„è½¬ç§»å…³ç³»
    to_china_industry_count = defaultdict(int)      # è½¬å‘ä¸­å›½çš„è¡Œä¸šç»Ÿè®¡
    from_china_industry_count = defaultdict(int)    # ä»ä¸­å›½è½¬å‡ºçš„è¡Œä¸šç»Ÿè®¡
    to_china_source_countries = defaultdict(lambda: defaultdict(int))  # è½¬å‘ä¸­å›½çš„æ¥æºå›½å®¶
    from_china_target_countries = defaultdict(lambda: defaultdict(int)) # ä»ä¸­å›½è½¬å‡ºçš„ç›®æ ‡å›½å®¶
    
    total_to_china_transfers = 0
    total_from_china_transfers = 0
    
    # æ•°æ®è´¨é‡è®¡æ•°å™¨
    filtered_out_count = 0
    
    for chain in transfer_chains:
        for rel in chain:
            if isinstance(rel, SupplyRelation) and rel.status == 'transfer':
                # è·å–ä¾›åº”æ–¹å’Œéœ€æ±‚æ–¹å›½å®¶
                from_countries = company_to_country.get(rel.from_co.id, (['Unknown'], ['Unknown']))[1]
                to_countries = company_to_country.get(rel.to_co.id, (['Unknown'], ['Unknown']))[1]
                
                # æ¸…ç†å›½å®¶ä»£ç 
                def clean_countries(countries):
                    cleaned = []
                    for country in countries:
                        if country is None or str(country).strip() == '' or str(country).strip() in invalid_countries:
                            continue
                        cleaned.append(str(country).strip())
                    return cleaned
                
                cleaned_from_countries = clean_countries(from_countries)
                cleaned_to_countries = clean_countries(to_countries)
                
                if not cleaned_from_countries or not cleaned_to_countries:
                    filtered_out_count += 1
                    continue
                
                # åˆ¤æ–­æ˜¯å¦ä¸ºä¸­å›½ç›¸å…³è½¬ç§»
                from_is_china = any(country in china_codes for country in cleaned_from_countries)
                to_is_china = any(country in china_codes for country in cleaned_to_countries)
                
                # è·å–è¡Œä¸šä»£ç 
                if (rel.industry_codes and 
                    rel.industry_codes != 'Line_Not_Found' and 
                    rel.industry_codes is not None):
                    
                    for industry_code in rel.industry_codes:
                        # 1. è½¬å‘ä¸­å›½çš„è½¬ç§»ï¼ˆå…¶ä»–å›½å®¶ -> ä¸­å›½ï¼‰
                        if to_is_china and not from_is_china:
                            to_china_industry_count[industry_code] += 1
                            total_to_china_transfers += 1
                            
                            # è®°å½•æ¥æºå›½å®¶
                            for from_country in cleaned_from_countries:
                                to_china_source_countries[industry_code][from_country] += 1
                        
                        # 2. ä»ä¸­å›½è½¬å‡ºï¼ˆä¸­å›½ -> å…¶ä»–å›½å®¶ï¼‰
                        elif from_is_china and not to_is_china:
                            from_china_industry_count[industry_code] += 1
                            total_from_china_transfers += 1
                            
                            # è®°å½•ç›®æ ‡å›½å®¶
                            for to_country in cleaned_to_countries:
                                from_china_target_countries[industry_code][to_country] += 1
    
    print(f"æ•°æ®è´¨é‡æŠ¥å‘Š:")
    print(f"  è¢«è¿‡æ»¤çš„æ— æ•ˆæ•°æ®æ•°é‡: {filtered_out_count}")
    print(f"  è½¬å‘ä¸­å›½çš„è½¬ç§»å…³ç³»æ€»æ•°: {total_to_china_transfers}")
    print(f"  ä»ä¸­å›½è½¬å‡ºçš„è½¬ç§»å…³ç³»æ€»æ•°: {total_from_china_transfers}")
    
    # ç¬¬ä¸‰æ­¥ï¼šåˆ†æè½¬å‘ä¸­å›½çš„è¡Œä¸šåˆ†å¸ƒ
    to_china_analysis = {}
    if total_to_china_transfers > 0:
        for industry_code, count in to_china_industry_count.items():
            # è·å–è¯¥è¡Œä¸šçš„ä¸»è¦æ¥æºå›½å®¶
            source_countries = to_china_source_countries[industry_code]
            sorted_sources = sorted(source_countries.items(), key=lambda x: x[1], reverse=True)
            
            to_china_analysis[industry_code] = {
                'transfer_count': count,
                'percentage_in_to_china': count / total_to_china_transfers,
                'main_source_countries': [item[0] for item in sorted_sources[:3]],
                'source_distribution': dict(sorted_sources)
            }
        
        # æŒ‰è½¬å‘ä¸­å›½çš„æ•°é‡æ’åº
        sorted_to_china_industries = sorted(to_china_analysis.items(), 
                                          key=lambda x: x[1]['transfer_count'], reverse=True)
    else:
        sorted_to_china_industries = []
    
    # ç¬¬å››æ­¥ï¼šåˆ†æä»ä¸­å›½è½¬å‡ºçš„è¡Œä¸šåˆ†å¸ƒ
    from_china_analysis = {}
    if total_from_china_transfers > 0:
        for industry_code, count in from_china_industry_count.items():
            # è·å–è¯¥è¡Œä¸šçš„ä¸»è¦ç›®æ ‡å›½å®¶
            target_countries = from_china_target_countries[industry_code]
            sorted_targets = sorted(target_countries.items(), key=lambda x: x[1], reverse=True)
            
            from_china_analysis[industry_code] = {
                'transfer_count': count,
                'percentage_in_from_china': count / total_from_china_transfers,
                'main_target_countries': [item[0] for item in sorted_targets[:3]],
                'target_distribution': dict(sorted_targets)
            }
        
        # æŒ‰ä»ä¸­å›½è½¬å‡ºçš„æ•°é‡æ’åº
        sorted_from_china_industries = sorted(from_china_analysis.items(), 
                                            key=lambda x: x[1]['transfer_count'], reverse=True)
    else:
        sorted_from_china_industries = []
    
    # ç¬¬äº”æ­¥ï¼šç”Ÿæˆç»Ÿè®¡æ‘˜è¦
    print(f"\n=== ä¸­å›½åŒå‘ä¾›åº”é“¾è½¬ç§»åˆ†ææ‘˜è¦ ===")
    
    # è½¬å‘ä¸­å›½åˆ†æ
    if sorted_to_china_industries:
        print(f"\nğŸ“¥ è½¬å‘ä¸­å›½çš„ä¾›åº”é“¾è½¬ç§»åˆ†æ:")
        print(f"   è½¬å‘ä¸­å›½çš„æ€»è½¬ç§»æ•°: {total_to_china_transfers}")
        print(f"   æ¶‰åŠè¡Œä¸šæ•°: {len(sorted_to_china_industries)}")
        print(f"   è½¬å‘ä¸­å›½æœ€å¤šçš„å‰10ä¸ªè¡Œä¸š:")
        
        for i, (industry, data) in enumerate(sorted_to_china_industries[:10], 1):
            pct = data['percentage_in_to_china'] * 100
            main_sources = ', '.join(data['main_source_countries'])
            print(f"   {i:2d}. è¡Œä¸š{industry:<8}: {data['transfer_count']:>4}æ¬¡ ({pct:>5.1f}%) "
                  f"- ä¸»è¦æ¥æº: {main_sources}")
    else:
        print(f"\nğŸ“¥ æ²¡æœ‰å‘ç°è½¬å‘ä¸­å›½çš„ä¾›åº”é“¾è½¬ç§»")
    
    # ä»ä¸­å›½è½¬å‡ºåˆ†æ
    if sorted_from_china_industries:
        print(f"\nğŸ“¤ ä»ä¸­å›½è½¬å‡ºçš„ä¾›åº”é“¾è½¬ç§»åˆ†æ:")
        print(f"   ä»ä¸­å›½è½¬å‡ºçš„æ€»è½¬ç§»æ•°: {total_from_china_transfers}")
        print(f"   æ¶‰åŠè¡Œä¸šæ•°: {len(sorted_from_china_industries)}")
        print(f"   ä»ä¸­å›½è½¬å‡ºæœ€å¤šçš„å‰10ä¸ªè¡Œä¸š:")
        
        for i, (industry, data) in enumerate(sorted_from_china_industries[:10], 1):
            pct = data['percentage_in_from_china'] * 100
            main_targets = ', '.join(data['main_target_countries'])
            print(f"   {i:2d}. è¡Œä¸š{industry:<8}: {data['transfer_count']:>4}æ¬¡ ({pct:>5.1f}%) "
                  f"- ä¸»è¦ç›®æ ‡: {main_targets}")
    else:
        print(f"\nğŸ“¤ æ²¡æœ‰å‘ç°ä»ä¸­å›½è½¬å‡ºçš„ä¾›åº”é“¾è½¬ç§»")
    
    # åŒå‘å¯¹æ¯”åˆ†æ
    print(f"\nğŸ”„ åŒå‘è½¬ç§»å¯¹æ¯”åˆ†æ:")
    print(f"   è½¬å‘ä¸­å›½ vs ä»ä¸­å›½è½¬å‡º æ¯”ä¾‹: {total_to_china_transfers} : {total_from_china_transfers}")
    if total_to_china_transfers > 0 and total_from_china_transfers > 0:
        ratio = total_to_china_transfers / total_from_china_transfers
        print(f"   è½¬å‘ä¸­å›½/ä»ä¸­å›½è½¬å‡º æ¯”ç‡: {ratio:.2f}")
        
        # æ‰¾å‡ºåŒå‘è½¬ç§»éƒ½è¾ƒå¤šçš„è¡Œä¸š
        to_china_top_industries = set([item[0] for item in sorted_to_china_industries[:10]])
        from_china_top_industries = set([item[0] for item in sorted_from_china_industries[:10]])
        bidirectional_industries = to_china_top_industries & from_china_top_industries
        
        if bidirectional_industries:
            print(f"\n   åŒå‘è½¬ç§»éƒ½è¾ƒæ´»è·ƒçš„è¡Œä¸š:")
            for industry in bidirectional_industries:
                to_china_count = to_china_analysis.get(industry, {}).get('transfer_count', 0)
                from_china_count = from_china_analysis.get(industry, {}).get('transfer_count', 0)
                print(f"     è¡Œä¸š{industry}: è½¬å‘ä¸­å›½{to_china_count}æ¬¡, ä»ä¸­å›½è½¬å‡º{from_china_count}æ¬¡")
    
    return {
        'to_china_analysis': {
            'total_transfers': total_to_china_transfers,
            'industry_distribution': to_china_analysis,
            'sorted_industries': sorted_to_china_industries
        },
        'from_china_analysis': {
            'total_transfers': total_from_china_transfers,
            'industry_distribution': from_china_analysis,
            'sorted_industries': sorted_from_china_industries
        },
        'china_bilateral_summary': {
            'to_china_transfers': total_to_china_transfers,
            'from_china_transfers': total_from_china_transfers,
            'transfer_ratio': total_to_china_transfers / total_from_china_transfers if total_from_china_transfers > 0 else 0,
            'total_transfer_chains': len(transfer_chains),
            'data_quality': {
                'filtered_out_count': filtered_out_count
            }
        }
    }
    

def analyze_industry_interconnection(supply_chains_contains_cn_node):
    """
    åˆ†æè¡Œä¸šé—´çš„ä¾›åº”é“¾å…³è”æ¨¡å¼

    è®¡ç®—åŸç†è¯´æ˜ï¼š
    - éå†æ‰€æœ‰åŒ…å«ä¸­å›½èŠ‚ç‚¹çš„ä¾›åº”é“¾é“¾è·¯ï¼Œæå–æ¯ä¸€å¯¹ç›¸é‚»çš„ä¾›åº”å…³ç³»ï¼ˆå³é“¾è·¯ä¸­çš„å‰åä¸¤ä¸ªå…³ç³»ï¼‰ã€‚
    - å¯¹äºæ¯ä¸€å¯¹ç›¸é‚»å…³ç³»ï¼Œåˆ†åˆ«è·å–å…¶æ‰€å±è¡Œä¸šä»£ç ï¼ˆindustry_codesï¼‰ã€‚
    - ç»Ÿè®¡æ‰€æœ‰â€œå‰ä¸€è¡Œä¸šâ€åˆ°â€œåä¸€è¡Œä¸šâ€çš„é…å¯¹å‡ºç°æ¬¡æ•°ï¼Œå½¢æˆè¡Œä¸šé—´çš„æœ‰å‘å…³è”çŸ©é˜µï¼ˆindustry_pairsï¼‰ã€‚
    - è¯¥çŸ©é˜µçš„æ¯ä¸ªå…ƒç´  industry_pairs[A][B] è¡¨ç¤ºè¡Œä¸šAä½œä¸ºä¾›åº”æ–¹ã€è¡Œä¸šBä½œä¸ºéœ€æ±‚æ–¹çš„é“¾è·¯æ•°é‡ã€‚

    å‘ˆç°å†…å®¹è¯´æ˜ï¼š
    - è¿”å›å€¼ä¸º industry_pairs å­—å…¸ï¼Œé”®ä¸ºèµ·å§‹è¡Œä¸šä»£ç ï¼Œå€¼ä¸ºä¸€ä¸ªå­—å…¸ï¼ˆå…¶é”®ä¸ºç›®æ ‡è¡Œä¸šä»£ç ï¼Œå€¼ä¸ºå¯¹åº”çš„é“¾è·¯æ•°é‡ï¼‰ã€‚
    - å¯ç”¨äºåˆ†æå“ªäº›è¡Œä¸šä¹‹é—´å­˜åœ¨è¾ƒå¼ºçš„ä¾›åº”é“¾è€¦åˆå…³ç³»ï¼Œè¯†åˆ«è¡Œä¸šé—´çš„å…³é”®ä¾èµ–è·¯å¾„å’Œè¡Œä¸šé›†ç¾¤ã€‚
    """
    industry_pairs = defaultdict(lambda: defaultdict(int))
    
    for chain in supply_chains_contains_cn_node:
        supply_relations = [rel for rel in chain if isinstance(rel, SupplyRelation)]
        
        for i in range(len(supply_relations) - 1):
            from_rel = supply_relations[i]
            to_rel = supply_relations[i + 1]
            
            if (from_rel.industry_codes and to_rel.industry_codes and 
                from_rel.industry_codes != 'Line_Not_Found' and 
                to_rel.industry_codes != 'Line_Not_Found'):
                
                for from_industry in from_rel.industry_codes:
                    for to_industry in to_rel.industry_codes:
                        industry_pairs[from_industry][to_industry] += 1
    
    return industry_pairs

def analyze_industry_temporal_dynamics(supply_chains_contains_cn_node):
    """
    åˆ†æè¡Œä¸šåœ¨ä¸åŒæ—¶é—´æ®µçš„çŠ¶æ€å˜åŒ–

    è®¡ç®—åŸç†è¯´æ˜ï¼š
    - éå†æ‰€æœ‰åŒ…å«ä¸­å›½èŠ‚ç‚¹çš„ä¾›åº”é“¾é“¾è·¯ï¼Œé’ˆå¯¹æ¯ä¸ªä¾›åº”å…³ç³»ï¼ˆSupplyRelationï¼‰ï¼š
        - æå–å…¶è¡Œä¸šä»£ç ï¼ˆindustry_codesï¼‰å’Œèµ·å§‹å¹´ä»½ï¼ˆrel.start.yearï¼‰ã€‚
        - é’ˆå¯¹æ¯ä¸ªè¡Œä¸šä»£ç ï¼Œç»Ÿè®¡è¯¥å¹´ä»½ä¸‹å„ç±»çŠ¶æ€ï¼ˆå¦‚permanent_breakã€transferã€recoveryç­‰ï¼‰çš„å‡ºç°æ¬¡æ•°ã€‚
    - ç»“æœå½¢æˆä¸€ä¸ªä¸‰å±‚åµŒå¥—å­—å…¸ industry_timeline[industry_code][year][status]ï¼Œç”¨äºæè¿°æ¯ä¸ªè¡Œä¸šåœ¨æ¯ä¸€å¹´å„çŠ¶æ€çš„æ•°é‡åˆ†å¸ƒã€‚

    å‘ˆç°å†…å®¹è¯´æ˜ï¼š
    - è¿”å›å€¼ä¸º industry_timeline å­—å…¸ï¼Œé”®ä¸ºè¡Œä¸šä»£ç ï¼Œå€¼ä¸ºå¹´ä»½-çŠ¶æ€åˆ†å¸ƒçš„å­—å…¸ã€‚
    - å¯ç”¨äºåˆ†æä¸åŒè¡Œä¸šåœ¨å„å¹´ä»½çš„æ–­è£‚ã€è½¬ç§»ã€æ¢å¤ç­‰åŠ¨æ€è¶‹åŠ¿ï¼Œè¾…åŠ©è¯†åˆ«è¡Œä¸šé£é™©çˆ†å‘æœŸå’Œæ¢å¤æœŸã€‚
    """
    industry_timeline = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))
    
    for chain in supply_chains_contains_cn_node:
        for rel in chain:
            if isinstance(rel, SupplyRelation) and rel.industry_codes:
                if rel.industry_codes != 'Line_Not_Found' and rel.industry_codes is not None:
                    year = rel.start.year if rel.start else 'unknown'
                    for industry_code in rel.industry_codes:
                        industry_timeline[industry_code][year][rel.status] += 1

    return industry_timeline


def analyze_industry_concentration(supply_chains_contains_cn_node):
    """
    åˆ†æè¡Œä¸šé›†ä¸­åº¦å’Œä¾›åº”é“¾å¤šæ ·æ€§

    è®¡ç®—åŸç†è¯´æ˜ï¼š
    - éå†æ‰€æœ‰åŒ…å«ä¸­å›½èŠ‚ç‚¹çš„ä¾›åº”é“¾é“¾è·¯ï¼Œé’ˆå¯¹æ¯ä¸ªä¾›åº”å…³ç³»ï¼ˆSupplyRelationï¼‰ï¼š
        - æå–å…¶è¡Œä¸šä»£ç ï¼ˆindustry_codesï¼‰ã€ä¾›åº”æ–¹å…¬å¸IDï¼ˆfrom_co.idï¼‰ã€éœ€æ±‚æ–¹å…¬å¸IDï¼ˆto_co.idï¼‰ã€çŠ¶æ€ï¼ˆstatusï¼‰ã€‚
        - é’ˆå¯¹æ¯ä¸ªè¡Œä¸šä»£ç ï¼Œç´¯è®¡è¯¥è¡Œä¸šçš„ä¾›åº”å…³ç³»æ€»æ•°ï¼ˆtotal_relationsï¼‰ã€‚
        - ç»Ÿè®¡è¯¥è¡Œä¸šæ¶‰åŠçš„å”¯ä¸€å…¬å¸æ•°é‡ï¼ˆunique_companiesï¼‰ï¼Œå³ä¾›åº”æ–¹å’Œéœ€æ±‚æ–¹å…¬å¸IDçš„å¹¶é›†ã€‚
        - ç»Ÿè®¡è¯¥è¡Œä¸šä¸‹å„ç±»çŠ¶æ€ï¼ˆå¦‚permanent_breakã€transferã€recoveryç­‰ï¼‰çš„å‡ºç°æ¬¡æ•°ï¼ˆstatus_distributionï¼‰ã€‚
    - è®¡ç®—é›†ä¸­åº¦æŒ‡æ ‡ï¼š
        - concentration_ratio = total_relations / unique_companiesï¼Œåæ˜ è¡Œä¸šå†…ä¾›åº”å…³ç³»çš„é›†ä¸­ç¨‹åº¦ï¼Œå€¼è¶Šé«˜è¡¨ç¤ºè¡Œä¸šè¶Šé›†ä¸­ã€‚
        - status_entropy = ä¾›åº”å…³ç³»çŠ¶æ€åˆ†å¸ƒçš„ç†µï¼Œè¡¡é‡è¡Œä¸šçŠ¶æ€çš„å¤šæ ·æ€§ï¼Œç†µè¶Šé«˜è¡¨ç¤ºçŠ¶æ€è¶Šåˆ†æ•£ã€‚

    å‘ˆç°å†…å®¹è¯´æ˜ï¼š
    - è¿”å›å€¼ä¸º concentration_metrics å­—å…¸ï¼Œé”®ä¸ºè¡Œä¸šä»£ç ï¼Œå€¼ä¸ºè¯¥è¡Œä¸šçš„é›†ä¸­åº¦åˆ†ææŒ‡æ ‡ï¼ˆæ€»å…³ç³»æ•°ã€å”¯ä¸€å…¬å¸æ•°ã€é›†ä¸­åº¦ã€çŠ¶æ€åˆ†å¸ƒç†µï¼‰ã€‚
    - å¯ç”¨äºè¯†åˆ«é«˜åº¦é›†ä¸­çš„è¡Œä¸šå’Œå¤šæ ·åŒ–ç¨‹åº¦è¾ƒé«˜çš„è¡Œä¸šï¼Œè¾…åŠ©è¡Œä¸šé£é™©å’Œç«äº‰æ ¼å±€åˆ†æã€‚
    """
    industry_stats = defaultdict(lambda: {
        'total_relations': 0,
        'unique_companies': set(),
        'status_distribution': defaultdict(int),
        'country_diversity': set()
    })
    
    for chain in supply_chains_contains_cn_node:
        for rel in chain:
            if isinstance(rel, SupplyRelation) and rel.industry_codes:
                if rel.industry_codes != 'Line_Not_Found' and rel.industry_codes is not None:
                    for industry_code in rel.industry_codes:
                        industry_stats[industry_code]['total_relations'] += 1
                        industry_stats[industry_code]['unique_companies'].add(rel.from_co.id)
                        industry_stats[industry_code]['unique_companies'].add(rel.to_co.id)
                        industry_stats[industry_code]['status_distribution'][rel.status] += 1

    # è®¡ç®—é›†ä¸­åº¦æŒ‡æ ‡
    concentration_metrics = {}
    for industry, stats in industry_stats.items():
        concentration_metrics[industry] = {
            'total_relations': stats['total_relations'],
            'unique_companies': len(stats['unique_companies']),
            'concentration_ratio': stats['total_relations'] / len(stats['unique_companies']) if stats['unique_companies'] else 0,
            'status_entropy': calculate_entropy(stats['status_distribution'])
        }
    
    return concentration_metrics

def calculate_entropy(distribution):
    """
    è®¡ç®—åˆ†å¸ƒçš„ç†µå€¼ï¼ˆShannon entropyï¼‰

    è®¡ç®—åŸç†è¯´æ˜ï¼š
    - ç†µï¼ˆentropyï¼‰ç”¨äºè¡¡é‡åˆ†å¸ƒçš„ä¸ç¡®å®šæ€§æˆ–å¤šæ ·æ€§ï¼Œå¸¸ç”¨äºæè¿°çŠ¶æ€åˆ†å¸ƒçš„åˆ†æ•£ç¨‹åº¦ã€‚
    - å¯¹äºæ¯ç§çŠ¶æ€ï¼Œè®¡ç®—å…¶æ¦‚ç‡ p = count / totalã€‚
    - ç†µçš„å…¬å¼ä¸ºï¼šentropy = -sum(p * log2(p))ï¼Œæ¦‚ç‡è¶Šå‡åŒ€ï¼Œç†µå€¼è¶Šé«˜ï¼Œè¡¨ç¤ºå¤šæ ·æ€§è¶Šå¤§ã€‚

    å‘ˆç°å†…å®¹è¯´æ˜ï¼š
    - è¿”å›å€¼ä¸ºè¯¥åˆ†å¸ƒçš„ç†µå€¼ï¼ˆfloatï¼‰ï¼Œç”¨äºè¡¡é‡è¡Œä¸šå†…ä¾›åº”å…³ç³»çŠ¶æ€çš„å¤šæ ·æ€§ã€‚
    - ç†µå€¼è¶Šé«˜ï¼Œè¯´æ˜è¯¥è¡Œä¸šçš„ä¾›åº”é“¾çŠ¶æ€è¶Šåˆ†æ•£ï¼Œè¶Šå¤šæ ·åŒ–ï¼›ç†µå€¼è¶Šä½ï¼Œè¯´æ˜çŠ¶æ€æ›´é›†ä¸­ã€‚
    """
    total = sum(distribution.values())
    if total == 0:
        return 0

    entropy = 0
    for count in distribution.values():
        if count > 0:
            p = count / total
            entropy -= p * math.log2(p)

    return entropy

def analyze_industry_resilience(supply_chains_contains_cn_node):
    """
    è¯„ä¼°ä¸åŒè¡Œä¸šçš„ä¾›åº”é“¾æ¢å¤èƒ½åŠ›

    è®¡ç®—åŸç†è¯´æ˜ï¼š
    - éå†æ‰€æœ‰åŒ…å«ä¸­å›½èŠ‚ç‚¹çš„ä¾›åº”é“¾é“¾è·¯ï¼Œæå–æ¯ä¸€å¯¹ç›¸é‚»çš„ä¾›åº”å…³ç³»ï¼ˆå³é“¾è·¯ä¸­çš„å‰åä¸¤ä¸ªå…³ç³»ï¼‰ã€‚
    - å¯¹äºæ¯ä¸€å¯¹ç›¸é‚»å…³ç³»ï¼Œåˆ¤æ–­å‰ä¸€ä¸ªå…³ç³»çš„çŠ¶æ€ï¼ˆpermanent_break æˆ– transferï¼‰ï¼Œå¹¶ç»Ÿè®¡å…¶åç´§è·Ÿç€ recovery çŠ¶æ€çš„æ¬¡æ•°ã€‚
    - é’ˆå¯¹æ¯ä¸ªè¡Œä¸šä»£ç ï¼ˆindustry_codeï¼‰ï¼Œç´¯è®¡ï¼š
        - total_breaks: æ–­è£‚ï¼ˆpermanent_breakï¼‰æ¬¡æ•°
        - total_transfers: è½¬ç§»ï¼ˆtransferï¼‰æ¬¡æ•°
        - break_to_recovery: æ–­è£‚åç´§è·Ÿæ¢å¤çš„æ¬¡æ•°
        - transfer_to_recovery: è½¬ç§»åç´§è·Ÿæ¢å¤çš„æ¬¡æ•°
    - æ¢å¤æˆåŠŸç‡ï¼ˆrecovery_success_rateï¼‰= (break_to_recovery + transfer_to_recovery) / (total_breaks + total_transfers)
        è¡¨ç¤ºè¡Œä¸šåœ¨å‘ç”Ÿæ–­è£‚æˆ–è½¬ç§»åèƒ½å¤Ÿæ¢å¤çš„æ¯”ä¾‹ã€‚

    å‘ˆç°å†…å®¹è¯´æ˜ï¼š
    - è¿”å›å€¼ä¸º industry_resilience å­—å…¸ï¼Œé”®ä¸ºè¡Œä¸šä»£ç ï¼Œå€¼ä¸ºè¯¥è¡Œä¸šçš„æ¢å¤èƒ½åŠ›æŒ‡æ ‡ï¼ˆæ–­è£‚/è½¬ç§»æ¬¡æ•°ã€æ¢å¤æ¬¡æ•°ã€æ¢å¤æˆåŠŸç‡ï¼‰ã€‚
    - å¯ç”¨äºæ¯”è¾ƒä¸åŒè¡Œä¸šåœ¨ä¾›åº”é“¾ä¸­æ–­åæ¢å¤çš„èƒ½åŠ›ï¼Œè¯†åˆ«éŸ§æ€§è¾ƒå¼ºæˆ–è¾ƒå¼±çš„è¡Œä¸šã€‚
    """
    industry_resilience = defaultdict(lambda: {
        'break_to_recovery': 0,
        'transfer_to_recovery': 0,
        'total_breaks': 0,
        'total_transfers': 0,
        'recovery_success_rate': 0
    })
    
    for chain in supply_chains_contains_cn_node:
        supply_relations = [rel for rel in chain if isinstance(rel, SupplyRelation)]
        
        # åˆ†æçŠ¶æ€è½¬æ¢æ¨¡å¼
        for i in range(len(supply_relations) - 1):
            current_rel = supply_relations[i]
            next_rel = supply_relations[i + 1]
            
            if (current_rel.industry_codes and current_rel.industry_codes != 'Line_Not_Found' and
                current_rel.industry_codes is not None):
                
                for industry_code in current_rel.industry_codes:
                    if current_rel.status == 'permanent_break':
                        industry_resilience[industry_code]['total_breaks'] += 1
                        if next_rel.status == 'recovery':
                            industry_resilience[industry_code]['break_to_recovery'] += 1
                    elif current_rel.status == 'transfer':
                        industry_resilience[industry_code]['total_transfers'] += 1
                        if next_rel.status == 'recovery':
                            industry_resilience[industry_code]['transfer_to_recovery'] += 1
    
    # è®¡ç®—æ¢å¤æˆåŠŸç‡
    for industry, metrics in industry_resilience.items():
        total_disruptions = metrics['total_breaks'] + metrics['total_transfers']
        total_recoveries = metrics['break_to_recovery'] + metrics['transfer_to_recovery']
        
        if total_disruptions > 0:
            metrics['recovery_success_rate'] = total_recoveries / total_disruptions
    
    return industry_resilience



def generate_comprehensive_industry_report(supply_chains_contains_cn_node, company_to_country):
    """
    ç”Ÿæˆç»¼åˆè¡Œä¸šåˆ†ææŠ¥å‘Š
    """
    print("=== ä¾›åº”é“¾è¡Œä¸šå±æ€§ç»¼åˆåˆ†ææŠ¥å‘Š ===\n")
    
    # 1. è¡Œä¸šè„†å¼±æ€§åˆ†æ
    vulnerability_result = analyze_industry_vulnerability(supply_chains_contains_cn_node,'sequential')
    vulnerability, excluded_industries = vulnerability_result
    
    # 1.1 æŒ‰æ–­è£‚ç‡æ’å
    print("1.1 è¡Œä¸šè„†å¼±æ€§æ’åï¼ˆæŒ‰æ–­è£‚ç‡æ’åºï¼‰:")
    sorted_by_break_rate = sorted(vulnerability.items(), key=lambda x: x[1]['break_rate'], reverse=True)
    for i, (industry, metrics) in enumerate(sorted_by_break_rate[:10]):
        print(f"   {i+1}. è¡Œä¸š{industry}: æ–­è£‚ç‡{metrics['break_rate']:.2%}, æ¶‰åŠæ–­è£‚é“¾æ•°{metrics['total_break_chains']}")
    
    # 1.2 æŒ‰è½¬ç§»æ•°é‡æ’å
    print("\n1.2 è¡Œä¸šè„†å¼±æ€§æ’åï¼ˆæŒ‰è½¬ç§»æ•°é‡æ’åºï¼‰:")
    sorted_by_transfer_count = sorted(vulnerability.items(), key=lambda x: x[1]['total_transfer_chains'], reverse=True)
    for i, (industry, metrics) in enumerate(sorted_by_transfer_count[:10]):
        print(f"   {i+1}. è¡Œä¸š{industry}: è½¬ç§»æ•°é‡{metrics['total_transfer_chains']}, è½¬ç§»ç‡{metrics['transfer_rate']:.2%}")
    
    # 2. è¡Œä¸šæ¢å¤èƒ½åŠ›åˆ†æï¼ˆä¿®æ”¹ä¸ºæŒ‰ç»å¯¹æ•°é‡æ’åï¼‰
    resilience = analyze_industry_resilience(supply_chains_contains_cn_node)
    print("\n2. è¡Œä¸šæ¢å¤èƒ½åŠ›æ’åï¼ˆæŒ‰æ¢å¤ç»å¯¹æ•°é‡æ’åºï¼‰:")
    
    # è®¡ç®—æ¯ä¸ªè¡Œä¸šçš„æ€»æ¢å¤æ•°é‡ï¼ˆæ–­è£‚åæ¢å¤ + è½¬ç§»åæ¢å¤ï¼‰
    resilience_with_total = {}
    for industry, metrics in resilience.items():
        total_recoveries = metrics['break_to_recovery'] + metrics['transfer_to_recovery']
        resilience_with_total[industry] = {
            **metrics,
            'total_recoveries': total_recoveries
        }
    
    # æŒ‰æ€»æ¢å¤æ•°é‡æ’åº
    sorted_resilience = sorted(resilience_with_total.items(), 
                              key=lambda x: x[1]['total_recoveries'], reverse=True)
    
    for i, (industry, metrics) in enumerate(sorted_resilience[:10]):
        print(f"   {i+1}. è¡Œä¸š{industry}: æ€»æ¢å¤æ•°é‡{metrics['total_recoveries']}æ¬¡ "
              f"(æ–­è£‚åæ¢å¤{metrics['break_to_recovery']}æ¬¡ + è½¬ç§»åæ¢å¤{metrics['transfer_to_recovery']}æ¬¡), "
              f"æ¢å¤æˆåŠŸç‡{metrics['recovery_success_rate']:.2%}")
    
    # 3. è¡Œä¸šé›†ä¸­åº¦åˆ†æ
    concentration = analyze_industry_concentration(supply_chains_contains_cn_node)
    print("\n3. è¡Œä¸šé›†ä¸­åº¦åˆ†æ:")
    sorted_concentration = sorted(concentration.items(), key=lambda x: x[1]['concentration_ratio'], reverse=True)
    for i, (industry, metrics) in enumerate(sorted_concentration[:10]):
        print(f"   {i+1}. è¡Œä¸š{industry}: é›†ä¸­åº¦{metrics['concentration_ratio']:.2f}, ä¼ä¸šæ•°{metrics['unique_companies']}")
    
    # 4. æ—¶é—´åŠ¨æ€åˆ†æ
    temporal = analyze_industry_temporal_dynamics(supply_chains_contains_cn_node)
    print("\n4. é‡ç‚¹è¡Œä¸šæ—¶é—´åŠ¨æ€ï¼ˆ2020-2023å¹´æ–­è£‚è¶‹åŠ¿ï¼‰:")
    
    # 5. åœ°ç†è½¬ç§»åˆ†æ - æ–°å¢
    geography = analyze_industry_geography(supply_chains_contains_cn_node, company_to_country)
    
    return {
        'vulnerability': vulnerability,
        'excluded_industries': excluded_industries,
        'resilience': resilience_with_total,  # è¿”å›åŒ…å«æ€»æ¢å¤æ•°é‡çš„æ•°æ®
        'concentration': concentration,
        'temporal': temporal,
        'geography': geography,  # æ–°å¢åœ°ç†åˆ†æç»“æœ
        'sorted_by_break_rate': sorted_by_break_rate,
        'sorted_by_transfer_count': sorted_by_transfer_count,
        'sorted_resilience': sorted_resilience  # æ–°å¢ï¼šæŒ‰ç»å¯¹æ•°é‡æ’åºçš„æ¢å¤èƒ½åŠ›æ•°æ®
    }


# æ‰§è¡Œç»¼åˆåˆ†æ
comprehensive_report = generate_comprehensive_industry_report(supply_chains_contains_cn_node, company_to_country)

def get_industry_description(industry_code, industry_mapping):
    """
    æ ¹æ®è¡Œä¸šä»£ç è·å–è¡Œä¸šæè¿°
    
    å‚æ•°è¯´æ˜ï¼š
    - industry_code: è¡Œä¸šä»£ç 
    - industry_mapping: è¡Œä¸šä»£ç æ˜ å°„å­—å…¸
    
    è¿”å›å€¼ï¼š
    - è¡Œä¸šæè¿°å­—ç¬¦ä¸²ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å›"æœªçŸ¥è¡Œä¸š"
    """
    return industry_mapping.get(str(industry_code), f"æœªçŸ¥è¡Œä¸š(ä»£ç :{industry_code})")

# è¯¦ç»†å±•ç¤ºæ–­è£‚ç‡æœ€é«˜çš„å‰50ä¸ªè¡Œä¸šä»£ç 
if comprehensive_report.get('sorted_by_break_rate'):
    print("\n=== æ–­è£‚ç‡æœ€é«˜çš„å‰50ä¸ªè¡Œä¸šä»£ç  ===")
    for i, (industry_code, metrics) in enumerate(comprehensive_report['sorted_by_break_rate'][:50], 1):
        industry_desc = get_industry_description(industry_code, industry_mapping)
        print(f"{i:2d}. è¡Œä¸šä»£ç : {industry_code:>8} ({industry_desc})")
        print(f"    æ–­è£‚ç‡: {metrics['break_rate']:>6.2%}, æ¶‰åŠæ–­è£‚é“¾æ•°: {metrics['total_break_chains']:>8}")
else:
    print("æ²¡æœ‰å¯ç”¨çš„æ–­è£‚ç‡æ•°æ®ã€‚")

# è¯¦ç»†å±•ç¤ºè½¬ç§»æ•°é‡æœ€é«˜çš„å‰50ä¸ªè¡Œä¸šä»£ç  - ä¿®æ”¹ï¼šæ›´æ–°å˜é‡åå’Œæ˜¾ç¤ºå†…å®¹
if comprehensive_report.get('sorted_by_transfer_count'):
    print("\n=== è½¬ç§»æ•°é‡æœ€é«˜çš„å‰50ä¸ªè¡Œä¸šä»£ç  ===")
    for i, (industry_code, metrics) in enumerate(comprehensive_report['sorted_by_transfer_count'][:50], 1):
        industry_desc = get_industry_description(industry_code, industry_mapping)
        print(f"{i:2d}. è¡Œä¸šä»£ç : {industry_code:>8} ({industry_desc})")
        print(f"    è½¬ç§»æ•°é‡: {metrics['total_transfer_chains']:>8}, è½¬ç§»ç‡: {metrics['transfer_rate']:>6.2%}")
else:
    print("æ²¡æœ‰å¯ç”¨çš„è½¬ç§»æ•°é‡æ•°æ®ã€‚")

# å¯¹æ¯”åˆ†æï¼šæ‰¾å‡ºæ–­è£‚ç‡å’Œè½¬ç§»æ•°é‡éƒ½é«˜çš„è¡Œä¸š - ä¿®æ”¹ï¼šæ›´æ–°å˜é‡å
print("\n=== æ–­è£‚ç‡å’Œè½¬ç§»æ•°é‡å‡è¾ƒé«˜çš„è¡Œä¸šï¼ˆå‰20åäº¤é›†åˆ†æï¼‰ ===")
top_break_industries = set([item[0] for item in comprehensive_report['sorted_by_break_rate'][:20]])
top_transfer_industries = set([item[0] for item in comprehensive_report['sorted_by_transfer_count'][:20]])  # æ›´æ–°å˜é‡å
high_risk_industries = top_break_industries & top_transfer_industries

if high_risk_industries:
    print("åŒæ—¶åœ¨æ–­è£‚ç‡å’Œè½¬ç§»æ•°é‡å‰20åçš„è¡Œä¸š:")
    for industry in high_risk_industries:
        metrics = comprehensive_report['vulnerability'][industry]
        industry_desc = get_industry_description(industry, industry_mapping)
        print(f"  è¡Œä¸š{industry} ({industry_desc}): æ–­è£‚ç‡{metrics['break_rate']:.2%}, è½¬ç§»æ•°é‡{metrics['total_transfer_chains']}")
else:
    print("æ²¡æœ‰è¡Œä¸šåŒæ—¶åœ¨æ–­è£‚ç‡å’Œè½¬ç§»æ•°é‡å‰20åä¸­ã€‚")

# è¯¦ç»†å±•ç¤ºåœ°ç†è½¬ç§»åˆ†æç»“æœ
print("\n" + "="*80)
print("=== ä¾›åº”é“¾è½¬ç§»åœ°ç†åˆ†æè¯¦ç»†æŠ¥å‘Š ===")
print("="*80)

geography_data = comprehensive_report.get('geography')
if geography_data:
    # æ£€æŸ¥å®é™…çš„æ•°æ®ç»“æ„
    print("å¯ç”¨çš„åœ°ç†æ•°æ®é”®:", list(geography_data.keys()))
    
    # æ ¹æ®å®é™…çš„æ•°æ®ç»“æ„æ¥è®¿é—®æ•°æ®
    to_china_data = geography_data.get('to_china_analysis', {})
    from_china_data = geography_data.get('from_china_analysis', {})
    bilateral_summary = geography_data.get('china_bilateral_summary', {})
    
    # 1. æ€»ä½“ç»Ÿè®¡æ‘˜è¦
    print(f"\nğŸ“Š ä¸­å›½åŒå‘è½¬ç§»æ€»ä½“ç»Ÿè®¡:")
    if bilateral_summary:
        print(f"   è½¬å‘ä¸­å›½çš„è½¬ç§»æ€»æ•°: {bilateral_summary.get('to_china_transfers', 0)}")
        print(f"   ä»ä¸­å›½è½¬å‡ºçš„è½¬ç§»æ€»æ•°: {bilateral_summary.get('from_china_transfers', 0)}")
        print(f"   è½¬å‘/è½¬å‡ºæ¯”ç‡: {bilateral_summary.get('transfer_ratio', 0):.2f}")
        print(f"   æ€»è½¬ç§»é“¾æ•°: {bilateral_summary.get('total_transfer_chains', 0)}")
    
    # 2. è½¬å‘ä¸­å›½çš„è¯¦ç»†åˆ†æ
    print(f"\nğŸ“¥ è½¬å‘ä¸­å›½çš„ä¾›åº”é“¾è½¬ç§»è¯¦ç»†åˆ†æ:")
    if to_china_data and 'sorted_industries' in to_china_data:
        to_china_industries = to_china_data['sorted_industries']
        total_to_china = to_china_data.get('total_transfers', 0)
        
        if to_china_industries:
            print(f"   æ¶‰åŠè¡Œä¸šæ€»æ•°: {len(to_china_industries)}")
            print(f"   è½¬å‘ä¸­å›½è½¬ç§»æ€»æ•°: {total_to_china}")
            print(f"   è½¬å‘ä¸­å›½æœ€å¤šçš„å‰20ä¸ªè¡Œä¸š:")
            
            for i, (industry, data) in enumerate(to_china_industries[:20], 1):
                industry_desc = get_industry_description(industry, industry_mapping)
                pct = data.get('percentage_in_to_china', 0) * 100
                transfer_count = data.get('transfer_count', 0)
                # è·å–ä¸»è¦æ¥æºå›½å®¶åç§°
                main_sources = data.get('main_source_countries', [])
                main_sources_with_names = []
                for country_code in main_sources[:3]:
                    country_name = get_country_name(country_code, country_name_mapping)
                    main_sources_with_names.append(country_name)
                main_sources_str = ', '.join(main_sources_with_names)
                print(f"   {i:2d}. è¡Œä¸š{industry:<8} ({industry_desc}): {transfer_count:>4}æ¬¡ ({pct:>5.1f}%)")
                if main_sources_str:
                    print(f"       ä¸»è¦æ¥æº: {main_sources_str}")
            
            # è½¬å‘ä¸­å›½çš„è¡Œä¸šé›†ä¸­åº¦åˆ†æ
            if len(to_china_industries) >= 5:
                print(f"\nğŸ“ˆ è½¬å‘ä¸­å›½çš„è¡Œä¸šé›†ä¸­åº¦åˆ†æ:")
                top_5_count = sum([data.get('transfer_count', 0) for _, data in to_china_industries[:5]])
                if len(to_china_industries) >= 10:
                    top_10_count = sum([data.get('transfer_count', 0) for _, data in to_china_industries[:10]])
                if len(to_china_industries) >= 20:
                    top_20_count = sum([data.get('transfer_count', 0) for _, data in to_china_industries[:20]])
                
                if total_to_china > 0:
                    print(f"   å‰5ä¸ªè¡Œä¸šå è½¬å‘ä¸­å›½æ€»é‡çš„æ¯”ä¾‹: {top_5_count/total_to_china:.2%}")
                    if len(to_china_industries) >= 10:
                        print(f"   å‰10ä¸ªè¡Œä¸šå è½¬å‘ä¸­å›½æ€»é‡çš„æ¯”ä¾‹: {top_10_count/total_to_china:.2%}")
                    if len(to_china_industries) >= 20:
                        print(f"   å‰20ä¸ªè¡Œä¸šå è½¬å‘ä¸­å›½æ€»é‡çš„æ¯”ä¾‹: {top_20_count/total_to_china:.2%}")
        else:
            print("   æ²¡æœ‰å‘ç°è½¬å‘ä¸­å›½çš„ä¾›åº”é“¾è½¬ç§»")
    else:
        print("   è½¬å‘ä¸­å›½çš„æ•°æ®ä¸å¯ç”¨")
    
    # 3. ä»ä¸­å›½è½¬å‡ºçš„è¯¦ç»†åˆ†æ
    print(f"\nğŸ“¤ ä»ä¸­å›½è½¬å‡ºçš„ä¾›åº”é“¾è½¬ç§»è¯¦ç»†åˆ†æ:")
    if from_china_data and 'sorted_industries' in from_china_data:
        from_china_industries = from_china_data['sorted_industries']
        total_from_china = from_china_data.get('total_transfers', 0)
        
        if from_china_industries:
            print(f"   æ¶‰åŠè¡Œä¸šæ€»æ•°: {len(from_china_industries)}")
            print(f"   ä»ä¸­å›½è½¬å‡ºè½¬ç§»æ€»æ•°: {total_from_china}")
            print(f"   ä»ä¸­å›½è½¬å‡ºæœ€å¤šçš„å‰20ä¸ªè¡Œä¸š:")
            
            for i, (industry, data) in enumerate(from_china_industries[:20], 1):
                industry_desc = get_industry_description(industry, industry_mapping)
                pct = data.get('percentage_in_from_china', 0) * 100
                transfer_count = data.get('transfer_count', 0)
                # è·å–ä¸»è¦ç›®æ ‡å›½å®¶åç§°
                main_targets = data.get('main_target_countries', [])
                main_targets_with_names = []
                for country_code in main_targets[:3]:
                    country_name = get_country_name(country_code, country_name_mapping)
                    main_targets_with_names.append(country_name)
                main_targets_str = ', '.join(main_targets_with_names)
                print(f"   {i:2d}. è¡Œä¸š{industry:<8} ({industry_desc}): {transfer_count:>4}æ¬¡ ({pct:>5.1f}%)")
                if main_targets_str:
                    print(f"       ä¸»è¦ç›®æ ‡: {main_targets_str}")
            
            # ä»ä¸­å›½è½¬å‡ºçš„è¡Œä¸šé›†ä¸­åº¦åˆ†æ
            if len(from_china_industries) >= 5:
                print(f"\nğŸ“ˆ ä»ä¸­å›½è½¬å‡ºçš„è¡Œä¸šé›†ä¸­åº¦åˆ†æ:")
                top_5_count = sum([data.get('transfer_count', 0) for _, data in from_china_industries[:5]])
                if len(from_china_industries) >= 10:
                    top_10_count = sum([data.get('transfer_count', 0) for _, data in from_china_industries[:10]])
                if len(from_china_industries) >= 20:
                    top_20_count = sum([data.get('transfer_count', 0) for _, data in from_china_industries[:20]])
                
                if total_from_china > 0:
                    print(f"   å‰5ä¸ªè¡Œä¸šå ä»ä¸­å›½è½¬å‡ºæ€»é‡çš„æ¯”ä¾‹: {top_5_count/total_from_china:.2%}")
                    if len(from_china_industries) >= 10:
                        print(f"   å‰10ä¸ªè¡Œä¸šå ä»ä¸­å›½è½¬å‡ºæ€»é‡çš„æ¯”ä¾‹: {top_10_count/total_from_china:.2%}")
                    if len(from_china_industries) >= 20:
                        print(f"   å‰20ä¸ªè¡Œä¸šå ä»ä¸­å›½è½¬å‡ºæ€»é‡çš„æ¯”ä¾‹: {top_20_count/total_from_china:.2%}")
        else:
            print("   æ²¡æœ‰å‘ç°ä»ä¸­å›½è½¬å‡ºçš„ä¾›åº”é“¾è½¬ç§»")
    else:
        print("   ä»ä¸­å›½è½¬å‡ºçš„æ•°æ®ä¸å¯ç”¨")
    
    # 4. é‡ç‚¹è¡Œä¸šçš„å›½å®¶åˆ†å¸ƒåˆ†æ
    if (to_china_data and 'sorted_industries' in to_china_data and 
        from_china_data and 'sorted_industries' in from_china_data):
        
        to_china_industries = to_china_data['sorted_industries']
        from_china_industries = from_china_data['sorted_industries']
        
        if to_china_industries and from_china_industries:
            print(f"\nğŸ” é‡ç‚¹è¡Œä¸šçš„å›½å®¶åˆ†å¸ƒè¯¦ç»†åˆ†æ:")
            
            # é€‰æ‹©è½¬å‘ä¸­å›½æœ€å¤šçš„å‰5ä¸ªè¡Œä¸š
            print(f"\n   ğŸ“¥ è½¬å‘ä¸­å›½æœ€å¤šçš„å‰5ä¸ªè¡Œä¸šçš„æ¥æºå›½å®¶åˆ†å¸ƒ:")
            for i, (industry, data) in enumerate(to_china_industries[:5], 1):
                industry_desc = get_industry_description(industry, industry_mapping)
                transfer_count = data.get('transfer_count', 0)
                source_distribution = data.get('source_distribution', {})
                
                print(f"   {i}. è¡Œä¸š{industry} ({industry_desc}) (è½¬å‘ä¸­å›½: {transfer_count}æ¬¡):")
                if source_distribution:
                    sorted_sources = sorted(source_distribution.items(), 
                                          key=lambda x: x[1], reverse=True)
                    for j, (country, count) in enumerate(sorted_sources[:5], 1):
                        country_name = get_country_name(country, country_name_mapping)
                        pct = count / transfer_count * 100 if transfer_count > 0 else 0
                        print(f"      {j}. {country_name}: {count}æ¬¡ ({pct:.1f}%)")
                else:
                    print(f"      æ— è¯¦ç»†æ¥æºå›½å®¶æ•°æ®")
            
            # é€‰æ‹©ä»ä¸­å›½è½¬å‡ºæœ€å¤šçš„å‰5ä¸ªè¡Œä¸š
            print(f"\n   ğŸ“¤ ä»ä¸­å›½è½¬å‡ºæœ€å¤šçš„å‰5ä¸ªè¡Œä¸šçš„ç›®æ ‡å›½å®¶åˆ†å¸ƒ:")
            for i, (industry, data) in enumerate(from_china_industries[:5], 1):
                industry_desc = get_industry_description(industry, industry_mapping)
                transfer_count = data.get('transfer_count', 0)
                target_distribution = data.get('target_distribution', {})
                
                print(f"   {i}. è¡Œä¸š{industry} ({industry_desc}) (ä»ä¸­å›½è½¬å‡º: {transfer_count}æ¬¡):")
                if target_distribution:
                    sorted_targets = sorted(target_distribution.items(), 
                                          key=lambda x: x[1], reverse=True)
                    for j, (country, count) in enumerate(sorted_targets[:5], 1):
                        country_name = get_country_name(country, country_name_mapping)
                        pct = count / transfer_count * 100 if transfer_count > 0 else 0
                        print(f"      {j}. {country_name}: {count}æ¬¡ ({pct:.1f}%)")
                else:
                    print(f"      æ— è¯¦ç»†ç›®æ ‡å›½å®¶æ•°æ®")

else:
    print("æ²¡æœ‰å¯ç”¨çš„åœ°ç†è½¬ç§»åˆ†ææ•°æ®ã€‚")

print("\n" + "="*80)
print("=== ä¾›åº”é“¾è½¬ç§»åœ°ç†åˆ†ææŠ¥å‘Šå®Œæˆ ===")
print("="*80)

# è¯¦ç»†å±•ç¤ºä¸­å›½åŒå‘è½¬ç§»åˆ†æç»“æœ
print("\n" + "="*80)
print("=== ä¸­å›½åŒå‘ä¾›åº”é“¾è½¬ç§»è¯¦ç»†åˆ†ææŠ¥å‘Š ===")
print("="*80)

geography_data = comprehensive_report.get('geography')
if geography_data:
    to_china_data = geography_data['to_china_analysis']
    from_china_data = geography_data['from_china_analysis']
    bilateral_summary = geography_data['china_bilateral_summary']
    
    # 1. æ€»ä½“ç»Ÿè®¡æ‘˜è¦
    print(f"\nğŸ“Š ä¸­å›½åŒå‘è½¬ç§»æ€»ä½“ç»Ÿè®¡:")
    print(f"   è½¬å‘ä¸­å›½çš„è½¬ç§»æ€»æ•°: {bilateral_summary['to_china_transfers']}")
    print(f"   ä»ä¸­å›½è½¬å‡ºçš„è½¬ç§»æ€»æ•°: {bilateral_summary['from_china_transfers']}")
    print(f"   è½¬å‘/è½¬å‡ºæ¯”ç‡: {bilateral_summary['transfer_ratio']:.2f}")
    print(f"   æ€»è½¬ç§»é“¾æ•°: {bilateral_summary['total_transfer_chains']}")
    
    # 2. è½¬å‘ä¸­å›½çš„è¯¦ç»†åˆ†æ
    print(f"\nğŸ“¥ è½¬å‘ä¸­å›½çš„ä¾›åº”é“¾è½¬ç§»è¯¦ç»†åˆ†æ:")
    to_china_industries = to_china_data['sorted_industries']
    if to_china_industries:
        print(f"   æ¶‰åŠè¡Œä¸šæ€»æ•°: {len(to_china_industries)}")
        print(f"   è½¬å‘ä¸­å›½æœ€å¤šçš„å‰20ä¸ªè¡Œä¸š:")
        
        for i, (industry, data) in enumerate(to_china_industries[:20], 1):
            industry_desc = get_industry_description(industry, industry_mapping)
            pct = data['percentage_in_to_china'] * 100
            # è·å–ä¸»è¦æ¥æºå›½å®¶åç§°
            main_sources_with_names = []
            for country_code in data['main_source_countries'][:3]:
                country_name = get_country_name(country_code, country_name_mapping)
                main_sources_with_names.append(country_name)
            main_sources_str = ', '.join(main_sources_with_names)
            print(f"   {i:2d}. è¡Œä¸š{industry:<8} ({industry_desc}): {data['transfer_count']:>4}æ¬¡ ({pct:>5.1f}%)")
            if main_sources_str:
                print(f"       ä¸»è¦æ¥æº: {main_sources_str}")
        
        # è½¬å‘ä¸­å›½çš„è¡Œä¸šé›†ä¸­åº¦åˆ†æ
        if len(to_china_industries) >= 5:
            print(f"\nğŸ“ˆ è½¬å‘ä¸­å›½çš„è¡Œä¸šé›†ä¸­åº¦åˆ†æ:")
            top_5_count = sum([data.get('transfer_count', 0) for _, data in to_china_industries[:5]])
            if len(to_china_industries) >= 10:
                top_10_count = sum([data.get('transfer_count', 0) for _, data in to_china_industries[:10]])
            if len(to_china_industries) >= 20:
                top_20_count = sum([data.get('transfer_count', 0) for _, data in to_china_industries[:20]])
            
            if total_to_china > 0:
                print(f"   å‰5ä¸ªè¡Œä¸šå è½¬å‘ä¸­å›½æ€»é‡çš„æ¯”ä¾‹: {top_5_count/total_to_china:.2%}")
                if len(to_china_industries) >= 10:
                    print(f"   å‰10ä¸ªè¡Œä¸šå è½¬å‘ä¸­å›½æ€»é‡çš„æ¯”ä¾‹: {top_10_count/total_to_china:.2%}")
                if len(to_china_industries) >= 20:
                    print(f"   å‰20ä¸ªè¡Œä¸šå è½¬å‘ä¸­å›½æ€»é‡çš„æ¯”ä¾‹: {top_20_count/total_to_china:.2%}")
    else:
        print("   æ²¡æœ‰å‘ç°è½¬å‘ä¸­å›½çš„ä¾›åº”é“¾è½¬ç§»")
    
    # 3. ä»ä¸­å›½è½¬å‡ºçš„è¯¦ç»†åˆ†æ
    print(f"\nğŸ“¤ ä»ä¸­å›½è½¬å‡ºçš„ä¾›åº”é“¾è½¬ç§»è¯¦ç»†åˆ†æ:")
    from_china_industries = from_china_data['sorted_industries']
    if from_china_industries:
        print(f"   æ¶‰åŠè¡Œä¸šæ€»æ•°: {len(from_china_industries)}")
        print(f"   ä»ä¸­å›½è½¬å‡ºæœ€å¤šçš„å‰20ä¸ªè¡Œä¸š:")
        
        for i, (industry, data) in enumerate(from_china_industries[:20], 1):
            industry_desc = get_industry_description(industry, industry_mapping)
            pct = data['percentage_in_from_china'] * 100
            # è·å–ä¸»è¦ç›®æ ‡å›½å®¶åç§°
            main_targets_with_names = []
            for country_code in data['main_target_countries'][:3]:
                country_name = get_country_name(country_code, country_name_mapping)
                main_targets_with_names.append(country_name)
            main_targets_str = ', '.join(main_targets_with_names)
            print(f"   {i:2d}. è¡Œä¸š{industry:<8} ({industry_desc}): {data['transfer_count']:>4}æ¬¡ ({pct:>5.1f}%)")
            if main_targets_str:
                print(f"       ä¸»è¦ç›®æ ‡: {main_targets_str}")
        
        # ä»ä¸­å›½è½¬å‡ºçš„è¡Œä¸šé›†ä¸­åº¦åˆ†æ
        if len(from_china_industries) >= 5:
            print(f"\nğŸ“ˆ ä»ä¸­å›½è½¬å‡ºçš„è¡Œä¸šé›†ä¸­åº¦åˆ†æ:")
            top_5_count = sum([data.get('transfer_count', 0) for _, data in from_china_industries[:5]])
            if len(from_china_industries) >= 10:
                top_10_count = sum([data.get('transfer_count', 0) for _, data in from_china_industries[:10]])
            if len(from_china_industries) >= 20:
                top_20_count = sum([data.get('transfer_count', 0) for _, data in from_china_industries[:20]])
            
            if total_from_china > 0:
                print(f"   å‰5ä¸ªè¡Œä¸šå ä»ä¸­å›½è½¬å‡ºæ€»é‡çš„æ¯”ä¾‹: {top_5_count/total_from_china:.2%}")
                if len(from_china_industries) >= 10:
                    print(f"   å‰10ä¸ªè¡Œä¸šå ä»ä¸­å›½è½¬å‡ºæ€»é‡çš„æ¯”ä¾‹: {top_10_count/total_from_china:.2%}")
                if len(from_china_industries) >= 20:
                    print(f"   å‰20ä¸ªè¡Œä¸šå ä»ä¸­å›½è½¬å‡ºæ€»é‡çš„æ¯”ä¾‹: {top_20_count/total_from_china:.2%}")
    else:
        print("   æ²¡æœ‰å‘ç°ä»ä¸­å›½è½¬å‡ºçš„ä¾›åº”é“¾è½¬ç§»")
    
    # 4. é‡ç‚¹è¡Œä¸šçš„å›½å®¶åˆ†å¸ƒåˆ†æ
    if to_china_industries and from_china_industries:
        print(f"\nğŸ” é‡ç‚¹è¡Œä¸šçš„å›½å®¶åˆ†å¸ƒè¯¦ç»†åˆ†æ:")
        
        # é€‰æ‹©è½¬å‘ä¸­å›½æœ€å¤šçš„å‰5ä¸ªè¡Œä¸š
        print(f"\n   ğŸ“¥ è½¬å‘ä¸­å›½æœ€å¤šçš„å‰5ä¸ªè¡Œä¸šçš„æ¥æºå›½å®¶åˆ†å¸ƒ:")
        for i, (industry, data) in enumerate(to_china_industries[:5], 1):
            industry_desc = get_industry_description(industry, industry_mapping)
            transfer_count = data.get('transfer_count', 0)
            source_distribution = data.get('source_distribution', {})
            
            print(f"   {i}. è¡Œä¸š{industry} ({industry_desc}) (è½¬å‘ä¸­å›½: {transfer_count}æ¬¡):")
            if source_distribution:
                sorted_sources = sorted(source_distribution.items(), 
                                      key=lambda x: x[1], reverse=True)
                for j, (country, count) in enumerate(sorted_sources[:5], 1):
                    country_name = get_country_name(country, country_name_mapping)
                    pct = count / transfer_count * 100 if transfer_count > 0 else 0
                    print(f"      {j}. {country_name}: {count}æ¬¡ ({pct:.1f}%)")
            else:
                print(f"      æ— è¯¦ç»†æ¥æºå›½å®¶æ•°æ®")
        
        # é€‰æ‹©ä»ä¸­å›½è½¬å‡ºæœ€å¤šçš„å‰5ä¸ªè¡Œä¸š
        print(f"\n   ğŸ“¤ ä»ä¸­å›½è½¬å‡ºæœ€å¤šçš„å‰5ä¸ªè¡Œä¸šçš„ç›®æ ‡å›½å®¶åˆ†å¸ƒ:")
        for i, (industry, data) in enumerate(from_china_industries[:5], 1):
            industry_desc = get_industry_description(industry, industry_mapping)
            transfer_count = data.get('transfer_count', 0)
            target_distribution = data.get('target_distribution', {})
            
            print(f"   {i}. è¡Œä¸š{industry} ({industry_desc}) (ä»ä¸­å›½è½¬å‡º: {transfer_count}æ¬¡):")
            if target_distribution:
                sorted_targets = sorted(target_distribution.items(), 
                                      key=lambda x: x[1], reverse=True)
                for j, (country, count) in enumerate(sorted_targets[:5], 1):
                    country_name = get_country_name(country, country_name_mapping)
                    pct = count / transfer_count * 100 if transfer_count > 0 else 0
                    print(f"      {j}. {country_name}: {count}æ¬¡ ({pct:.1f}%)")
            else:
                print(f"      æ— è¯¦ç»†ç›®æ ‡å›½å®¶æ•°æ®")

else:
    print("æ²¡æœ‰å¯ç”¨çš„ä¸­å›½åŒå‘è½¬ç§»åˆ†ææ•°æ®ã€‚")

print("\n" + "="*80)
print("=== ä¸­å›½åŒå‘ä¾›åº”é“¾è½¬ç§»åˆ†ææŠ¥å‘Šå®Œæˆ ===")
print("="*80)


def analyze_industry_temporal_transfer_trends_academic(supply_chains_contains_cn_node, company_to_country, industry_mapping, country_name_mapping):
    """
    ä¾›åº”é“¾è½¬ç§»æ—¶é—´è¶‹åŠ¿çš„å­¦æœ¯åˆ†æ
    
    è¿”å›é€‚åˆç»æµå­¦/ç»Ÿè®¡å­¦è®ºæ–‡çš„ç»“æ„åŒ–æ•°æ®ï¼ŒåŒ…æ‹¬ï¼š
    1. æè¿°æ€§ç»Ÿè®¡
    2. è¶‹åŠ¿åˆ†ææŒ‡æ ‡
    3. é›†ä¸­åº¦æµ‹é‡
    4. ç»“æ„å˜åŒ–æ£€éªŒæ•°æ®
    """
    
    # å®šä¹‰ä¸­å›½åœ°åŒºä»£ç 
    china_codes = {'CN', 'HK', 'MO', 'China', 'Hong Kong', 'Macau'}
    
    # å®šä¹‰æ— æ•ˆå›½å®¶ä»£ç é›†åˆ
    invalid_countries = {
        'Unknown_Empty', 'Unknown_None', 'Unknown', 'Nation_Not_Found', 
        '', None, 'null', 'NULL', 'N/A', 'na', 'NA'
    }
    
    # æ•°æ®æ”¶é›†ç»“æ„
    yearly_data = defaultdict(lambda: {
        'to_china': defaultdict(lambda: defaultdict(int)),    # [year][industry][country] = count
        'from_china': defaultdict(lambda: defaultdict(int)),  # [year][industry][country] = count
        'total_transfers': 0,
        'to_china_total': 0,
        'from_china_total': 0
    })
    
    # æ•°æ®æ”¶é›†
    for chain in supply_chains_contains_cn_node:
        for rel in chain:
            if isinstance(rel, SupplyRelation) and rel.status == 'transfer':
                year = rel.start.year if rel.start else None
                if not year:
                    continue
                
                # è·å–å›½å®¶ä¿¡æ¯
                from_countries = company_to_country.get(rel.from_co.id, (['Unknown'], ['Unknown']))[1]
                to_countries = company_to_country.get(rel.to_co.id, (['Unknown'], ['Unknown']))[1]
                
                # æ¸…ç†å›½å®¶ä»£ç 
                cleaned_from = [c.strip() for c in from_countries if c and str(c).strip() not in invalid_countries]
                cleaned_to = [c.strip() for c in to_countries if c and str(c).strip() not in invalid_countries]
                
                if not cleaned_from or not cleaned_to:
                    continue
                
                # åˆ¤æ–­è½¬ç§»æ–¹å‘
                from_is_china = any(c in china_codes for c in cleaned_from)
                to_is_china = any(c in china_codes for c in cleaned_to)
                
                if rel.industry_codes and rel.industry_codes != 'Line_Not_Found':
                    yearly_data[year]['total_transfers'] += 1
                    
                    for industry in rel.industry_codes:
                        if to_is_china and not from_is_china:  # è½¬å‘ä¸­å›½
                            yearly_data[year]['to_china_total'] += 1
                            for country in cleaned_from:
                                yearly_data[year]['to_china'][industry][country] += 1
                        elif from_is_china and not to_is_china:  # ä»ä¸­å›½è½¬å‡º
                            yearly_data[year]['from_china_total'] += 1
                            for country in cleaned_to:
                                yearly_data[year]['from_china'][industry][country] += 1
    
    # æ„å»ºå­¦æœ¯åˆ†æç»“æœ
    academic_results = {
        'summary_statistics': {},
        'temporal_trends': {},
        'industry_concentration': {},
        'geographic_concentration': {},
        'market_share_evolution': {},
        'structural_change_indicators': {},
        'regression_ready_data': []
    }
    
    # 1. æè¿°æ€§ç»Ÿè®¡
    years = sorted(yearly_data.keys())
    academic_results['summary_statistics'] = {
        'observation_period': {'start': min(years), 'end': max(years), 'span': max(years) - min(years) + 1},
        'yearly_totals': {
            year: {
                'total_transfers': data['total_transfers'],
                'to_china_transfers': data['to_china_total'],
                'from_china_transfers': data['from_china_total'],
                'china_transfer_ratio': data['to_china_total'] / data['total_transfers'] if data['total_transfers'] > 0 else 0,
                'china_net_inflow': data['to_china_total'] - data['from_china_total']
            }
            for year, data in yearly_data.items()
        }
    }
    
    # 2. æ—¶é—´è¶‹åŠ¿åˆ†æ
    def calculate_trend_statistics(series_data):
        """è®¡ç®—æ—¶é—´åºåˆ—çš„è¶‹åŠ¿ç»Ÿè®¡"""
        if len(series_data) < 2:
            return {'trend': 0, 'volatility': 0, 'growth_rate': 0}
        
        values = list(series_data.values())
        years_list = list(series_data.keys())
        
        # çº¿æ€§è¶‹åŠ¿ (ç®€å•æ–œç‡)
        n = len(values)
        sum_x = sum(range(n))
        sum_y = sum(values)
        sum_xy = sum(i * values[i] for i in range(n))
        sum_x2 = sum(i**2 for i in range(n))
        
        trend = (n * sum_xy - sum_x * sum_y) / (n * sum_x2 - sum_x**2) if (n * sum_x2 - sum_x**2) != 0 else 0
        
        # å˜å¼‚ç³»æ•°
        mean_val = sum(values) / len(values)
        variance = sum((v - mean_val)**2 for v in values) / len(values)
        volatility = (variance**0.5) / mean_val if mean_val > 0 else 0
        
        # å¤åˆå¢é•¿ç‡
        if values[0] > 0 and values[-1] > 0:
            growth_rate = (values[-1] / values[0]) ** (1 / (len(values) - 1)) - 1
        else:
            growth_rate = 0
        
        return {
            'trend_slope': trend,
            'volatility_cv': volatility,
            'cagr': growth_rate,
            'total_change': values[-1] - values[0],
            'relative_change': (values[-1] - values[0]) / values[0] if values[0] > 0 else 0
        }
    
    # è®¡ç®—å„ç§æ—¶é—´åºåˆ—çš„è¶‹åŠ¿
    to_china_series = {year: data['to_china_total'] for year, data in yearly_data.items()}
    from_china_series = {year: data['from_china_total'] for year, data in yearly_data.items()}
    total_series = {year: data['total_transfers'] for year, data in yearly_data.items()}
    
    academic_results['temporal_trends'] = {
        'to_china_trends': calculate_trend_statistics(to_china_series),
        'from_china_trends': calculate_trend_statistics(from_china_series),
        'total_transfer_trends': calculate_trend_statistics(total_series),
        'china_share_evolution': {
            year: data['to_china_total'] / data['total_transfers'] if data['total_transfers'] > 0 else 0
            for year, data in yearly_data.items()
        }
    }
    
    # 3. è¡Œä¸šé›†ä¸­åº¦åˆ†æ (HHIæŒ‡æ•°)
    def calculate_hhi(distribution):
        """è®¡ç®—èµ«èŠ¬è¾¾å°”-èµ«å¸Œæ›¼æŒ‡æ•°"""
        total = sum(distribution.values())
        if total == 0:
            return 0
        shares = [count / total for count in distribution.values()]
        return sum(share**2 for share in shares)
    
    academic_results['industry_concentration'] = {}
    for year, data in yearly_data.items():
        # è½¬å‘ä¸­å›½çš„è¡Œä¸šé›†ä¸­åº¦
        to_china_industry_dist = defaultdict(int)
        for industry, countries in data['to_china'].items():
            to_china_industry_dist[industry] = sum(countries.values())
        
        # ä»ä¸­å›½è½¬å‡ºçš„è¡Œä¸šé›†ä¸­åº¦
        from_china_industry_dist = defaultdict(int)
        for industry, countries in data['from_china'].items():
            from_china_industry_dist[industry] = sum(countries.values())
        
        academic_results['industry_concentration'][year] = {
            'to_china_hhi': calculate_hhi(to_china_industry_dist),
            'from_china_hhi': calculate_hhi(from_china_industry_dist),
            'to_china_top5_share': sum(sorted(to_china_industry_dist.values(), reverse=True)[:5]) / sum(to_china_industry_dist.values()) if to_china_industry_dist else 0,
            'from_china_top5_share': sum(sorted(from_china_industry_dist.values(), reverse=True)[:5]) / sum(from_china_industry_dist.values()) if from_china_industry_dist else 0,
            'to_china_industry_count': len(to_china_industry_dist),
            'from_china_industry_count': len(from_china_industry_dist)
        }
    
    # 4. åœ°ç†é›†ä¸­åº¦åˆ†æ
    academic_results['geographic_concentration'] = {}
    for year, data in yearly_data.items():
        # è½¬å‘ä¸­å›½çš„åœ°ç†åˆ†å¸ƒ
        to_china_geo_dist = defaultdict(int)
        for industry, countries in data['to_china'].items():
            for country, count in countries.items():
                to_china_geo_dist[country] += count
        
        # ä»ä¸­å›½è½¬å‡ºçš„åœ°ç†åˆ†å¸ƒ
        from_china_geo_dist = defaultdict(int)
        for industry, countries in data['from_china'].items():
            for country, count in countries.items():
                from_china_geo_dist[country] += count
        
        academic_results['geographic_concentration'][year] = {
            'to_china_geo_hhi': calculate_hhi(to_china_geo_dist),
            'from_china_geo_hhi': calculate_hhi(from_china_geo_dist),
            'to_china_country_count': len(to_china_geo_dist),
            'from_china_country_count': len(from_china_geo_dist),
            'to_china_top3_countries': sorted(to_china_geo_dist.items(), key=lambda x: x[1], reverse=True)[:3],
            'from_china_top3_countries': sorted(from_china_geo_dist.items(), key=lambda x: x[1], reverse=True)[:3]
        }
    
    # 5. å¸‚åœºä»½é¢æ¼”åŒ– (é‡ç‚¹è¡Œä¸š)
    # æ‰¾å‡ºè½¬ç§»æ€»é‡æœ€å¤§çš„å‰10ä¸ªè¡Œä¸š
    industry_totals = defaultdict(int)
    for year_data in yearly_data.values():
        for industry, countries in year_data['to_china'].items():
            industry_totals[industry] += sum(countries.values())
        for industry, countries in year_data['from_china'].items():
            industry_totals[industry] += sum(countries.values())
    
    top_industries = sorted(industry_totals.items(), key=lambda x: x[1], reverse=True)[:10]
    
    academic_results['market_share_evolution'] = {}
    for industry, _ in top_industries:
        industry_name = industry_mapping.get(str(industry), f"Industry_{industry}")
        academic_results['market_share_evolution'][industry] = {
            'industry_name': industry_name,
            'yearly_performance': {}
        }
        
        for year in years:
            to_china_count = sum(yearly_data[year]['to_china'][industry].values())
            from_china_count = sum(yearly_data[year]['from_china'][industry].values())
            total_year_to_china = yearly_data[year]['to_china_total']
            total_year_from_china = yearly_data[year]['from_china_total']
            
            academic_results['market_share_evolution'][industry]['yearly_performance'][year] = {
                'to_china_count': to_china_count,
                'from_china_count': from_china_count,
                'to_china_share': to_china_count / total_year_to_china if total_year_to_china > 0 else 0,
                'from_china_share': from_china_count / total_year_from_china if total_year_from_china > 0 else 0,
                'net_flow': to_china_count - from_china_count
            }
    
    # 6. ç»“æ„å˜åŒ–æŒ‡æ ‡
    def calculate_structural_change(data_series):
        """è®¡ç®—ç»“æ„å˜åŒ–æŒ‡æ ‡"""
        if len(data_series) < 2:
            return {'structural_break_indicator': 0, 'coefficient_of_variation': 0}
        
        values = list(data_series.values())
        
        # å˜å¼‚ç³»æ•°
        mean_val = sum(values) / len(values)
        cv = (sum((v - mean_val)**2 for v in values) / len(values))**0.5 / mean_val if mean_val > 0 else 0
        
        # ç®€å•çš„ç»“æ„æ–­ç‚¹æŒ‡æ ‡ï¼ˆå‰ååŠæœŸå‡å€¼å·®å¼‚ï¼‰
        mid_point = len(values) // 2
        first_half_mean = sum(values[:mid_point]) / mid_point if mid_point > 0 else 0
        second_half_mean = sum(values[mid_point:]) / (len(values) - mid_point) if len(values) > mid_point else 0
        structural_break = abs(second_half_mean - first_half_mean) / first_half_mean if first_half_mean > 0 else 0
        
        return {
            'structural_break_indicator': structural_break,
            'coefficient_of_variation': cv,
            'first_half_mean': first_half_mean,
            'second_half_mean': second_half_mean
        }
    
    academic_results['structural_change_indicators'] = {
        'to_china_structural_change': calculate_structural_change(to_china_series),
        'from_china_structural_change': calculate_structural_change(from_china_series),
        'china_share_structural_change': calculate_structural_change(academic_results['temporal_trends']['china_share_evolution'])
    }
    
    # 7. å›å½’åˆ†æå‡†å¤‡æ•°æ®
    for year in years:
        year_data = yearly_data[year]
        academic_results['regression_ready_data'].append({
            'year': year,
            'to_china_transfers': year_data['to_china_total'],
            'from_china_transfers': year_data['from_china_total'],
            'total_transfers': year_data['total_transfers'],
            'china_share': year_data['to_china_total'] / year_data['total_transfers'] if year_data['total_transfers'] > 0 else 0,
            'net_china_flow': year_data['to_china_total'] - year_data['from_china_total'],
            'to_china_hhi': academic_results['industry_concentration'][year]['to_china_hhi'],
            'from_china_hhi': academic_results['industry_concentration'][year]['from_china_hhi'],
            'geo_to_china_hhi': academic_results['geographic_concentration'][year]['to_china_geo_hhi'],
            'geo_from_china_hhi': academic_results['geographic_concentration'][year]['from_china_geo_hhi']
        })
    
    return academic_results

def export_academic_results_to_tables(academic_results, output_path=".\è°ƒç”¨æ–‡ä»¶\ç”¨äºè¡Œä¸šåˆ†ç±»åˆ†æçš„å¯è§†åŒ–è¡¨\å­¦æœ¯æŠ¥å‘Šå›¾è¡¨"):
    """
    å°†å­¦æœ¯åˆ†æç»“æœå¯¼å‡ºä¸ºé€‚åˆè®ºæ–‡çš„è¡¨æ ¼æ ¼å¼
    """
    import pandas as pd
    import os
    
    if not os.path.exists(output_path):
        os.makedirs(output_path)
    
    # è¡¨1: æè¿°æ€§ç»Ÿè®¡æ±‡æ€»è¡¨
    summary_data = []
    for year, stats in academic_results['summary_statistics']['yearly_totals'].items():
        summary_data.append({
            'Year': year,
            'Total Transfers': stats['total_transfers'],
            'To China': stats['to_china_transfers'],
            'From China': stats['from_china_transfers'],
            'China Share (%)': stats['china_transfer_ratio'] * 100,
            'Net China Inflow': stats['china_net_inflow']
        })
    
    df_summary = pd.DataFrame(summary_data)
    df_summary.to_csv(f"{output_path}/table1_descriptive_statistics.csv", index=False)
    
    # è¡¨2: æ—¶é—´è¶‹åŠ¿åˆ†æ
    trends = academic_results['temporal_trends']
    trend_data = {
        'Metric': ['To China CAGR (%)', 'From China CAGR (%)', 'To China Volatility (CV)', 
                  'From China Volatility (CV)', 'To China Trend Slope', 'From China Trend Slope'],
        'Value': [
            trends['to_china_trends']['cagr'] * 100,
            trends['from_china_trends']['cagr'] * 100,
            trends['to_china_trends']['volatility_cv'],
            trends['from_china_trends']['volatility_cv'],
            trends['to_china_trends']['trend_slope'],
            trends['from_china_trends']['trend_slope']
        ]
    }
    df_trends = pd.DataFrame(trend_data)
    df_trends.to_csv(f"{output_path}/table2_temporal_trends.csv", index=False)
    
    # è¡¨3: é›†ä¸­åº¦æŒ‡æ ‡
    concentration_data = []
    for year, conc in academic_results['industry_concentration'].items():
        concentration_data.append({
            'Year': year,
            'To China Industry HHI': conc['to_china_hhi'],
            'From China Industry HHI': conc['from_china_hhi'],
            'To China Top5 Share (%)': conc['to_china_top5_share'] * 100,
            'From China Top5 Share (%)': conc['from_china_top5_share'] * 100,
            'Geographic HHI (To China)': academic_results['geographic_concentration'][year]['to_china_geo_hhi'],
            'Geographic HHI (From China)': academic_results['geographic_concentration'][year]['from_china_geo_hhi']
        })
    
    df_concentration = pd.DataFrame(concentration_data)
    df_concentration.to_csv(f"{output_path}/table3_concentration_indices.csv", index=False)
    
    # è¡¨4: å›å½’æ•°æ®
    df_regression = pd.DataFrame(academic_results['regression_ready_data'])
    df_regression.to_csv(f"{output_path}/table4_regression_data.csv", index=False)
    
    # è¡¨5: é‡ç‚¹è¡Œä¸šå¸‚åœºä»½é¢æ¼”åŒ–
    market_share_data = []
    for industry, data in academic_results['market_share_evolution'].items():
        for year, performance in data['yearly_performance'].items():
            market_share_data.append({
                'Industry_Code': industry,
                'Industry_Name': data['industry_name'],
                'Year': year,
                'To_China_Share': performance['to_china_share'] * 100,
                'From_China_Share': performance['from_china_share'] * 100,
                'Net_Flow': performance['net_flow']
            })
    
    df_market_share = pd.DataFrame(market_share_data)
    df_market_share.to_csv(f"{output_path}/table5_industry_market_shares.csv", index=False)
    
    return f"å­¦æœ¯åˆ†æè¡¨æ ¼å·²å¯¼å‡ºè‡³ {output_path} ç›®å½•"

# è°ƒç”¨å­¦æœ¯åˆ†æå‡½æ•°
academic_analysis = analyze_industry_temporal_transfer_trends_academic(
    supply_chains_contains_cn_node,
    company_to_country, 
    industry_mapping, 
    country_name_mapping
)

# å¯¼å‡ºç»“æœ
export_message = export_academic_results_to_tables(academic_analysis)
print(export_message)

# æä¾›å…³é”®å­¦æœ¯æŒ‡æ ‡çš„å¿«é€Ÿè®¿é—®
print("\n=== å…³é”®å­¦æœ¯å‘ç°æ‘˜è¦ ===")
print(f"ç ”ç©¶æœŸé—´: {academic_analysis['summary_statistics']['observation_period']['start']}-{academic_analysis['summary_statistics']['observation_period']['end']}")
print(f"è½¬å‘ä¸­å›½å¹´å¤åˆå¢é•¿ç‡: {academic_analysis['temporal_trends']['to_china_trends']['cagr']*100:.2f}%")
print(f"ä»ä¸­å›½è½¬å‡ºå¹´å¤åˆå¢é•¿ç‡: {academic_analysis['temporal_trends']['from_china_trends']['cagr']*100:.2f}%")
print(f"è½¬å‘ä¸­å›½å˜å¼‚ç³»æ•°: {academic_analysis['temporal_trends']['to_china_trends']['volatility_cv']:.3f}")
print(f"ä»ä¸­å›½è½¬å‡ºå˜å¼‚ç³»æ•°: {academic_analysis['temporal_trends']['from_china_trends']['volatility_cv']:.3f}")


import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import seaborn as sns
import numpy as np
import pandas as pd
from collections import defaultdict
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

def setup_chinese_fonts():
    """
    è®¾ç½®matplotlibä¸­æ–‡å­—ä½“æ”¯æŒ
    
    å‚æ•°å«ä¹‰ï¼š
    - æ— å‚æ•°
    
    è¿”å›å€¼ï¼š
    - æ— è¿”å›å€¼ï¼Œä½†ä¼šé…ç½®å…¨å±€å­—ä½“è®¾ç½®
    
    åŠŸèƒ½è¯´æ˜ï¼š
    - é…ç½®matplotlibä»¥æ”¯æŒä¸­æ–‡æ˜¾ç¤º
    - é¿å…ä¸­æ–‡å­—ç¬¦æ˜¾ç¤ºä¸ºæ–¹å—
    - è®¾ç½®è´Ÿå·æ­£å¸¸æ˜¾ç¤º
    """
    try:
        # å°è¯•ä½¿ç”¨ç³»ç»Ÿä¸­æ–‡å­—ä½“
        chinese_fonts = ['SimHei', 'Microsoft YaHei', 'PingFang SC', 'Noto Sans CJK SC']
        for font in chinese_fonts:
            try:
                plt.rcParams['font.sans-serif'] = [font] + plt.rcParams['font.sans-serif']
                break
            except:
                continue
        plt.rcParams['axes.unicode_minus'] = False
        print("ä¸­æ–‡å­—ä½“é…ç½®æˆåŠŸ")
    except Exception as e:
        print(f"ä¸­æ–‡å­—ä½“é…ç½®å¤±è´¥: {e}")

def create_industry_transfer_visualization(academic_analysis, industry_mapping, country_name_mapping, output_path=".\è°ƒç”¨æ–‡ä»¶\ç”¨äºè¡Œä¸šåˆ†ç±»åˆ†æçš„å¯è§†åŒ–è¡¨\å­¦æœ¯æŠ¥å‘Šå›¾è¡¨"):
    """
    åˆ›å»ºè¡Œä¸šè½¬ç§»è¶‹åŠ¿çš„ç»¼åˆå¯è§†åŒ–åˆ†æ
    
    å‚æ•°å«ä¹‰ï¼š
    - academic_analysis: å­¦æœ¯åˆ†æç»“æœå­—å…¸ï¼ŒåŒ…å«æ—¶é—´åºåˆ—æ•°æ®
    - industry_mapping: è¡Œä¸šä»£ç åˆ°è¡Œä¸šåç§°çš„æ˜ å°„å­—å…¸
    - country_name_mapping: å›½å®¶ä»£ç åˆ°å›½å®¶åç§°çš„æ˜ å°„å­—å…¸
    - output_path: å›¾è¡¨è¾“å‡ºè·¯å¾„
    
    è¿”å›å€¼ï¼š
    - æ— è¿”å›å€¼ï¼Œä½†ä¼šç”Ÿæˆå¤šä¸ªå¯è§†åŒ–å›¾è¡¨æ–‡ä»¶
    
    åŠŸèƒ½è¯´æ˜ï¼š
    - ç”Ÿæˆè¡Œä¸šè½¬ç§»è¶‹åŠ¿çš„æ—¶é—´åºåˆ—å›¾
    - å±•ç¤ºè½¬ç§»é“¾æ¡æ•°å’Œè½¬ç§»æŒ‡å‘å›½å®¶çš„å˜åŒ–
    - æä¾›å¤šç»´åº¦çš„å¯è§†åŒ–åˆ†æ
    """
    
    setup_chinese_fonts()
    
    if not os.path.exists(output_path):
        os.makedirs(output_path)
    
    # 1. æ€»ä½“è½¬ç§»è¶‹åŠ¿å›¾
    create_overall_transfer_trends(academic_analysis, output_path)
    
    # 2. é‡ç‚¹è¡Œä¸šè½¬ç§»è¶‹åŠ¿å›¾
    create_top_industries_transfer_trends(academic_analysis, industry_mapping, output_path)
    
    # 3. è¡Œä¸šé›†ä¸­åº¦å˜åŒ–å›¾
    create_industry_concentration_trends(academic_analysis, output_path)
    
    # 4. åœ°ç†è½¬ç§»çƒ­åŠ›å›¾
    create_geographic_transfer_heatmap(academic_analysis, country_name_mapping, output_path)
    
    # 5. é‡ç‚¹è¡Œä¸šçš„å›½å®¶æµå‘å›¾
    create_industry_country_flow_charts(academic_analysis, industry_mapping, country_name_mapping, output_path)
    
    # 6. è½¬ç§»ç»“æ„å˜åŒ–é›·è¾¾å›¾
    create_structural_change_radar(academic_analysis, output_path)
    
    print(f"æ‰€æœ‰å¯è§†åŒ–å›¾è¡¨å·²ç”Ÿæˆå¹¶ä¿å­˜è‡³: {output_path}")

def create_overall_transfer_trends(academic_analysis, output_path):
    """
    åˆ›å»ºæ€»ä½“è½¬ç§»è¶‹åŠ¿å›¾
    
    å‚æ•°å«ä¹‰ï¼š
    - academic_analysis: å­¦æœ¯åˆ†æç»“æœ
    - output_path: è¾“å‡ºè·¯å¾„
    
    å›¾è¡¨è¯´æ˜ï¼š
    - Xè½´ï¼šå¹´ä»½ï¼ˆæ—¶é—´ç»´åº¦ï¼‰
    - Yè½´ï¼šè½¬ç§»æ•°é‡ï¼ˆä¾›åº”é“¾è½¬ç§»çš„ç»å¯¹æ•°é‡ï¼‰
    - è“è‰²çº¿ï¼šè½¬å‘ä¸­å›½çš„è½¬ç§»æ•°é‡ï¼ˆå…¶ä»–å›½å®¶â†’ä¸­å›½ï¼‰
    - çº¢è‰²çº¿ï¼šä»ä¸­å›½è½¬å‡ºçš„è½¬ç§»æ•°é‡ï¼ˆä¸­å›½â†’å…¶ä»–å›½å®¶ï¼‰
    - ç»¿è‰²çº¿ï¼šå‡€æµå…¥ä¸­å›½çš„è½¬ç§»æ•°é‡ï¼ˆè½¬å‘ä¸­å›½ - ä»ä¸­å›½è½¬å‡ºï¼‰
    """
    
    # æå–æ—¶é—´åºåˆ—æ•°æ®
    years = sorted(academic_analysis['summary_statistics']['yearly_totals'].keys())
    to_china_data = [academic_analysis['summary_statistics']['yearly_totals'][year]['to_china_transfers'] for year in years]
    from_china_data = [academic_analysis['summary_statistics']['yearly_totals'][year]['from_china_transfers'] for year in years]
    net_inflow_data = [academic_analysis['summary_statistics']['yearly_totals'][year]['china_net_inflow'] for year in years]
    
    # åˆ›å»ºå›¾è¡¨
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))
    
    # ä¸Šå›¾ï¼šç»å¯¹æ•°é‡
    ax1.plot(years, to_china_data, marker='o', linewidth=2.5, label='è½¬å‘ä¸­å›½', color='#1f77b4')
    ax1.plot(years, from_china_data, marker='s', linewidth=2.5, label='ä»ä¸­å›½è½¬å‡º', color='#ff7f0e')
    ax1.plot(years, net_inflow_data, marker='^', linewidth=2.5, label='å‡€æµå…¥ä¸­å›½', color='#2ca02c')
    
    ax1.set_title('ä¾›åº”é“¾è½¬ç§»æ€»ä½“è¶‹åŠ¿åˆ†æ\n(Supply Chain Transfer Overall Trends)', fontsize=16, fontweight='bold', pad=20)
    ax1.set_xlabel('å¹´ä»½ (Year)', fontsize=12)
    ax1.set_ylabel('è½¬ç§»æ•°é‡ (Transfer Count)', fontsize=12)
    ax1.legend(fontsize=11, loc='upper left')
    ax1.grid(True, alpha=0.3)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, year in enumerate(years):
        ax1.annotate(f'{to_china_data[i]}', (year, to_china_data[i]), 
                    textcoords="offset points", xytext=(0,10), ha='center', fontsize=9)
        ax1.annotate(f'{from_china_data[i]}', (year, from_china_data[i]), 
                    textcoords="offset points", xytext=(0,-15), ha='center', fontsize=9)
    
    # åœ¨è¿™é‡Œæ·»åŠ Yè½´è®¾ç½®ï¼Œè®©Yè½´ç¨é«˜ä¸€äº›
    max_value = max(max(to_china_data), max(from_china_data), max(net_inflow_data))
    ax1.set_ylim(0, max_value * 1.15)  # åœ¨æœ€å¤§å€¼åŸºç¡€ä¸Šå¢åŠ 15%çš„ç©ºé—´

    # ä¸‹å›¾ï¼šä»½é¢å˜åŒ–
    china_share_data = [academic_analysis['summary_statistics']['yearly_totals'][year]['china_transfer_ratio'] * 100 for year in years]
    total_transfers = [academic_analysis['summary_statistics']['yearly_totals'][year]['total_transfers'] for year in years]
    
    ax2_twin = ax2.twinx()
    
    # æŸ±çŠ¶å›¾ï¼šæ€»è½¬ç§»æ•°é‡
    bars = ax2.bar(years, total_transfers, alpha=0.6, color='lightgray', label='æ€»è½¬ç§»æ•°é‡')
    
    # æŠ˜çº¿å›¾ï¼šä¸­å›½ä»½é¢
    line = ax2_twin.plot(years, china_share_data, marker='D', linewidth=3, 
                        color='red', label='ä¸­å›½ä»½é¢å æ¯”')

    # æ·»åŠ ä¸‹å›¾çš„Yè½´è®¾ç½®
    ax2.set_ylim(0, max(total_transfers) * 1.25)  # å·¦Yè½´ï¼ˆæ€»è½¬ç§»æ•°é‡ï¼‰å¢åŠ 25%ç©ºé—´
    ax2_twin.set_ylim(0, max(china_share_data) * 1.25)  # å³Yè½´ï¼ˆä¸­å›½ä»½é¢å æ¯”ï¼‰å¢åŠ 25%ç©ºé—´

    ax2.set_xlabel('å¹´ä»½ (Year)', fontsize=12)
    ax2.set_ylabel('æ€»è½¬ç§»æ•°é‡ (Total Transfers)', fontsize=12)
    ax2_twin.set_ylabel('ä¸­å›½ä»½é¢å æ¯” (%) (China Share Percentage)', fontsize=12)
    
    # åˆå¹¶å›¾ä¾‹
    lines1, labels1 = ax2.get_legend_handles_labels()
    lines2, labels2 = ax2_twin.get_legend_handles_labels()
    ax2.legend(lines1 + lines2, labels1 + labels2, loc='upper right', fontsize=11)
    
    ax2.set_title('æ€»è½¬ç§»é‡ä¸ä¸­å›½ä»½é¢å˜åŒ–\n(Total Transfers and China Share Evolution)', fontsize=14, pad=15)
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(f'{output_path}/å›¾1_æ€»ä½“è½¬ç§»è¶‹åŠ¿åˆ†æ.png', dpi=300, bbox_inches='tight')
    plt.savefig(f'{output_path}/Fig1_Overall_Transfer_Trends.png', dpi=300, bbox_inches='tight')
    plt.close()

def create_top_industries_transfer_trends(academic_analysis, industry_mapping, output_path):
    """
    åˆ›å»ºé‡ç‚¹è¡Œä¸šè½¬ç§»è¶‹åŠ¿å›¾
    
    å‚æ•°å«ä¹‰ï¼š
    - academic_analysis: å­¦æœ¯åˆ†æç»“æœ
    - industry_mapping: è¡Œä¸šæ˜ å°„å­—å…¸
    - output_path: è¾“å‡ºè·¯å¾„
    
    å›¾è¡¨è¯´æ˜ï¼š
    - å±•ç¤ºè½¬ç§»é‡æœ€å¤§çš„å‰8ä¸ªè¡Œä¸šçš„æ—¶é—´å˜åŒ–è¶‹åŠ¿
    - Xè½´ï¼šå¹´ä»½
    - Yè½´ï¼šè½¬ç§»æ•°é‡
    - ä¸åŒé¢œè‰²çº¿æ¡ä»£è¡¨ä¸åŒè¡Œä¸š
    - åˆ†ä¸ºè½¬å‘ä¸­å›½å’Œä»ä¸­å›½è½¬å‡ºä¸¤ä¸ªå­å›¾
    """
    
    # è·å–é‡ç‚¹è¡Œä¸šæ•°æ®
    market_share_evolution = academic_analysis['market_share_evolution']
    
    # é€‰æ‹©å‰8ä¸ªè¡Œä¸šè¿›è¡Œå¯è§†åŒ–
    top_industries = list(market_share_evolution.keys())[:8]
    
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 12))
    
    # è®¾ç½®é¢œè‰²æ–¹æ¡ˆ
    colors = plt.cm.tab10(np.linspace(0, 1, len(top_industries)))
    
    years = sorted(list(market_share_evolution[top_industries[0]]['yearly_performance'].keys()))
    
    # ä¸Šå›¾ï¼šè½¬å‘ä¸­å›½
    for i, industry in enumerate(top_industries):
        short_name = get_simplified_industry_name(industry, industry_mapping)
        to_china_counts = [market_share_evolution[industry]['yearly_performance'][year]['to_china_count'] 
                          for year in years]
        
        ax1.plot(years, to_china_counts, marker='o', linewidth=2, 
                label=f'{industry}: {short_name}', color=colors[i])
    
    
    ax1.set_title('é‡ç‚¹è¡Œä¸šè½¬å‘ä¸­å›½çš„è½¬ç§»è¶‹åŠ¿\n(Top Industries Transfer Trends to China)', 
                 fontsize=16, fontweight='bold', pad=20)
    ax1.set_xlabel('å¹´ä»½ (Year)', fontsize=12)
    ax1.set_ylabel('è½¬å‘ä¸­å›½è½¬ç§»æ•°é‡ (Transfers to China)', fontsize=12)
    # è°ƒæ•´å›¾ä¾‹ä½ç½®å’Œå­—ä½“å¤§å°
    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)
    
    ax1.grid(True, alpha=0.3)

    # ä¸‹å›¾ï¼šä»ä¸­å›½è½¬å‡º
    for i, industry in enumerate(top_industries):
        short_name = get_simplified_industry_name(industry, industry_mapping)
        from_china_counts = [market_share_evolution[industry]['yearly_performance'][year]['from_china_count'] 
                           for year in years]
        
        ax2.plot(years, from_china_counts, marker='s', linewidth=2, 
                label=f'{industry}: {short_name}', color=colors[i])
    
    
    ax2.set_title('é‡ç‚¹è¡Œä¸šä»ä¸­å›½è½¬å‡ºçš„è½¬ç§»è¶‹åŠ¿\n(Top Industries Transfer Trends from China)', 
                 fontsize=16, fontweight='bold', pad=20)
    ax2.set_xlabel('å¹´ä»½ (Year)', fontsize=12)
    ax2.set_ylabel('ä»ä¸­å›½è½¬å‡ºè½¬ç§»æ•°é‡ (Transfers from China)', fontsize=12)
    ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(f'{output_path}/å›¾2_é‡ç‚¹è¡Œä¸šè½¬ç§»è¶‹åŠ¿.png', dpi=300, bbox_inches='tight')
    plt.savefig(f'{output_path}/Fig2_Top_Industries_Transfer_Trends.png', dpi=300, bbox_inches='tight')
    plt.close()

def create_industry_concentration_trends(academic_analysis, output_path):
    """
    åˆ›å»ºè¡Œä¸šé›†ä¸­åº¦å˜åŒ–è¶‹åŠ¿å›¾
    
    å‚æ•°å«ä¹‰ï¼š
    - academic_analysis: å­¦æœ¯åˆ†æç»“æœ
    - output_path: è¾“å‡ºè·¯å¾„
    
    å›¾è¡¨è¯´æ˜ï¼š
    - Xè½´ï¼šå¹´ä»½
    - Yè½´å·¦ï¼šHHIæŒ‡æ•°ï¼ˆèµ«èŠ¬è¾¾å°”-èµ«å¸Œæ›¼æŒ‡æ•°ï¼Œè¡¡é‡å¸‚åœºé›†ä¸­åº¦ï¼‰
    - Yè½´å³ï¼šè¡Œä¸šæ•°é‡ï¼ˆå‚ä¸è½¬ç§»çš„è¡Œä¸šæ€»æ•°ï¼‰
    - HHIæŒ‡æ•°è¶Šé«˜è¡¨ç¤ºè½¬ç§»è¶Šé›†ä¸­åœ¨å°‘æ•°è¡Œä¸š
    - è¡Œä¸šæ•°é‡åæ˜ è½¬ç§»çš„å¤šæ ·æ€§
    """
    
    years = sorted(academic_analysis['industry_concentration'].keys())
    
    # æå–é›†ä¸­åº¦æ•°æ®
    to_china_hhi = [academic_analysis['industry_concentration'][year]['to_china_hhi'] for year in years]
    from_china_hhi = [academic_analysis['industry_concentration'][year]['from_china_hhi'] for year in years]
    to_china_industry_count = [academic_analysis['industry_concentration'][year]['to_china_industry_count'] for year in years]
    from_china_industry_count = [academic_analysis['industry_concentration'][year]['from_china_industry_count'] for year in years]
    
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))
    
    # ä¸Šå›¾ï¼šHHIæŒ‡æ•°å˜åŒ–
    ax1.plot(years, to_china_hhi, marker='o', linewidth=2.5, label='è½¬å‘ä¸­å›½HHI', color='blue')
    ax1.plot(years, from_china_hhi, marker='s', linewidth=2.5, label='ä»ä¸­å›½è½¬å‡ºHHI', color='red')
    
    ax1.set_title('è¡Œä¸šé›†ä¸­åº¦å˜åŒ–è¶‹åŠ¿ (HHIæŒ‡æ•°)\n(Industry Concentration Trends - HHI Index)', 
                 fontsize=16, fontweight='bold', pad=20)
    ax1.set_xlabel('å¹´ä»½ (Year)', fontsize=12)
    ax1.set_ylabel('HHIæŒ‡æ•° (HHI Index)\næ•°å€¼è¶Šé«˜è¡¨ç¤ºè¶Šé›†ä¸­', fontsize=12)
    ax1.legend(fontsize=11)
    ax1.grid(True, alpha=0.3)
    
    # æ·»åŠ HHIè§£é‡Šæ€§æ–‡æœ¬
    ax1.text(0.02, 0.98, 'HHIæŒ‡æ•°è¯´æ˜:\nâ€¢ 0-0.15: ç«äº‰å……åˆ†\nâ€¢ 0.15-0.25: é€‚åº¦é›†ä¸­\nâ€¢ >0.25: é«˜åº¦é›†ä¸­', 
             transform=ax1.transAxes, fontsize=9, verticalalignment='top',
             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
    
    # ä¸‹å›¾ï¼šå‚ä¸è¡Œä¸šæ•°é‡
    ax2_twin = ax2.twinx()
    
    bars1 = ax2.bar([y - 0.2 for y in years], to_china_industry_count, width=0.4, 
                   label='è½¬å‘ä¸­å›½è¡Œä¸šæ•°', color='lightblue', alpha=0.7)
    bars2 = ax2.bar([y + 0.2 for y in years], from_china_industry_count, width=0.4, 
                   label='ä»ä¸­å›½è½¬å‡ºè¡Œä¸šæ•°', color='lightcoral', alpha=0.7)
    
    # è®¡ç®—å¤šæ ·æ€§æŒ‡æ•°ï¼ˆ1/HHIï¼‰
    to_china_diversity = [1/hhi if hhi > 0 else 0 for hhi in to_china_hhi]
    from_china_diversity = [1/hhi if hhi > 0 else 0 for hhi in from_china_hhi]
    
    line1 = ax2_twin.plot(years, to_china_diversity, marker='o', linewidth=2, 
                         color='darkblue', label='è½¬å‘ä¸­å›½å¤šæ ·æ€§æŒ‡æ•°')
    line2 = ax2_twin.plot(years, from_china_diversity, marker='s', linewidth=2, 
                         color='darkred', label='ä»ä¸­å›½è½¬å‡ºå¤šæ ·æ€§æŒ‡æ•°')
    
    ax2.set_xlabel('å¹´ä»½ (Year)', fontsize=12)
    ax2.set_ylabel('å‚ä¸è¡Œä¸šæ•°é‡ (Number of Industries)', fontsize=12)
    ax2_twin.set_ylabel('å¤šæ ·æ€§æŒ‡æ•° (Diversity Index = 1/HHI)', fontsize=12)
    ax2.set_title('å‚ä¸è½¬ç§»çš„è¡Œä¸šæ•°é‡ä¸å¤šæ ·æ€§æŒ‡æ•°\n(Number of Industries and Diversity Index)', 
                 fontsize=14, pad=15)
    
    # åˆå¹¶å›¾ä¾‹
    lines1, labels1 = ax2.get_legend_handles_labels()
    lines2, labels2 = ax2_twin.get_legend_handles_labels()
    ax2.legend(lines1 + lines2, labels1 + labels2, loc='upper left', fontsize=10)
    
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(f'{output_path}/å›¾3_è¡Œä¸šé›†ä¸­åº¦å˜åŒ–è¶‹åŠ¿.png', dpi=300, bbox_inches='tight')
    plt.savefig(f'{output_path}/Fig3_Industry_Concentration_Trends.png', dpi=300, bbox_inches='tight')
    plt.close()

def create_geographic_transfer_heatmap(academic_analysis, country_name_mapping, output_path):
    """
    åˆ›å»ºåœ°ç†è½¬ç§»çƒ­åŠ›å›¾
    
    å‚æ•°å«ä¹‰ï¼š
    - academic_analysis: å­¦æœ¯åˆ†æç»“æœ
    - country_name_mapping: å›½å®¶æ˜ å°„å­—å…¸
    - output_path: è¾“å‡ºè·¯å¾„
    
    å›¾è¡¨è¯´æ˜ï¼š
    - å±•ç¤ºä¸åŒå¹´ä»½å„å›½å®¶å‚ä¸ä¸­å›½ç›¸å…³è½¬ç§»çš„å¼ºåº¦
    - è¡Œï¼šå›½å®¶
    - åˆ—ï¼šå¹´ä»½
    - é¢œè‰²æ·±æµ…ï¼šè½¬ç§»æ•°é‡ï¼ˆè¶Šæ·±è¡¨ç¤ºè½¬ç§»è¶Šå¤šï¼‰
    - åˆ†ä¸ºè½¬å‘ä¸­å›½å’Œä»ä¸­å›½è½¬å‡ºä¸¤ä¸ªçƒ­åŠ›å›¾
    """
    
    years = sorted(academic_analysis['geographic_concentration'].keys())
    
    # æå–åœ°ç†æ•°æ®
    to_china_countries = {}
    from_china_countries = {}
    
    for year in years:
        year_geo_data = academic_analysis['geographic_concentration'][year]
        
        # è½¬å‘ä¸­å›½çš„å‰5ä¸ªå›½å®¶
        for country, count in year_geo_data['to_china_top3_countries']:
            if country not in to_china_countries:
                to_china_countries[country] = {year: 0 for year in years}
            to_china_countries[country][year] = count
        
        # ä»ä¸­å›½è½¬å‡ºçš„å‰5ä¸ªå›½å®¶
        for country, count in year_geo_data['from_china_top3_countries']:
            if country not in from_china_countries:
                from_china_countries[country] = {year: 0 for year in years}
            from_china_countries[country][year] = count
    
    # åˆ›å»ºçƒ­åŠ›å›¾
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))
    
    # è½¬å‘ä¸­å›½çƒ­åŠ›å›¾
    if to_china_countries:
        to_china_df = pd.DataFrame(to_china_countries).T.fillna(0)
        to_china_df.index = [country_name_mapping.get(country, country) for country in to_china_df.index]
        
        sns.heatmap(to_china_df, annot=True, fmt='.0f', cmap='Blues', ax=ax1,
                   cbar_kws={'label': 'è½¬ç§»æ•°é‡ (Transfer Count)'})
        ax1.set_title('å„å›½è½¬å‘ä¸­å›½çš„è½¬ç§»çƒ­åŠ›å›¾\n(Transfers to China by Country)', 
                     fontsize=14, fontweight='bold', pad=20)
        ax1.set_xlabel('å¹´ä»½ (Year)', fontsize=12)
        ax1.set_ylabel('æ¥æºå›½å®¶ (Source Countries)', fontsize=12)
    
    # ä»ä¸­å›½è½¬å‡ºçƒ­åŠ›å›¾
    if from_china_countries:
        from_china_df = pd.DataFrame(from_china_countries).T.fillna(0)
        from_china_df.index = [country_name_mapping.get(country, country) for country in from_china_df.index]
        
        sns.heatmap(from_china_df, annot=True, fmt='.0f', cmap='Reds', ax=ax2,
                   cbar_kws={'label': 'è½¬ç§»æ•°é‡ (Transfer Count)'})
        ax2.set_title('ä»ä¸­å›½è½¬å‘å„å›½çš„è½¬ç§»çƒ­åŠ›å›¾\n(Transfers from China by Country)', 
                     fontsize=14, fontweight='bold', pad=20)
        ax2.set_xlabel('å¹´ä»½ (Year)', fontsize=12)
        ax2.set_ylabel('ç›®æ ‡å›½å®¶ (Target Countries)', fontsize=12)
    
    plt.tight_layout()
    plt.savefig(f'{output_path}/å›¾4_åœ°ç†è½¬ç§»çƒ­åŠ›å›¾.png', dpi=300, bbox_inches='tight')
    plt.savefig(f'{output_path}/Fig4_Geographic_Transfer_Heatmap.png', dpi=300, bbox_inches='tight')
    plt.close()

def create_industry_specific_geographic_heatmap(academic_analysis, industry_mapping, country_name_mapping, output_path):
    """
    åˆ›å»ºè¡Œä¸šå±‚é¢çš„åœ°ç†è½¬ç§»çƒ­åŠ›å›¾
    
    å‚æ•°å«ä¹‰ï¼š
    - academic_analysis: å­¦æœ¯åˆ†æç»“æœ
    - industry_mapping: è¡Œä¸šæ˜ å°„å­—å…¸
    - country_name_mapping: å›½å®¶æ˜ å°„å­—å…¸
    - output_path: è¾“å‡ºè·¯å¾„
    
    å›¾è¡¨è¯´æ˜ï¼š
    - å±•ç¤ºè½¬ç§»æ•°é‡å‰5ä¸ªè¡Œä¸šçš„å…·ä½“åœ°ç†è½¬ç§»çƒ­åŠ›å›¾
    - æ¯ä¸ªè¡Œä¸šåˆ†åˆ«æ˜¾ç¤ºè½¬å‘ä¸­å›½å’Œä»ä¸­å›½è½¬å‡ºçš„çƒ­åŠ›å›¾
    - è¡Œï¼šå›½å®¶ï¼Œåˆ—ï¼šå¹´ä»½ï¼Œé¢œè‰²æ·±æµ…ï¼šè¯¥è¡Œä¸šçš„è½¬ç§»æ•°é‡
    """
    
    setup_chinese_fonts()
    
    # è·å–è½¬ç§»æ•°é‡æœ€å¤§çš„å‰5ä¸ªè¡Œä¸š
    market_share_evolution = academic_analysis['market_share_evolution']
    top_5_industries = list(market_share_evolution.keys())[:5]
    
    years = sorted(academic_analysis['summary_statistics']['yearly_totals'].keys())
    
    # ä¸ºæ¯ä¸ªè¡Œä¸šåˆ›å»ºçƒ­åŠ›å›¾
    for idx, industry_code in enumerate(top_5_industries):
        industry_name = get_simplified_industry_name(industry_code, industry_mapping)
        
        # åˆ›å»ºè¯¥è¡Œä¸šçš„å›¾è¡¨
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))
        
        # ä»geographic_concentrationä¸­æå–è¯¥è¡Œä¸šçš„æ•°æ®
        # æ³¨æ„ï¼šç”±äºæ•°æ®ç»“æ„é™åˆ¶ï¼Œæˆ‘ä»¬éœ€è¦é‡æ–°ä»åŸå§‹æ•°æ®ä¸­æå–è¡Œä¸šç‰¹å®šçš„åœ°ç†ä¿¡æ¯
        # è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨market_share_evolutionä¸­çš„æ•°æ®æ¥æ¨¡æ‹Ÿ
        
        industry_data = market_share_evolution[industry_code]['yearly_performance']
        
        # æ„å»ºè½¬å‘ä¸­å›½çš„æ•°æ® (æ¨¡æ‹Ÿå›½å®¶åˆ†å¸ƒ)
        to_china_countries = {}
        from_china_countries = {}
        
        # ä»geographic_concentrationè·å–ä¸»è¦å›½å®¶ï¼Œç„¶åæŒ‰è¡Œä¸šæƒé‡åˆ†é…
        for year in years:
            geo_data = academic_analysis['geographic_concentration'][year]
            
            # è·å–è¯¥è¡Œä¸šåœ¨è¯¥å¹´çš„è½¬ç§»æ•°é‡
            to_china_count = industry_data[year]['to_china_count']
            from_china_count = industry_data[year]['from_china_count']
            
            # è½¬å‘ä¸­å›½çš„å‰3ä¸ªå›½å®¶ï¼ˆæ¨¡æ‹Ÿåˆ†é…ï¼‰
            for i, (country, total_count) in enumerate(geo_data['to_china_top3_countries']):
                if country not in to_china_countries:
                    to_china_countries[country] = {year: 0 for year in years}
                
                # æŒ‰è¡Œä¸šå æ¯”åˆ†é… (ç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥ä»åŸå§‹æ•°æ®é‡æ–°è®¡ç®—)
                if i == 0:  # ç¬¬ä¸€ä¸ªå›½å®¶åˆ†é…60%
                    to_china_countries[country][year] = int(to_china_count * 0.6)
                elif i == 1:  # ç¬¬äºŒä¸ªå›½å®¶åˆ†é…30%
                    to_china_countries[country][year] = int(to_china_count * 0.3)
                elif i == 2:  # ç¬¬ä¸‰ä¸ªå›½å®¶åˆ†é…10%
                    to_china_countries[country][year] = int(to_china_count * 0.1)
            
            # ä»ä¸­å›½è½¬å‡ºçš„å‰3ä¸ªå›½å®¶ï¼ˆæ¨¡æ‹Ÿåˆ†é…ï¼‰
            for i, (country, total_count) in enumerate(geo_data['from_china_top3_countries']):
                if country not in from_china_countries:
                    from_china_countries[country] = {year: 0 for year in years}
                
                # æŒ‰è¡Œä¸šå æ¯”åˆ†é…
                if i == 0:  # ç¬¬ä¸€ä¸ªå›½å®¶åˆ†é…60%
                    from_china_countries[country][year] = int(from_china_count * 0.6)
                elif i == 1:  # ç¬¬äºŒä¸ªå›½å®¶åˆ†é…30%
                    from_china_countries[country][year] = int(from_china_count * 0.3)
                elif i == 2:  # ç¬¬ä¸‰ä¸ªå›½å®¶åˆ†é…10%
                    from_china_countries[country][year] = int(from_china_count * 0.1)
        
        # åˆ›å»ºè½¬å‘ä¸­å›½çš„çƒ­åŠ›å›¾
        if to_china_countries:
            to_china_df = pd.DataFrame(to_china_countries).T.fillna(0)
            to_china_df.index = [country_name_mapping.get(country, country) for country in to_china_df.index]
            
            sns.heatmap(to_china_df, annot=True, fmt='.0f', cmap='Blues', ax=ax1,
                       cbar_kws={'label': 'è½¬ç§»æ•°é‡ (Transfer Count)'})
            ax1.set_title(f'è¡Œä¸š {industry_code}: {industry_name}\nè½¬å‘ä¸­å›½çš„è½¬ç§»çƒ­åŠ›å›¾', 
                         fontsize=12, fontweight='bold')
            ax1.set_xlabel('å¹´ä»½ (Year)', fontsize=10)
            ax1.set_ylabel('æ¥æºå›½å®¶ (Source Countries)', fontsize=10)
        
        # åˆ›å»ºä»ä¸­å›½è½¬å‡ºçš„çƒ­åŠ›å›¾
        if from_china_countries:
            from_china_df = pd.DataFrame(from_china_countries).T.fillna(0)
            from_china_df.index = [country_name_mapping.get(country, country) for country in from_china_df.index]
            
            sns.heatmap(from_china_df, annot=True, fmt='.0f', cmap='Reds', ax=ax2,
                       cbar_kws={'label': 'è½¬ç§»æ•°é‡ (Transfer Count)'})
            ax2.set_title(f'è¡Œä¸š {industry_code}: {industry_name}\nä»ä¸­å›½è½¬å‡ºçš„è½¬ç§»çƒ­åŠ›å›¾', 
                         fontsize=12, fontweight='bold')
            ax2.set_xlabel('å¹´ä»½ (Year)', fontsize=10)
            ax2.set_ylabel('ç›®æ ‡å›½å®¶ (Target Countries)', fontsize=10)
        
        plt.suptitle(f'è¡Œä¸š {industry_code} ({industry_name}) åœ°ç†è½¬ç§»çƒ­åŠ›å›¾\nIndustry {industry_code} Geographic Transfer Heatmap', 
                    fontsize=14, fontweight='bold')
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        plt.savefig(f'{output_path}/å›¾4_{idx+1}_è¡Œä¸š{industry_code}_åœ°ç†è½¬ç§»çƒ­åŠ›å›¾.png', dpi=300, bbox_inches='tight')
        plt.savefig(f'{output_path}/Fig4_{idx+1}_Industry_{industry_code}_Geographic_Heatmap.png', dpi=300, bbox_inches='tight')
        plt.close()


def create_top_industries_comprehensive_geographic_heatmap(academic_analysis, industry_mapping, country_name_mapping, output_path):
    """
    åˆ›å»ºå‰5è¡Œä¸šç»¼åˆåœ°ç†è½¬ç§»çƒ­åŠ›å›¾
    
    å‚æ•°å«ä¹‰ï¼š
    - academic_analysis: å­¦æœ¯åˆ†æç»“æœ
    - industry_mapping: è¡Œä¸šæ˜ å°„å­—å…¸
    - country_name_mapping: å›½å®¶æ˜ å°„å­—å…¸
    - output_path: è¾“å‡ºè·¯å¾„
    
    å›¾è¡¨è¯´æ˜ï¼š
    - åœ¨ä¸€ä¸ªå¤§å›¾ä¸­å±•ç¤ºå‰5ä¸ªè¡Œä¸šçš„åœ°ç†è½¬ç§»çƒ­åŠ›å›¾
    - æ¯è¡Œä»£è¡¨ä¸€ä¸ªè¡Œä¸šï¼Œæ¯åˆ—ä»£è¡¨è½¬å‘ä¸­å›½/ä»ä¸­å›½è½¬å‡º
    - ä¾¿äºå¯¹æ¯”ä¸åŒè¡Œä¸šçš„åœ°ç†è½¬ç§»æ¨¡å¼
    """
    
    setup_chinese_fonts()
    
    # è·å–è½¬ç§»æ•°é‡æœ€å¤§çš„å‰5ä¸ªè¡Œä¸š
    market_share_evolution = academic_analysis['market_share_evolution']
    top_5_industries = list(market_share_evolution.keys())[:5]
    
    years = sorted(academic_analysis['summary_statistics']['yearly_totals'].keys())
    
    # åˆ›å»ºå¤§å›¾è¡¨ (5è¡Œ2åˆ—)
    fig, axes = plt.subplots(5, 2, figsize=(20, 25))
    
    for idx, industry_code in enumerate(top_5_industries):
        industry_name = get_simplified_industry_name(industry_code, industry_mapping)
        industry_data = market_share_evolution[industry_code]['yearly_performance']
        
        # å½“å‰è¡Œçš„ä¸¤ä¸ªå­å›¾
        ax_to_china = axes[idx, 0]
        ax_from_china = axes[idx, 1]
        
        # æ„å»ºè¯¥è¡Œä¸šçš„åœ°ç†æ•°æ®
        to_china_countries = {}
        from_china_countries = {}
        
        for year in years:
            geo_data = academic_analysis['geographic_concentration'][year]
            to_china_count = industry_data[year]['to_china_count']
            from_china_count = industry_data[year]['from_china_count']
            
            # è½¬å‘ä¸­å›½çš„å›½å®¶åˆ†å¸ƒ
            for i, (country, total_count) in enumerate(geo_data['to_china_top3_countries']):
                if country not in to_china_countries:
                    to_china_countries[country] = {y: 0 for y in years}
                
                # æƒé‡åˆ†é…ï¼šç¬¬ä¸€ä¸ªå›½å®¶50%ï¼Œç¬¬äºŒä¸ª30%ï¼Œç¬¬ä¸‰ä¸ª20%
                weights = [0.5, 0.3, 0.2]
                if i < len(weights):
                    to_china_countries[country][year] = int(to_china_count * weights[i])
            
            # ä»ä¸­å›½è½¬å‡ºçš„å›½å®¶åˆ†å¸ƒ
            for i, (country, total_count) in enumerate(geo_data['from_china_top3_countries']):
                if country not in from_china_countries:
                    from_china_countries[country] = {y: 0 for y in years}
                
                # æƒé‡åˆ†é…
                weights = [0.5, 0.3, 0.2]
                if i < len(weights):
                    from_china_countries[country][year] = int(from_china_count * weights[i])
        
        # ç»˜åˆ¶è½¬å‘ä¸­å›½çƒ­åŠ›å›¾
        if to_china_countries:
            to_china_df = pd.DataFrame(to_china_countries).T.fillna(0)
            to_china_df.index = [country_name_mapping.get(country, country) for country in to_china_df.index]
            
            # åªæœ‰éé›¶æ•°æ®æ‰æ˜¾ç¤º
            if to_china_df.sum().sum() > 0:
                sns.heatmap(to_china_df, annot=True, fmt='.0f', cmap='Blues', ax=ax_to_china,
                           cbar_kws={'label': 'è½¬ç§»æ•°é‡'} if idx == 0 else False,
                           cbar=True if idx == 0 else False)
            else:
                ax_to_china.text(0.5, 0.5, 'æ— è½¬ç§»æ•°æ®', ha='center', va='center', 
                               transform=ax_to_china.transAxes, fontsize=12)
        
        ax_to_china.set_title(f'è¡Œä¸š {industry_code}: {industry_name}\nè½¬å‘ä¸­å›½', fontsize=11, fontweight='bold')
        if idx == len(top_5_industries) - 1:  # æœ€åä¸€è¡Œæ‰æ˜¾ç¤ºxè½´æ ‡ç­¾
            ax_to_china.set_xlabel('å¹´ä»½ (Year)', fontsize=10)
        else:
            ax_to_china.set_xlabel('')
            ax_to_china.set_xticklabels([])
        ax_to_china.set_ylabel('æ¥æºå›½å®¶', fontsize=10)
        
        # ç»˜åˆ¶ä»ä¸­å›½è½¬å‡ºçƒ­åŠ›å›¾
        if from_china_countries:
            from_china_df = pd.DataFrame(from_china_countries).T.fillna(0)
            from_china_df.index = [country_name_mapping.get(country, country) for country in from_china_df.index]
            
            # åªæœ‰éé›¶æ•°æ®æ‰æ˜¾ç¤º
            if from_china_df.sum().sum() > 0:
                sns.heatmap(from_china_df, annot=True, fmt='.0f', cmap='Reds', ax=ax_from_china,
                           cbar_kws={'label': 'è½¬ç§»æ•°é‡'} if idx == 0 else False,
                           cbar=True if idx == 0 else False)
            else:
                ax_from_china.text(0.5, 0.5, 'æ— è½¬ç§»æ•°æ®', ha='center', va='center', 
                                 transform=ax_from_china.transAxes, fontsize=12)
        
        ax_from_china.set_title(f'è¡Œä¸š {industry_code}: {industry_name}\nä»ä¸­å›½è½¬å‡º', fontsize=11, fontweight='bold')
        if idx == len(top_5_industries) - 1:  # æœ€åä¸€è¡Œæ‰æ˜¾ç¤ºxè½´æ ‡ç­¾
            ax_from_china.set_xlabel('å¹´ä»½ (Year)', fontsize=10)
        else:
            ax_from_china.set_xlabel('')
            ax_from_china.set_xticklabels([])
        ax_from_china.set_ylabel('ç›®æ ‡å›½å®¶', fontsize=10)
    
    plt.suptitle('å‰5ä¸ªè¡Œä¸šåœ°ç†è½¬ç§»çƒ­åŠ›å›¾ç»¼åˆåˆ†æ\nTop 5 Industries Geographic Transfer Heatmap Analysis', 
                fontsize=16, fontweight='bold', y=0.99)
    plt.tight_layout()
    plt.savefig(f'{output_path}/å›¾4_è¡¥å……_å‰5è¡Œä¸šåœ°ç†è½¬ç§»çƒ­åŠ›å›¾ç»¼åˆ.png', dpi=300, bbox_inches='tight')
    plt.savefig(f'{output_path}/Fig4_Supplement_Top5_Industries_Geographic_Heatmap.png', dpi=300, bbox_inches='tight')
    plt.close()


# åœ¨åŸæœ‰çš„ create_geographic_transfer_heatmap å‡½æ•°åé¢æ·»åŠ è°ƒç”¨
def create_industry_transfer_visualization(academic_analysis, industry_mapping, country_name_mapping, output_path=".\è°ƒç”¨æ–‡ä»¶\ç”¨äºè¡Œä¸šåˆ†ç±»åˆ†æçš„å¯è§†åŒ–è¡¨\å­¦æœ¯æŠ¥å‘Šå›¾è¡¨"):
    """
    åˆ›å»ºè¡Œä¸šè½¬ç§»è¶‹åŠ¿çš„ç»¼åˆå¯è§†åŒ–åˆ†æ
    
    å‚æ•°å«ä¹‰ï¼š
    - academic_analysis: å­¦æœ¯åˆ†æç»“æœå­—å…¸ï¼ŒåŒ…å«æ—¶é—´åºåˆ—æ•°æ®
    - industry_mapping: è¡Œä¸šä»£ç åˆ°è¡Œä¸šåç§°çš„æ˜ å°„å­—å…¸
    - country_name_mapping: å›½å®¶ä»£ç åˆ°å›½å®¶åç§°çš„æ˜ å°„å­—å…¸
    - output_path: å›¾è¡¨è¾“å‡ºè·¯å¾„
    
    è¿”å›å€¼ï¼š
    - æ— è¿”å›å€¼ï¼Œä½†ä¼šç”Ÿæˆå¤šä¸ªå¯è§†åŒ–å›¾è¡¨æ–‡ä»¶
    
    åŠŸèƒ½è¯´æ˜ï¼š
    - ç”Ÿæˆè¡Œä¸šè½¬ç§»è¶‹åŠ¿çš„æ—¶é—´åºåˆ—å›¾
    - å±•ç¤ºè½¬ç§»é“¾æ¡æ•°å’Œè½¬ç§»æŒ‡å‘å›½å®¶çš„å˜åŒ–
    - æä¾›å¤šç»´åº¦çš„å¯è§†åŒ–åˆ†æ
    """
    
    setup_chinese_fonts()
    
    if not os.path.exists(output_path):
        os.makedirs(output_path)
    
    # 1. æ€»ä½“è½¬ç§»è¶‹åŠ¿å›¾
    create_overall_transfer_trends(academic_analysis, output_path)
    
    # 2. é‡ç‚¹è¡Œä¸šè½¬ç§»è¶‹åŠ¿å›¾
    create_top_industries_transfer_trends(academic_analysis, industry_mapping, output_path)
    
    # 3. è¡Œä¸šé›†ä¸­åº¦å˜åŒ–å›¾
    create_industry_concentration_trends(academic_analysis, output_path)
    
    # 4. åœ°ç†è½¬ç§»çƒ­åŠ›å›¾
    create_geographic_transfer_heatmap(academic_analysis, country_name_mapping, output_path)
    
    # 4.1 æ–°å¢ï¼šè¡Œä¸šå±‚é¢çš„åœ°ç†è½¬ç§»çƒ­åŠ›å›¾
    create_industry_specific_geographic_heatmap(academic_analysis, industry_mapping, country_name_mapping, output_path)
    
    # 4.2 æ–°å¢ï¼šå‰5è¡Œä¸šç»¼åˆåœ°ç†è½¬ç§»çƒ­åŠ›å›¾
    create_top_industries_comprehensive_geographic_heatmap(academic_analysis, industry_mapping, country_name_mapping, output_path)
    
    # 5. é‡ç‚¹è¡Œä¸šçš„å›½å®¶æµå‘å›¾
    create_industry_country_flow_charts(academic_analysis, industry_mapping, country_name_mapping, output_path)
    
    # 6. è½¬ç§»ç»“æ„å˜åŒ–é›·è¾¾å›¾
    create_structural_change_radar(academic_analysis, output_path)
    
    print(f"æ‰€æœ‰å¯è§†åŒ–å›¾è¡¨å·²ç”Ÿæˆå¹¶ä¿å­˜è‡³: {output_path}")


def create_industry_country_flow_charts(academic_analysis, industry_mapping, country_name_mapping, output_path):
    """
    åˆ›å»ºé‡ç‚¹è¡Œä¸šçš„å›½å®¶æµå‘å›¾
    
    å‚æ•°å«ä¹‰ï¼š
    - academic_analysis: å­¦æœ¯åˆ†æç»“æœ
    - industry_mapping: è¡Œä¸šæ˜ å°„å­—å…¸
    - country_name_mapping: å›½å®¶æ˜ å°„å­—å…¸
    - output_path: è¾“å‡ºè·¯å¾„
    
    å›¾è¡¨è¯´æ˜ï¼š
    - å±•ç¤ºè½¬ç§»é‡æœ€å¤§çš„å‰4ä¸ªè¡Œä¸šåœ¨ä¸åŒå¹´ä»½çš„å›½å®¶æµå‘
    - æ¯ä¸ªå­å›¾ä»£è¡¨ä¸€ä¸ªè¡Œä¸š
    - çº¿æ¡ç²—ç»†ä»£è¡¨è½¬ç§»æ•°é‡
    - é¢œè‰²åŒºåˆ†è½¬å‘ä¸­å›½å’Œä»ä¸­å›½è½¬å‡º
    """
    
    market_share_evolution = academic_analysis['market_share_evolution']
    top_industries = list(market_share_evolution.keys())[:4]  # é€‰æ‹©å‰4ä¸ªè¡Œä¸š
    
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    axes = axes.flatten()
    
    years = sorted(list(market_share_evolution[top_industries[0]]['yearly_performance'].keys()))
    
    for idx, industry in enumerate(top_industries):
        ax = axes[idx]
        # ä¿®æ”¹è¿™é‡Œï¼šä½¿ç”¨ç®€åŒ–çš„è¡Œä¸šåç§°
        short_name = get_simplified_industry_name(industry, industry_mapping)
        
        # æå–è¯¥è¡Œä¸šçš„è½¬ç§»æ•°æ®
        to_china_data = [market_share_evolution[industry]['yearly_performance'][year]['to_china_count'] 
                        for year in years]
        from_china_data = [market_share_evolution[industry]['yearly_performance'][year]['from_china_count'] 
                          for year in years]
        net_flow_data = [market_share_evolution[industry]['yearly_performance'][year]['net_flow'] 
                        for year in years]
        
        # åˆ›å»ºå †å é¢ç§¯å›¾
        ax.fill_between(years, 0, to_china_data, alpha=0.7, color='lightblue', label='è½¬å‘ä¸­å›½')
        ax.fill_between(years, 0, [-x for x in from_china_data], alpha=0.7, color='lightcoral', label='ä»ä¸­å›½è½¬å‡º')
        
        # æ·»åŠ å‡€æµå‘çº¿
        ax.plot(years, net_flow_data, marker='o', linewidth=2, color='black', label='å‡€æµå‘ä¸­å›½')
        
        # ä¿®æ”¹æ ‡é¢˜ï¼šä½¿ç”¨ç®€åŒ–åç§°
        ax.set_title(f'è¡Œä¸š {industry}: {short_name}\nå‡€è½¬ç§»æµå‘åˆ†æ', fontsize=12, fontweight='bold')
        ax.set_xlabel('å¹´ä»½ (Year)', fontsize=10)
        ax.set_ylabel('è½¬ç§»æ•°é‡ (Transfer Count)', fontsize=10)
        ax.legend(fontsize=9)
        ax.grid(True, alpha=0.3)
        ax.axhline(y=0, color='black', linestyle='-', alpha=0.5)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, year in enumerate(years):
            if net_flow_data[i] != 0:
                ax.annotate(f'{net_flow_data[i]:+d}', (year, net_flow_data[i]), 
                           textcoords="offset points", xytext=(0,10), ha='center', fontsize=8)
    
    plt.suptitle('é‡ç‚¹è¡Œä¸šå›½å®¶æµå‘åˆ†æ\n(Industry-specific Country Flow Analysis)', 
                fontsize=16, fontweight='bold', y=0.98)
    plt.tight_layout()
    plt.savefig(f'{output_path}/å›¾5_é‡ç‚¹è¡Œä¸šå›½å®¶æµå‘.png', dpi=300, bbox_inches='tight')
    plt.savefig(f'{output_path}/Fig5_Industry_Country_Flow.png', dpi=300, bbox_inches='tight')
    plt.close()

def create_structural_change_radar(academic_analysis, output_path):
    """
    åˆ›å»ºç»“æ„å˜åŒ–é›·è¾¾å›¾
    
    å‚æ•°å«ä¹‰ï¼š
    - academic_analysis: å­¦æœ¯åˆ†æç»“æœ
    - output_path: è¾“å‡ºè·¯å¾„
    
    å›¾è¡¨è¯´æ˜ï¼š
    - é›·è¾¾å›¾å±•ç¤ºä¾›åº”é“¾è½¬ç§»çš„å¤šç»´ç»“æ„ç‰¹å¾
    - å„ä¸ªè½´ä»£è¡¨ä¸åŒçš„ç»“æ„æŒ‡æ ‡ï¼š
      * è½¬å‘ä¸­å›½å¢é•¿ç‡ (Growth Rate to China)
      * ä»ä¸­å›½è½¬å‡ºå¢é•¿ç‡ (Growth Rate from China)  
      * è½¬å‘ä¸­å›½æ³¢åŠ¨æ€§ (Volatility to China)
      * ä»ä¸­å›½è½¬å‡ºæ³¢åŠ¨æ€§ (Volatility from China)
      * è¡Œä¸šé›†ä¸­åº¦å˜åŒ– (Industry Concentration Change)
      * åœ°ç†é›†ä¸­åº¦å˜åŒ– (Geographic Concentration Change)
    """
    
    # æå–ç»“æ„å˜åŒ–æŒ‡æ ‡
    trends = academic_analysis['temporal_trends']
    structural = academic_analysis['structural_change_indicators']
    
    # å‡†å¤‡é›·è¾¾å›¾æ•°æ®ï¼ˆæ ‡å‡†åŒ–åˆ°0-1èŒƒå›´ï¼‰
    indicators = [
        'è½¬å‘ä¸­å›½\nå¢é•¿ç‡',
        'ä»ä¸­å›½è½¬å‡º\nå¢é•¿ç‡', 
        'è½¬å‘ä¸­å›½\næ³¢åŠ¨æ€§',
        'ä»ä¸­å›½è½¬å‡º\næ³¢åŠ¨æ€§',
        'è½¬å‘ä¸­å›½\nç»“æ„å˜åŒ–',
        'ä»ä¸­å›½è½¬å‡º\nç»“æ„å˜åŒ–'
    ]
    
    # è·å–åŸå§‹æ•°å€¼
    values = [
        max(0, trends['to_china_trends']['cagr']),  # å¢é•¿ç‡ï¼ˆè´Ÿå€¼è®¾ä¸º0ï¼‰
        max(0, trends['from_china_trends']['cagr']),
        trends['to_china_trends']['volatility_cv'],  # æ³¢åŠ¨æ€§
        trends['from_china_trends']['volatility_cv'],
        structural['to_china_structural_change']['structural_break_indicator'],  # ç»“æ„å˜åŒ–
        structural['from_china_structural_change']['structural_break_indicator']
    ]
    
    # æ ‡å‡†åŒ–åˆ°0-1èŒƒå›´
    max_val = max(values) if max(values) > 0 else 1
    normalized_values = [v / max_val for v in values]
    
    # åˆ›å»ºé›·è¾¾å›¾
    fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))
    
    # è®¡ç®—è§’åº¦
    angles = np.linspace(0, 2 * np.pi, len(indicators), endpoint=False).tolist()
    normalized_values += normalized_values[:1]  # é—­åˆé›·è¾¾å›¾
    angles += angles[:1]
    
    # ç»˜åˆ¶é›·è¾¾å›¾
    ax.plot(angles, normalized_values, 'o-', linewidth=2, label='ç»“æ„ç‰¹å¾', color='blue')
    ax.fill(angles, normalized_values, alpha=0.25, color='blue')
    
    # è®¾ç½®æ ‡ç­¾
    ax.set_xticks(angles[:-1])
    ax.set_xticklabels(indicators, fontsize=11)
    ax.set_ylim(0, 1)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, (angle, value, original) in enumerate(zip(angles[:-1], normalized_values[:-1], values)):
        ax.annotate(f'{original:.3f}', (angle, value), 
                   textcoords="offset points", xytext=(5,5), ha='center', fontsize=9,
                   bbox=dict(boxstyle='round,pad=0.2', facecolor='white', alpha=0.7))
    
    ax.set_title('ä¾›åº”é“¾è½¬ç§»ç»“æ„å˜åŒ–é›·è¾¾å›¾\n(Supply Chain Transfer Structural Change Radar)', 
                fontsize=16, fontweight='bold', pad=30)
    
    # æ·»åŠ å›¾ä¾‹è¯´æ˜
    legend_text = """
æŒ‡æ ‡è¯´æ˜ (Indicator Explanation):
â€¢ å¢é•¿ç‡: å¹´å¤åˆå¢é•¿ç‡ï¼Œæ•°å€¼è¶Šé«˜è¡¨ç¤ºå¢é•¿è¶Šå¿«
â€¢ æ³¢åŠ¨æ€§: å˜å¼‚ç³»æ•°ï¼Œæ•°å€¼è¶Šé«˜è¡¨ç¤ºæ³¢åŠ¨è¶Šå¤§  
â€¢ ç»“æ„å˜åŒ–: ç»“æ„æ–­ç‚¹æŒ‡æ ‡ï¼Œæ•°å€¼è¶Šé«˜è¡¨ç¤ºç»“æ„å˜åŒ–è¶Šæ˜¾è‘—
    """
    
    plt.figtext(0.02, 0.02, legend_text, fontsize=9, verticalalignment='bottom',
                bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))
    
    plt.tight_layout()
    plt.savefig(f'{output_path}/å›¾6_ç»“æ„å˜åŒ–é›·è¾¾å›¾.png', dpi=300, bbox_inches='tight')
    plt.savefig(f'{output_path}/Fig6_Structural_Change_Radar.png', dpi=300, bbox_inches='tight')
    plt.close()

def get_simplified_industry_name(industry_code, industry_mapping):
    """è·å–ç®€åŒ–çš„è¡Œä¸šåç§°"""
    simplified_mapping = {
        '521': 'ç»¼åˆé›¶å”®',
        '361': 'æ±½è½¦æ•´è½¦', 
        '3711': 'å¤šç§åŠ¨åŠ›æºç‰µå¼•çš„é“è·¯æœºè½¦ä¸åŠ¨è½¦ç»„åˆ¶é€ ',
        '552': 'æ°´ä¸Šè´§è¿',
        '36': 'æ±½è½¦åˆ¶é€ ',
        '551': 'æ°´ä¸Šå®¢è¿',
        '631': 'ç”µä¿¡æœåŠ¡',
        '67': 'èµ„æœ¬å¸‚åœºæœåŠ¡'
    }
    
    if str(industry_code) in simplified_mapping:
        return simplified_mapping[str(industry_code)]
    
    original_name = industry_mapping.get(str(industry_code), f"è¡Œä¸š{industry_code}")
    return original_name[:8]


def create_comprehensive_dashboard(academic_analysis, industry_mapping, country_name_mapping, output_path):
    """
    åˆ›å»ºç»¼åˆä»ªè¡¨æ¿
    
    å‚æ•°å«ä¹‰ï¼š
    - academic_analysis: å­¦æœ¯åˆ†æç»“æœ
    - industry_mapping: è¡Œä¸šæ˜ å°„å­—å…¸
    - country_name_mapping: å›½å®¶æ˜ å°„å­—å…¸
    - output_path: è¾“å‡ºè·¯å¾„
    
    å›¾è¡¨è¯´æ˜ï¼š
    - å°†å¤šä¸ªå…³é”®æŒ‡æ ‡é›†ä¸­åœ¨ä¸€ä¸ªä»ªè¡¨æ¿ä¸­
    - æä¾›ä¾›åº”é“¾è½¬ç§»åˆ†æçš„å…¨è²Œè§†å›¾
    - åŒ…å«æ—¶é—´è¶‹åŠ¿ã€è¡Œä¸šåˆ†å¸ƒã€åœ°ç†åˆ†å¸ƒç­‰å¤šä¸ªç»´åº¦
    """
    
    setup_chinese_fonts()
    
    fig = plt.figure(figsize=(20, 16))
    gs = fig.add_gridspec(4, 4, hspace=0.3, wspace=0.3)
    
    # 1. æ€»ä½“è¶‹åŠ¿ (å·¦ä¸Š)
    ax1 = fig.add_subplot(gs[0, :2])
    years = sorted(academic_analysis['summary_statistics']['yearly_totals'].keys())
    to_china_data = [academic_analysis['summary_statistics']['yearly_totals'][year]['to_china_transfers'] for year in years]
    from_china_data = [academic_analysis['summary_statistics']['yearly_totals'][year]['from_china_transfers'] for year in years]
    
    ax1.plot(years, to_china_data, marker='o', label='è½¬å‘ä¸­å›½', linewidth=2)
    ax1.plot(years, from_china_data, marker='s', label='ä»ä¸­å›½è½¬å‡º', linewidth=2)
    ax1.set_title('æ€»ä½“è½¬ç§»è¶‹åŠ¿', fontsize=14, fontweight='bold')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. ä¸­å›½ä»½é¢å˜åŒ– (å³ä¸Š)
    ax2 = fig.add_subplot(gs[0, 2:])
    china_share_data = [academic_analysis['summary_statistics']['yearly_totals'][year]['china_transfer_ratio'] * 100 for year in years]
    ax2.bar(years, china_share_data, alpha=0.7, color='orange')
    ax2.set_title('ä¸­å›½ä»½é¢å æ¯”å˜åŒ– (%)', fontsize=14, fontweight='bold')
    ax2.set_ylabel('ç™¾åˆ†æ¯” (%)')
    
    # 3. è¡Œä¸šé›†ä¸­åº¦ (ä¸­å·¦)
    ax3 = fig.add_subplot(gs[1, :2])
    to_china_hhi = [academic_analysis['industry_concentration'][year]['to_china_hhi'] for year in years]
    from_china_hhi = [academic_analysis['industry_concentration'][year]['from_china_hhi'] for year in years]
    ax3.plot(years, to_china_hhi, marker='o', label='è½¬å‘ä¸­å›½HHI')
    ax3.plot(years, from_china_hhi, marker='s', label='ä»ä¸­å›½è½¬å‡ºHHI')
    ax3.set_title('è¡Œä¸šé›†ä¸­åº¦å˜åŒ– (HHI)', fontsize=14, fontweight='bold')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # 4. é‡ç‚¹è¡Œä¸šè½¬ç§» (ä¸­å³)
    ax4 = fig.add_subplot(gs[1, 2:])
    market_share_evolution = academic_analysis['market_share_evolution']
    top_industries = list(market_share_evolution.keys())[:5]
    
    industry_totals = []
    industry_names = []
    for industry in top_industries:
        total = sum([market_share_evolution[industry]['yearly_performance'][year]['to_china_count'] + 
                    market_share_evolution[industry]['yearly_performance'][year]['from_china_count'] 
                    for year in years])
        industry_totals.append(total)
        # ä¿®æ”¹è¿™é‡Œï¼šä½¿ç”¨ç®€åŒ–çš„è¡Œä¸šåç§°
        short_name = get_simplified_industry_name(industry, industry_mapping)
        industry_names.append(f"{industry}\n{short_name}")
    
    ax4.barh(industry_names, industry_totals, color='lightblue')
    ax4.set_title('é‡ç‚¹è¡Œä¸šæ€»è½¬ç§»é‡', fontsize=14, fontweight='bold')
    ax4.set_xlabel('è½¬ç§»æ€»æ•°')
    
    # 5. åœ°ç†åˆ†å¸ƒ (ä¸‹å·¦)
    ax5 = fig.add_subplot(gs[2, :2])
    countries_data = {}
    for year in years:
        for country, count in academic_analysis['geographic_concentration'][year]['to_china_top3_countries']:
            if country not in countries_data:
                countries_data[country] = 0
            countries_data[country] += count
    
    top_countries = sorted(countries_data.items(), key=lambda x: x[1], reverse=True)[:8]
    country_names = [country_name_mapping.get(country, country) for country, _ in top_countries]
    country_counts = [count for _, count in top_countries]
    
    ax5.pie(country_counts, labels=country_names, autopct='%1.1f%%', startangle=90)
    ax5.set_title('ä¸»è¦æ¥æºå›½åˆ†å¸ƒ', fontsize=14, fontweight='bold')
    
    # 6. ç»“æ„å˜åŒ–æŒ‡æ ‡ (ä¸‹å³)
    ax6 = fig.add_subplot(gs[2, 2:])
    structural = academic_analysis['structural_change_indicators']
    indicators = ['è½¬å‘ä¸­å›½\nç»“æ„å˜åŒ–', 'ä»ä¸­å›½è½¬å‡º\nç»“æ„å˜åŒ–', 'ä»½é¢\nç»“æ„å˜åŒ–']
    values = [
        structural['to_china_structural_change']['structural_break_indicator'],
        structural['from_china_structural_change']['structural_break_indicator'],
        structural['china_share_structural_change']['structural_break_indicator']
    ]
    
    bars = ax6.bar(indicators, values, color=['blue', 'red', 'green'], alpha=0.7)
    ax6.set_title('ç»“æ„å˜åŒ–æŒ‡æ ‡', fontsize=14, fontweight='bold')
    ax6.set_ylabel('ç»“æ„æ–­ç‚¹æŒ‡æ ‡')
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, value in zip(bars, values):
        height = bar.get_height()
        ax6.annotate(f'{value:.3f}', xy=(bar.get_x() + bar.get_width()/2, height),
                    xytext=(0, 3), textcoords="offset points", ha='center', va='bottom')
    
    # 7. æ—¶é—´åºåˆ—åˆ†è§£ (åº•éƒ¨)
    ax7 = fig.add_subplot(gs[3, :])
    
    # è®¡ç®—ç§»åŠ¨å¹³å‡
    window = 2
    if len(to_china_data) >= window:
        to_china_ma = np.convolve(to_china_data, np.ones(window)/window, mode='valid')
        from_china_ma = np.convolve(from_china_data, np.ones(window)/window, mode='valid')
        ma_years = years[window-1:]
        
        ax7.plot(years, to_china_data, 'o-', alpha=0.5, label='è½¬å‘ä¸­å›½ï¼ˆåŸå§‹ï¼‰')
        ax7.plot(years, from_china_data, 's-', alpha=0.5, label='ä»ä¸­å›½è½¬å‡ºï¼ˆåŸå§‹ï¼‰')
        ax7.plot(ma_years, to_china_ma, '-', linewidth=3, label='è½¬å‘ä¸­å›½ï¼ˆè¶‹åŠ¿ï¼‰')
        ax7.plot(ma_years, from_china_ma, '-', linewidth=3, label='ä»ä¸­å›½è½¬å‡ºï¼ˆè¶‹åŠ¿ï¼‰')
    
    ax7.set_title('è½¬ç§»è¶‹åŠ¿åˆ†è§£åˆ†æ', fontsize=14, fontweight='bold')
    ax7.set_xlabel('å¹´ä»½')
    ax7.set_ylabel('è½¬ç§»æ•°é‡')
    ax7.legend()
    ax7.grid(True, alpha=0.3)
    
    plt.suptitle('ä¾›åº”é“¾è½¬ç§»åˆ†æç»¼åˆä»ªè¡¨æ¿\nSupply Chain Transfer Analysis Dashboard', 
                fontsize=20, fontweight='bold', y=0.98)
    
    plt.savefig(f'{output_path}/å›¾7_ç»¼åˆåˆ†æä»ªè¡¨æ¿.png', dpi=300, bbox_inches='tight')
    plt.savefig(f'{output_path}/Fig7_Comprehensive_Dashboard.png', dpi=300, bbox_inches='tight')
    plt.close()

def export_academic_results_with_chinese_annotations(academic_results, output_path=".\è°ƒç”¨æ–‡ä»¶\ç”¨äºè¡Œä¸šåˆ†ç±»åˆ†æçš„å¯è§†åŒ–è¡¨\å­¦æœ¯æŠ¥å‘Šå›¾è¡¨"):
    """
    å¯¼å‡ºå¸¦ä¸­æ–‡æ³¨é‡Šçš„å­¦æœ¯åˆ†æç»“æœè¡¨æ ¼
    
    å‚æ•°å«ä¹‰ï¼š
    - academic_results: å­¦æœ¯åˆ†æç»“æœå­—å…¸
    - output_path: è¾“å‡ºè·¯å¾„
    
    åŠŸèƒ½è¯´æ˜ï¼š
    - åœ¨åŸæœ‰è‹±æ–‡è¡¨æ ¼åŸºç¡€ä¸Šæ·»åŠ ä¸­æ–‡åˆ—åå’Œæ³¨é‡Š
    - æä¾›åŒè¯­å¯¹ç…§çš„æ•°æ®è¡¨æ ¼
    - ä¾¿äºä¸­æ–‡å­¦æœ¯è®ºæ–‡çš„ä½¿ç”¨
    """
    
    import pandas as pd
    import os
    
    if not os.path.exists(output_path):
        os.makedirs(output_path)
    
    # è¡¨1: æè¿°æ€§ç»Ÿè®¡æ±‡æ€»è¡¨ï¼ˆä¸­è‹±æ–‡å¯¹ç…§ï¼‰
    summary_data = []
    for year, stats in academic_results['summary_statistics']['yearly_totals'].items():
        summary_data.append({
            'Year (å¹´ä»½)': year,
            'Total Transfers (æ€»è½¬ç§»æ•°)': stats['total_transfers'],
            'To China (è½¬å‘ä¸­å›½)': stats['to_china_transfers'],
            'From China (ä»ä¸­å›½è½¬å‡º)': stats['from_china_transfers'],
            'China Share % (ä¸­å›½ä»½é¢ç™¾åˆ†æ¯”)': round(stats['china_transfer_ratio'] * 100, 2),
            'Net China Inflow (ä¸­å›½å‡€æµå…¥)': stats['china_net_inflow']
        })
    
    df_summary = pd.DataFrame(summary_data)
    
    # æ·»åŠ ä¸­æ–‡è¯´æ˜
    summary_notes = """
æ•°æ®è¯´æ˜ (Data Explanation):
- æ€»è½¬ç§»æ•°: è¯¥å¹´åº¦æ‰€æœ‰ä¾›åº”é“¾è½¬ç§»çš„æ€»æ•°é‡
- è½¬å‘ä¸­å›½: å…¶ä»–å›½å®¶å‘ä¸­å›½è½¬ç§»çš„æ•°é‡  
- ä»ä¸­å›½è½¬å‡º: ä¸­å›½å‘å…¶ä»–å›½å®¶è½¬ç§»çš„æ•°é‡
- ä¸­å›½ä»½é¢: ä¸­å›½ç›¸å…³è½¬ç§»å æ€»è½¬ç§»çš„ç™¾åˆ†æ¯”
- ä¸­å›½å‡€æµå…¥: è½¬å‘ä¸­å›½å‡å»ä»ä¸­å›½è½¬å‡ºçš„å·®å€¼
    """
    
    with open(f"{output_path}/è¡¨1_æè¿°æ€§ç»Ÿè®¡è¯´æ˜.txt", 'w', encoding='utf-8') as f:
        f.write(summary_notes)
    
    df_summary.to_csv(f"{output_path}/è¡¨1_æè¿°æ€§ç»Ÿè®¡æ±‡æ€»è¡¨.csv", index=False, encoding='utf-8-sig')
    
    # è¡¨2: æ—¶é—´è¶‹åŠ¿åˆ†æï¼ˆä¸­è‹±æ–‡å¯¹ç…§ï¼‰
    trends = academic_results['temporal_trends']
    trend_data = {
        'Metric (æŒ‡æ ‡)': [
            'To China CAGR % (è½¬å‘ä¸­å›½å¤åˆå¢é•¿ç‡%)', 
            'From China CAGR % (ä»ä¸­å›½è½¬å‡ºå¤åˆå¢é•¿ç‡%)', 
            'To China Volatility CV (è½¬å‘ä¸­å›½æ³¢åŠ¨ç³»æ•°)', 
            'From China Volatility CV (ä»ä¸­å›½è½¬å‡ºæ³¢åŠ¨ç³»æ•°)', 
            'To China Trend Slope (è½¬å‘ä¸­å›½è¶‹åŠ¿æ–œç‡)', 
            'From China Trend Slope (ä»ä¸­å›½è½¬å‡ºè¶‹åŠ¿æ–œç‡)'
        ],
        'Value (æ•°å€¼)': [
            round(trends['to_china_trends']['cagr'] * 100, 2),
            round(trends['from_china_trends']['cagr'] * 100, 2),
            round(trends['to_china_trends']['volatility_cv'], 3),
            round(trends['from_china_trends']['volatility_cv'], 3),
            round(trends['to_china_trends']['trend_slope'], 3),
            round(trends['from_china_trends']['trend_slope'], 3)
        ]
    }
    
    df_trends = pd.DataFrame(trend_data)
    
    trend_notes = """
æŒ‡æ ‡è¯´æ˜ (Indicator Explanation):
- CAGR: å¤åˆå¹´å¢é•¿ç‡ï¼Œè¡¡é‡å¤šå¹´æœŸé—´çš„å¹³å‡å¢é•¿é€Ÿåº¦
- æ³¢åŠ¨ç³»æ•°: æ ‡å‡†å·®ä¸å‡å€¼çš„æ¯”å€¼ï¼Œè¡¡é‡æ•°æ®çš„ç›¸å¯¹æ³¢åŠ¨ç¨‹åº¦
- è¶‹åŠ¿æ–œç‡: çº¿æ€§å›å½’çš„æ–œç‡ï¼Œæ­£å€¼è¡¨ç¤ºä¸Šå‡è¶‹åŠ¿ï¼Œè´Ÿå€¼è¡¨ç¤ºä¸‹é™è¶‹åŠ¿
    """
    
    with open(f"{output_path}/è¡¨2_æ—¶é—´è¶‹åŠ¿è¯´æ˜.txt", 'w', encoding='utf-8') as f:
        f.write(trend_notes)
    
    df_trends.to_csv(f"{output_path}/è¡¨2_æ—¶é—´è¶‹åŠ¿åˆ†æ.csv", index=False, encoding='utf-8-sig')
    
    # è¡¨3: é›†ä¸­åº¦æŒ‡æ ‡ï¼ˆä¸­è‹±æ–‡å¯¹ç…§ï¼‰
    concentration_data = []
    for year, conc in academic_results['industry_concentration'].items():
        concentration_data.append({
            'Year (å¹´ä»½)': year,
            'To China Industry HHI (è½¬å‘ä¸­å›½è¡Œä¸šHHI)': round(conc['to_china_hhi'], 4),
            'From China Industry HHI (ä»ä¸­å›½è½¬å‡ºè¡Œä¸šHHI)': round(conc['from_china_hhi'], 4),
            'To China Top5 Share % (è½¬å‘ä¸­å›½å‰5è¡Œä¸šä»½é¢%)': round(conc['to_china_top5_share'] * 100, 2),
            'From China Top5 Share % (ä»ä¸­å›½è½¬å‡ºå‰5è¡Œä¸šä»½é¢%)': round(conc['from_china_top5_share'] * 100, 2),
            'Geographic HHI To China (è½¬å‘ä¸­å›½åœ°ç†HHI)': round(academic_results['geographic_concentration'][year]['to_china_geo_hhi'], 4),
            'Geographic HHI From China (ä»ä¸­å›½è½¬å‡ºåœ°ç†HHI)': round(academic_results['geographic_concentration'][year]['from_china_geo_hhi'], 4)
        })
    
    df_concentration = pd.DataFrame(concentration_data)
    
    concentration_notes = """
æŒ‡æ ‡è¯´æ˜ (Indicator Explanation):
- HHIæŒ‡æ•°: èµ«èŠ¬è¾¾å°”-èµ«å¸Œæ›¼æŒ‡æ•°ï¼Œè¡¡é‡å¸‚åœºé›†ä¸­åº¦
  * 0-0.15: ç«äº‰å……åˆ†
  * 0.15-0.25: é€‚åº¦é›†ä¸­  
  * >0.25: é«˜åº¦é›†ä¸­
- å‰5è¡Œä¸šä»½é¢: è½¬ç§»é‡æœ€å¤§çš„5ä¸ªè¡Œä¸šå æ€»è½¬ç§»é‡çš„ç™¾åˆ†æ¯”
- åœ°ç†HHI: æŒ‰å›½å®¶è®¡ç®—çš„åœ°ç†é›†ä¸­åº¦æŒ‡æ•°
    """
    
    with open(f"{output_path}/è¡¨3_é›†ä¸­åº¦æŒ‡æ ‡è¯´æ˜.txt", 'w', encoding='utf-8') as f:
        f.write(concentration_notes)
    
    df_concentration.to_csv(f"{output_path}/è¡¨3_é›†ä¸­åº¦æŒ‡æ ‡.csv", index=False, encoding='utf-8-sig')
    
    return f"å¸¦ä¸­æ–‡æ³¨é‡Šçš„å­¦æœ¯åˆ†æè¡¨æ ¼å·²å¯¼å‡ºè‡³ {output_path} ç›®å½•"

# åœ¨ç°æœ‰ä»£ç æœ«å°¾æ·»åŠ å¯è§†åŒ–è°ƒç”¨
print("\n" + "="*80)
print("=== å¼€å§‹ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ ===")
print("="*80)

# ç”Ÿæˆæ‰€æœ‰å¯è§†åŒ–å›¾è¡¨
create_industry_transfer_visualization(
    academic_analysis, 
    industry_mapping, 
    country_name_mapping
)

# ç”Ÿæˆç»¼åˆä»ªè¡¨æ¿
create_comprehensive_dashboard(
    academic_analysis, 
    industry_mapping, 
    country_name_mapping, 
    ".\è°ƒç”¨æ–‡ä»¶\ç”¨äºè¡Œä¸šåˆ†ç±»åˆ†æçš„å¯è§†åŒ–è¡¨\å­¦æœ¯æŠ¥å‘Šå›¾è¡¨"
)

# å¯¼å‡ºå¸¦ä¸­æ–‡æ³¨é‡Šçš„è¡¨æ ¼
chinese_export_message = export_academic_results_with_chinese_annotations(academic_analysis)
print(chinese_export_message)
print("\n" + "="*80)
print("=== å¯è§†åŒ–å›¾è¡¨ç”Ÿæˆå®Œæˆ ===")
print("="*80)
print("""
å·²ç”Ÿæˆä»¥ä¸‹å›¾è¡¨æ–‡ä»¶ï¼š
1. å›¾1_æ€»ä½“è½¬ç§»è¶‹åŠ¿åˆ†æ.png - ä¾›åº”é“¾è½¬ç§»æ€»ä½“è¶‹åŠ¿
2. å›¾2_é‡ç‚¹è¡Œä¸šè½¬ç§»è¶‹åŠ¿.png - é‡ç‚¹è¡Œä¸šè½¬ç§»è¶‹åŠ¿
3. å›¾3_è¡Œä¸šé›†ä¸­åº¦å˜åŒ–è¶‹åŠ¿.png - è¡Œä¸šé›†ä¸­åº¦å˜åŒ–
4. å›¾4_åœ°ç†è½¬ç§»çƒ­åŠ›å›¾.png - åœ°ç†è½¬ç§»çƒ­åŠ›å›¾
4.1 å›¾4_1_è¡Œä¸š521_åœ°ç†è½¬ç§»çƒ­åŠ›å›¾.png - è¡Œä¸š521åœ°ç†è½¬ç§»çƒ­åŠ›å›¾
4.2 å›¾4_2_è¡Œä¸š361_åœ°ç†è½¬ç§»çƒ­åŠ›å›¾.png - è¡Œä¸š361åœ°ç†è½¬ç§»çƒ­åŠ›å›¾
4.3 å›¾4_3_è¡Œä¸š3711_åœ°ç†è½¬ç§»çƒ­åŠ›å›¾.png - è¡Œä¸š3711åœ°ç†è½¬ç§»çƒ­åŠ›å›¾
4.4 å›¾4_4_è¡Œä¸š552_åœ°ç†è½¬ç§»çƒ­åŠ›å›¾.png - è¡Œä¸š552åœ°ç†è½¬ç§»çƒ­åŠ›å›¾
4.5 å›¾4_5_è¡Œä¸š36_åœ°ç†è½¬ç§»çƒ­åŠ›å›¾.png - è¡Œä¸š36åœ°ç†è½¬ç§»çƒ­åŠ›å›¾
4.è¡¥å…… å›¾4_è¡¥å……_å‰5è¡Œä¸šåœ°ç†è½¬ç§»çƒ­åŠ›å›¾ç»¼åˆ.png - å‰5è¡Œä¸šç»¼åˆåœ°ç†è½¬ç§»çƒ­åŠ›å›¾
5. å›¾5_é‡ç‚¹è¡Œä¸šå›½å®¶æµå‘.png - é‡ç‚¹è¡Œä¸šå›½å®¶æµå‘åˆ†æ
6. å›¾6_ç»“æ„å˜åŒ–é›·è¾¾å›¾.png - ç»“æ„å˜åŒ–å¤šç»´åˆ†æ
7. å›¾7_ç»¼åˆåˆ†æä»ªè¡¨æ¿.png - ç»¼åˆåˆ†æä»ªè¡¨æ¿
8. å›¾8_ä¸­å›½äº§ä¸šé“¾æµå‡ºç»¼åˆåˆ†æ.png - ä¸­å›½äº§ä¸šé“¾æµå‡ºçš„å›½å®¶å’ŒåŒºåŸŸåˆ†æ
9. å›¾9_æµå…¥ä¸­å›½è¡Œä¸šå›½å®¶åˆ†æ.png - æµå…¥ä¸­å›½å‰10è¡Œä¸šçš„å›½å®¶æ¥æºåˆ†æ

æ–°å¢è¡Œä¸šå±‚é¢åœ°ç†è½¬ç§»çƒ­åŠ›å›¾ï¼š
- æ¯ä¸ªå‰5è¡Œä¸šçš„ç‹¬ç«‹åœ°ç†è½¬ç§»çƒ­åŠ›å›¾ï¼ˆè½¬å‘ä¸­å›½ & ä»ä¸­å›½è½¬å‡ºï¼‰
- å‰5è¡Œä¸šç»¼åˆå¯¹æ¯”åœ°ç†è½¬ç§»çƒ­åŠ›å›¾
- å±•ç¤ºå…·ä½“è¡Œä¸šåœ¨ä¸åŒå¹´ä»½ã€ä¸åŒå›½å®¶çš„è½¬ç§»æ¨¡å¼
- ä¾¿äºè¯†åˆ«ç‰¹å®šè¡Œä¸šçš„åœ°ç†è½¬ç§»é›†ä¸­åº¦å’Œè¶‹åŠ¿å˜åŒ–

åŒæ—¶ç”Ÿæˆå¯¹åº”çš„è‹±æ–‡ç‰ˆæœ¬å›¾è¡¨å’Œå¸¦ä¸­æ–‡æ³¨é‡Šçš„æ•°æ®è¡¨æ ¼ã€‚
æ‰€æœ‰æ–‡ä»¶å·²ä¿å­˜è‡³å­¦æœ¯æŠ¥å‘Šå›¾è¡¨ç›®å½•ã€‚
""")

# åœ¨ç°æœ‰ä»£ç åŸºç¡€ä¸Šæ·»åŠ ä»¥ä¸‹æ–°åŠŸèƒ½å‡½æ•°

def create_china_outflow_regional_analysis(academic_analysis, industry_mapping, country_name_mapping, output_path):
    """
    åˆ›å»ºä¸­å›½äº§ä¸šé“¾æµå‡ºçš„åŒºåŸŸåˆ†æå›¾è¡¨
    
    å‚æ•°å«ä¹‰ï¼š
    - academic_analysis: å­¦æœ¯åˆ†æç»“æœ
    - industry_mapping: è¡Œä¸šæ˜ å°„å­—å…¸  
    - country_name_mapping: å›½å®¶æ˜ å°„å­—å…¸
    - output_path: è¾“å‡ºè·¯å¾„
    
    å›¾è¡¨è¯´æ˜ï¼š
    - åˆ†æä»ä¸­å›½æµå‡ºçš„äº§ä¸šé“¾æŒ‰åŒºåŸŸå’Œå›½å®¶çš„åˆ†å¸ƒ
    - åŒ…å«å‰10ä¸ªæµå‡ºå›½å®¶çš„è¡Œä¸šå æ¯”åˆ†æ
    - æŒ‰åœ°ç†åŒºåŸŸåˆ’åˆ†çš„æ‰¿æ¥è¡Œä¸šåˆ†æ
    """
    
    setup_chinese_fonts()
    
    # å®šä¹‰åœ°ç†åŒºåŸŸæ˜ å°„
    regional_mapping = {
        # ä¸œå—äºš
        'TH': 'ä¸œå—äºš', 'VN': 'ä¸œå—äºš', 'MY': 'ä¸œå—äºš', 'SG': 'ä¸œå—äºš', 
        'ID': 'ä¸œå—äºš', 'PH': 'ä¸œå—äºš', 'LA': 'ä¸œå—äºš', 'KH': 'ä¸œå—äºš',
        'MM': 'ä¸œå—äºš', 'BN': 'ä¸œå—äºš',
        
        # åŒ—ç¾
        'US': 'åŒ—ç¾', 'CA': 'åŒ—ç¾', 'MX': 'åŒ—ç¾',
        
        # æ¬§æ´²
        'DE': 'æ¬§æ´²', 'GB': 'æ¬§æ´²', 'FR': 'æ¬§æ´²', 'IT': 'æ¬§æ´²', 'ES': 'æ¬§æ´²',
        'NL': 'æ¬§æ´²', 'BE': 'æ¬§æ´²', 'CH': 'æ¬§æ´²', 'AT': 'æ¬§æ´²', 'SE': 'æ¬§æ´²',
        'NO': 'æ¬§æ´²', 'DK': 'æ¬§æ´²', 'FI': 'æ¬§æ´²', 'IE': 'æ¬§æ´²', 'PT': 'æ¬§æ´²',
        'GR': 'æ¬§æ´²', 'PL': 'æ¬§æ´²', 'CZ': 'æ¬§æ´²', 'HU': 'æ¬§æ´²', 'RO': 'æ¬§æ´²',
        'BG': 'æ¬§æ´²', 'HR': 'æ¬§æ´²', 'SI': 'æ¬§æ´²', 'SK': 'æ¬§æ´²', 'EE': 'æ¬§æ´²',
        'LV': 'æ¬§æ´²', 'LT': 'æ¬§æ´²', 'CY': 'æ¬§æ´²', 'MT': 'æ¬§æ´²', 'LU': 'æ¬§æ´²',
        
        # å—äºš
        'IN': 'å—äºš', 'PK': 'å—äºš', 'BD': 'å—äºš', 'LK': 'å—äºš', 'NP': 'å—äºš',
        'BT': 'å—äºš', 'MV': 'å—äºš', 'AF': 'å—äºš',
        
        # ä¸œäºš
        'JP': 'ä¸œäºš', 'KR': 'ä¸œäºš', 'TW': 'ä¸œäºš', 'MN': 'ä¸œäºš',
        
        # ä¸­ä¸œ
        'SA': 'ä¸­ä¸œ', 'AE': 'ä¸­ä¸œ', 'QA': 'ä¸­ä¸œ', 'KW': 'ä¸­ä¸œ', 'BH': 'ä¸­ä¸œ',
        'OM': 'ä¸­ä¸œ', 'JO': 'ä¸­ä¸œ', 'LB': 'ä¸­ä¸œ', 'SY': 'ä¸­ä¸œ', 'IQ': 'ä¸­ä¸œ',
        'IR': 'ä¸­ä¸œ', 'IL': 'ä¸­ä¸œ', 'PS': 'ä¸­ä¸œ', 'YE': 'ä¸­ä¸œ',
        
        # å—ç¾
        'BR': 'å—ç¾', 'AR': 'å—ç¾', 'CL': 'å—ç¾', 'PE': 'å—ç¾', 'CO': 'å—ç¾',
        'VE': 'å—ç¾', 'EC': 'å—ç¾', 'BO': 'å—ç¾', 'PY': 'å—ç¾', 'UY': 'å—ç¾',
        'GY': 'å—ç¾', 'SR': 'å—ç¾', 'GF': 'å—ç¾',
        
        # éæ´²
        'ZA': 'éæ´²', 'EG': 'éæ´²', 'NG': 'éæ´²', 'KE': 'éæ´²', 'MA': 'éæ´²',
        'TN': 'éæ´²', 'DZ': 'éæ´²', 'LY': 'éæ´²', 'SD': 'éæ´²', 'ET': 'éæ´²',
        'GH': 'éæ´²', 'CM': 'éæ´²', 'UG': 'éæ´²', 'TZ': 'éæ´²', 'MZ': 'éæ´²',
        'MG': 'éæ´²', 'ZM': 'éæ´²', 'ZW': 'éæ´²', 'BW': 'éæ´²', 'NA': 'éæ´²',
        
        # å¤§æ´‹æ´²
        'AU': 'å¤§æ´‹æ´²', 'NZ': 'å¤§æ´‹æ´²', 'PG': 'å¤§æ´‹æ´²', 'FJ': 'å¤§æ´‹æ´²',
        
        # å…¶ä»–
        'RU': 'ä¿„ç½—æ–¯åŠä¸­äºš', 'KZ': 'ä¿„ç½—æ–¯åŠä¸­äºš', 'UZ': 'ä¿„ç½—æ–¯åŠä¸­äºš', 
        'KG': 'ä¿„ç½—æ–¯åŠä¸­äºš', 'TJ': 'ä¿„ç½—æ–¯åŠä¸­äºš', 'TM': 'ä¿„ç½—æ–¯åŠä¸­äºš'
    }
    
    # ä»å­¦æœ¯åˆ†æç»“æœä¸­æå–ä»ä¸­å›½è½¬å‡ºçš„æ•°æ®
    from_china_data = {}
    years = sorted(academic_analysis['summary_statistics']['yearly_totals'].keys())
    
    # é‡æ–°åˆ†æåŸå§‹æ•°æ®ä»¥è·å–è¯¦ç»†çš„å›½å®¶-è¡Œä¸šåˆ†å¸ƒ
    yearly_data = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))  # [year][country][industry] = count
    
    # è¿™é‡Œéœ€è¦é‡æ–°ä»åŸå§‹æ•°æ®ä¸­æå–ï¼Œå› ä¸ºå­¦æœ¯åˆ†æç»“æœä¸­çš„æ•°æ®ç»“æ„ä¸å¤Ÿè¯¦ç»†
    # æˆ‘ä»¬éœ€è¦ä» academic_analysis ä¸­çš„åŸå§‹æ•°æ®é‡æ–°è®¡ç®—
    
    # ä»ç°æœ‰çš„æ•°æ®ç»“æ„ä¸­æå–ä¿¡æ¯
    market_share_evolution = academic_analysis.get('market_share_evolution', {})
    
    # åˆ›å»ºå›¾è¡¨
    fig = plt.figure(figsize=(20, 16))
    gs = fig.add_gridspec(3, 3, hspace=0.4, wspace=0.3)
    
    # ç”±äºæ•°æ®ç»“æ„é™åˆ¶ï¼Œæˆ‘ä»¬å°†åŸºäºç°æœ‰æ•°æ®è¿›è¡Œåˆ†æ
    print("æ­£åœ¨ç”Ÿæˆä¸­å›½äº§ä¸šé“¾æµå‡ºåŒºåŸŸåˆ†æå›¾è¡¨...")
    
    plt.suptitle('ä¸­å›½äº§ä¸šé“¾æµå‡ºåŒºåŸŸåˆ†æ\nChina Industrial Chain Outflow Regional Analysis', 
                fontsize=20, fontweight='bold', y=0.98)
    
    plt.savefig(f'{output_path}/å›¾8_ä¸­å›½äº§ä¸šé“¾æµå‡ºåŒºåŸŸåˆ†æ.png', dpi=300, bbox_inches='tight')
    plt.close()

def analyze_detailed_china_outflow_by_country_and_region(supply_chains_contains_cn_node, company_to_country, industry_mapping, country_name_mapping):
    """
    è¯¦ç»†åˆ†æä¸­å›½äº§ä¸šé“¾æµå‡ºçš„å›½å®¶å’ŒåŒºåŸŸåˆ†å¸ƒ
    
    å‚æ•°å«ä¹‰ï¼š
    - supply_chains_contains_cn_node: åŒ…å«ä¸­å›½èŠ‚ç‚¹çš„ä¾›åº”é“¾æ•°æ®
    - company_to_country: å…¬å¸åˆ°å›½å®¶çš„æ˜ å°„
    - industry_mapping: è¡Œä¸šæ˜ å°„å­—å…¸
    - country_name_mapping: å›½å®¶æ˜ å°„å­—å…¸
    
    è¿”å›å€¼ï¼š
    - è¯¦ç»†çš„æµå‡ºåˆ†ææ•°æ®å­—å…¸
    
    åŠŸèƒ½è¯´æ˜ï¼š
    - åˆ†æä»ä¸­å›½æµå‡ºåˆ°å„å›½çš„äº§ä¸šé“¾åˆ†å¸ƒ
    - æŒ‰åŒºåŸŸç»Ÿè®¡æ‰¿æ¥çš„è¡Œä¸šç±»å‹å’Œå æ¯”
    - è®¡ç®—å‰10ä¸ªæµå‡ºå›½å®¶çš„è¡Œä¸šæ„æˆ
    """
    
    # å®šä¹‰ä¸­å›½åœ°åŒºä»£ç 
    china_codes = {'CN', 'HK', 'MO', 'China', 'Hong Kong', 'Macau'}
    
    # å®šä¹‰åœ°ç†åŒºåŸŸæ˜ å°„
    regional_mapping = {
        # ä¸œå—äºš
        'TH': 'ä¸œå—äºš', 'VN': 'ä¸œå—äºš', 'MY': 'ä¸œå—äºš', 'SG': 'ä¸œå—äºš', 
        'ID': 'ä¸œå—äºš', 'PH': 'ä¸œå—äºš', 'LA': 'ä¸œå—äºš', 'KH': 'ä¸œå—äºš',
        'MM': 'ä¸œå—äºš', 'BN': 'ä¸œå—äºš',
        
        # åŒ—ç¾
        'US': 'åŒ—ç¾', 'CA': 'åŒ—ç¾', 'MX': 'åŒ—ç¾',
        
        # æ¬§æ´²
        'DE': 'æ¬§æ´²', 'GB': 'æ¬§æ´²', 'FR': 'æ¬§æ´²', 'IT': 'æ¬§æ´²', 'ES': 'æ¬§æ´²',
        'NL': 'æ¬§æ´²', 'BE': 'æ¬§æ´²', 'CH': 'æ¬§æ´²', 'AT': 'æ¬§æ´²', 'SE': 'æ¬§æ´²',
        'NO': 'æ¬§æ´²', 'DK': 'æ¬§æ´²', 'FI': 'æ¬§æ´²', 'IE': 'æ¬§æ´²', 'PT': 'æ¬§æ´²',
        'GR': 'æ¬§æ´²', 'PL': 'æ¬§æ´²', 'CZ': 'æ¬§æ´²', 'HU': 'æ¬§æ´²', 'RO': 'æ¬§æ´²',
        'BG': 'æ¬§æ´²', 'HR': 'æ¬§æ´²', 'SI': 'æ¬§æ´²', 'SK': 'æ¬§æ´²', 'EE': 'æ¬§æ´²',
        'LV': 'æ¬§æ´²', 'LT': 'æ¬§æ´²', 'CY': 'æ¬§æ´²', 'MT': 'æ¬§æ´²', 'LU': 'æ¬§æ´²',
        
        # å—äºš
        'IN': 'å—äºš', 'PK': 'å—äºš', 'BD': 'å—äºš', 'LK': 'å—äºš', 'NP': 'å—äºš',
        'BT': 'å—äºš', 'MV': 'å—äºš', 'AF': 'å—äºš',
        
        # ä¸œäºš
        'JP': 'ä¸œäºš', 'KR': 'ä¸œäºš', 'TW': 'ä¸œäºš', 'MN': 'ä¸œäºš',
        
        # ä¸­ä¸œ
        'SA': 'ä¸­ä¸œ', 'AE': 'ä¸­ä¸œ', 'QA': 'ä¸­ä¸œ', 'KW': 'ä¸­ä¸œ', 'BH': 'ä¸­ä¸œ',
        'OM': 'ä¸­ä¸œ', 'JO': 'ä¸­ä¸œ', 'LB': 'ä¸­ä¸œ', 'SY': 'ä¸­ä¸œ', 'IQ': 'ä¸­ä¸œ',
        'IR': 'ä¸­ä¸œ', 'IL': 'ä¸­ä¸œ', 'PS': 'ä¸­ä¸œ', 'YE': 'ä¸­ä¸œ',
        
        # å—ç¾
        'BR': 'å—ç¾', 'AR': 'å—ç¾', 'CL': 'å—ç¾', 'PE': 'å—ç¾', 'CO': 'å—ç¾',
        'VE': 'å—ç¾', 'EC': 'å—ç¾', 'BO': 'å—ç¾', 'PY': 'å—ç¾', 'UY': 'å—ç¾',
        
        # éæ´²
        'ZA': 'éæ´²', 'EG': 'éæ´²', 'NG': 'éæ´²', 'KE': 'éæ´²', 'MA': 'éæ´²',
        'TN': 'éæ´²', 'DZ': 'éæ´²', 'GH': 'éæ´²', 'ET': 'éæ´²',
        
        # å¤§æ´‹æ´²
        'AU': 'å¤§æ´‹æ´²', 'NZ': 'å¤§æ´‹æ´²',
        
        # ä¿„ç½—æ–¯åŠä¸­äºš
        'RU': 'ä¿„ç½—æ–¯åŠä¸­äºš', 'KZ': 'ä¿„ç½—æ–¯åŠä¸­äºš', 'UZ': 'ä¿„ç½—æ–¯åŠä¸­äºš'
    }
    
    # å®šä¹‰æ— æ•ˆå›½å®¶ä»£ç é›†åˆ
    invalid_countries = {
        'Unknown_Empty', 'Unknown_None', 'Unknown', 'Nation_Not_Found', 
        '', None, 'null', 'NULL', 'N/A', 'na', 'NA'
    }
    
    # æ•°æ®æ”¶é›†ç»“æ„
    country_industry_data = defaultdict(lambda: defaultdict(int))  # [country][industry] = count
    regional_industry_data = defaultdict(lambda: defaultdict(int))  # [region][industry] = count
    
    total_outflow_count = 0
    
    print("å¼€å§‹åˆ†æä¸­å›½äº§ä¸šé“¾æµå‡ºçš„è¯¦ç»†åˆ†å¸ƒ...")
    
    # éå†ä¾›åº”é“¾æ•°æ®
    for chain in supply_chains_contains_cn_node:
        for rel in chain:
            if isinstance(rel, SupplyRelation) and rel.status == 'transfer':
                # è·å–ä¾›åº”æ–¹å’Œéœ€æ±‚æ–¹å›½å®¶
                from_countries = company_to_country.get(rel.from_co.id, (['Unknown'], ['Unknown']))[1]
                to_countries = company_to_country.get(rel.to_co.id, (['Unknown'], ['Unknown']))[1]
                
                # æ¸…ç†å›½å®¶ä»£ç 
                cleaned_from = [c.strip() for c in from_countries if c and str(c).strip() not in invalid_countries]
                cleaned_to = [c.strip() for c in to_countries if c and str(c).strip() not in invalid_countries]
                
                if not cleaned_from or not cleaned_to:
                    continue
                
                # åˆ¤æ–­æ˜¯å¦ä¸ºä»ä¸­å›½è½¬å‡º
                from_is_china = any(country in china_codes for country in cleaned_from)
                to_is_china = any(country in china_codes for country in cleaned_to)
                
                # åªåˆ†æä»ä¸­å›½è½¬å‡ºçš„æƒ…å†µ
                if from_is_china and not to_is_china:
                    if rel.industry_codes and rel.industry_codes != 'Line_Not_Found' and rel.industry_codes is not None:
                        for industry_code in rel.industry_codes:
                            for to_country in cleaned_to:
                                # ç»Ÿè®¡å›½å®¶å±‚é¢çš„è¡Œä¸šåˆ†å¸ƒ
                                country_industry_data[to_country][industry_code] += 1
                                total_outflow_count += 1
                                
                                # ç»Ÿè®¡åŒºåŸŸå±‚é¢çš„è¡Œä¸šåˆ†å¸ƒ
                                region = regional_mapping.get(to_country, 'å…¶ä»–')
                                regional_industry_data[region][industry_code] += 1
    
    # è®¡ç®—å‰10ä¸ªæµå‡ºå›½å®¶
    country_totals = {country: sum(industries.values()) for country, industries in country_industry_data.items()}
    top_10_countries = sorted(country_totals.items(), key=lambda x: x[1], reverse=True)[:10]
    
    # æ„å»ºåˆ†æç»“æœ
    analysis_result = {
        'country_analysis': {},
        'regional_analysis': {},
        'top_10_countries': top_10_countries,
        'total_outflow_count': total_outflow_count,
        'summary': {}
    }
    
    # åˆ†æå‰10ä¸ªå›½å®¶çš„è¡Œä¸šæ„æˆ
    for country, total_count in top_10_countries:
        country_name = country_name_mapping.get(country, country)
        region = regional_mapping.get(country, 'å…¶ä»–')
        
        industry_distribution = country_industry_data[country]
        sorted_industries = sorted(industry_distribution.items(), key=lambda x: x[1], reverse=True)
        
        analysis_result['country_analysis'][country] = {
            'country_name': country_name,
            'region': region,
            'total_count': total_count,
            'percentage_of_total_outflow': total_count / total_outflow_count * 100,
            'industry_distribution': dict(sorted_industries),
            'top_5_industries': sorted_industries[:5]
        }
    
    # åˆ†æåŒºåŸŸçš„è¡Œä¸šæ„æˆ
    regional_totals = {region: sum(industries.values()) for region, industries in regional_industry_data.items()}
    sorted_regions = sorted(regional_totals.items(), key=lambda x: x[1], reverse=True)
    
    for region, total_count in sorted_regions:
        industry_distribution = regional_industry_data[region]
        sorted_industries = sorted(industry_distribution.items(), key=lambda x: x[1], reverse=True)
        
        analysis_result['regional_analysis'][region] = {
            'total_count': total_count,
            'percentage_of_total_outflow': total_count / total_outflow_count * 100,
            'industry_distribution': dict(sorted_industries),
            'top_10_industries': sorted_industries[:10]
        }
    
    # ç”Ÿæˆæ‘˜è¦ç»Ÿè®¡
    analysis_result['summary'] = {
        'total_countries': len(country_industry_data),
        'total_regions': len(regional_industry_data),
        'total_industries': len(set().union(*[industries.keys() for industries in country_industry_data.values()])),
        'top_3_regions': sorted_regions[:3]
    }
    
    print(f"åˆ†æå®Œæˆï¼")
    print(f"  æ€»æµå‡ºè½¬ç§»æ•°: {total_outflow_count}")
    print(f"  æ¶‰åŠå›½å®¶æ•°: {len(country_industry_data)}")
    print(f"  æ¶‰åŠåŒºåŸŸæ•°: {len(regional_industry_data)}")
    print(f"  æ¶‰åŠè¡Œä¸šæ•°: {analysis_result['summary']['total_industries']}")
    
    return analysis_result

def analyze_detailed_china_inflow_by_industry(supply_chains_contains_cn_node, company_to_country, industry_mapping, country_name_mapping):
    """
    è¯¦ç»†åˆ†ææµå…¥ä¸­å›½çš„å‰10ä¸ªè¡Œä¸šçš„å›½å®¶å æ¯”
    
    å‚æ•°å«ä¹‰ï¼š
    - supply_chains_contains_cn_node: åŒ…å«ä¸­å›½èŠ‚ç‚¹çš„ä¾›åº”é“¾æ•°æ®
    - company_to_country: å…¬å¸åˆ°å›½å®¶çš„æ˜ å°„
    - industry_mapping: è¡Œä¸šæ˜ å°„å­—å…¸
    - country_name_mapping: å›½å®¶æ˜ å°„å­—å…¸
    
    è¿”å›å€¼ï¼š
    - è¯¦ç»†çš„æµå…¥åˆ†ææ•°æ®å­—å…¸
    
    åŠŸèƒ½è¯´æ˜ï¼š
    - åˆ†ææµå…¥ä¸­å›½çš„å‰10ä¸ªè¡Œä¸š
    - è®¡ç®—æ¯ä¸ªè¡Œä¸šçš„å›½å®¶æ¥æºåˆ†å¸ƒ
    - æä¾›å„è¡Œä¸šçš„å›½å®¶å æ¯”åˆ†æ
    """
    
    # å®šä¹‰ä¸­å›½åœ°åŒºä»£ç 
    china_codes = {'CN', 'HK', 'MO', 'China', 'Hong Kong', 'Macau'}
    
    # å®šä¹‰æ— æ•ˆå›½å®¶ä»£ç é›†åˆ
    invalid_countries = {
        'Unknown_Empty', 'Unknown_None', 'Unknown', 'Nation_Not_Found', 
        '', None, 'null', 'NULL', 'N/A', 'na', 'NA'
    }
    
    # æ•°æ®æ”¶é›†ç»“æ„
    industry_country_data = defaultdict(lambda: defaultdict(int))  # [industry][country] = count
    industry_totals = defaultdict(int)  # [industry] = total_count
    
    total_inflow_count = 0
    
    print("å¼€å§‹åˆ†ææµå…¥ä¸­å›½çš„è¡Œä¸šå›½å®¶åˆ†å¸ƒ...")
    
    # éå†ä¾›åº”é“¾æ•°æ®
    for chain in supply_chains_contains_cn_node:
        for rel in chain:
            if isinstance(rel, SupplyRelation) and rel.status == 'transfer':
                # è·å–ä¾›åº”æ–¹å’Œéœ€æ±‚æ–¹å›½å®¶
                from_countries = company_to_country.get(rel.from_co.id, (['Unknown'], ['Unknown']))[1]
                to_countries = company_to_country.get(rel.to_co.id, (['Unknown'], ['Unknown']))[1]
                
                # æ¸…ç†å›½å®¶ä»£ç 
                cleaned_from = [c.strip() for c in from_countries if c and str(c).strip() not in invalid_countries]
                cleaned_to = [c.strip() for c in to_countries if c and str(c).strip() not in invalid_countries]
                
                if not cleaned_from or not cleaned_to:
                    continue
                
                # åˆ¤æ–­æ˜¯å¦ä¸ºè½¬å‘ä¸­å›½
                from_is_china = any(country in china_codes for country in cleaned_from)
                to_is_china = any(country in china_codes for country in cleaned_to)
                
                # åªåˆ†æè½¬å‘ä¸­å›½çš„æƒ…å†µ
                if to_is_china and not from_is_china:
                    if rel.industry_codes and rel.industry_codes != 'Line_Not_Found' and rel.industry_codes is not None:
                        for industry_code in rel.industry_codes:
                            industry_totals[industry_code] += 1
                            total_inflow_count += 1
                            
                            for from_country in cleaned_from:
                                industry_country_data[industry_code][from_country] += 1
    
    # è·å–å‰10ä¸ªæµå…¥è¡Œä¸š
    top_10_industries = sorted(industry_totals.items(), key=lambda x: x[1], reverse=True)[:10]
    
    # æ„å»ºåˆ†æç»“æœ
    analysis_result = {
        'industry_analysis': {},
        'top_10_industries': top_10_industries,
        'total_inflow_count': total_inflow_count,
        'summary': {}
    }
    
    # åˆ†æå‰10ä¸ªè¡Œä¸šçš„å›½å®¶æ¥æºåˆ†å¸ƒ
    for industry_code, total_count in top_10_industries:
        industry_name = industry_mapping.get(str(industry_code), f"è¡Œä¸š{industry_code}")
        
        country_distribution = industry_country_data[industry_code]
        sorted_countries = sorted(country_distribution.items(), key=lambda x: x[1], reverse=True)
        
        # è®¡ç®—å›½å®¶å æ¯”
        country_percentages = []
        for country, count in sorted_countries:
            country_name = country_name_mapping.get(country, country)
            percentage = count / total_count * 100
            country_percentages.append((country, country_name, count, percentage))
        
        analysis_result['industry_analysis'][industry_code] = {
            'industry_name': industry_name,
            'total_count': total_count,
            'percentage_of_total_inflow': total_count / total_inflow_count * 100,
            'country_distribution': dict(sorted_countries),
            'country_percentages': country_percentages,
            'top_5_countries': country_percentages[:5],
            'country_count': len(country_distribution)
        }
    
    # ç”Ÿæˆæ‘˜è¦ç»Ÿè®¡
    analysis_result['summary'] = {
        'total_industries': len(industry_totals),
        'total_countries': len(set().union(*[countries.keys() for countries in industry_country_data.values()])),
        'average_countries_per_industry': sum(len(countries) for countries in industry_country_data.values()) / len(industry_country_data) if industry_country_data else 0
    }
    
    print(f"æµå…¥ä¸­å›½åˆ†æå®Œæˆï¼")
    print(f"  æ€»æµå…¥è½¬ç§»æ•°: {total_inflow_count}")
    print(f"  æ¶‰åŠè¡Œä¸šæ•°: {len(industry_totals)}")
    print(f"  å‰10è¡Œä¸šè½¬ç§»æ•°: {sum(count for _, count in top_10_industries)}")
    
    return analysis_result

def create_china_outflow_comprehensive_charts(outflow_analysis, industry_mapping, country_name_mapping, output_path):
    """
    åˆ›å»ºä¸­å›½äº§ä¸šé“¾æµå‡ºçš„ç»¼åˆå›¾è¡¨
    
    å‚æ•°å«ä¹‰ï¼š
    - outflow_analysis: æµå‡ºåˆ†æç»“æœ
    - industry_mapping: è¡Œä¸šæ˜ å°„å­—å…¸
    - country_name_mapping: å›½å®¶æ˜ å°„å­—å…¸
    - output_path: è¾“å‡ºè·¯å¾„
    
    å›¾è¡¨è¯´æ˜ï¼š
    - å‰10ä¸ªæµå‡ºå›½å®¶çš„è¡Œä¸šå æ¯”é¥¼å›¾
    - åŒºåŸŸæ‰¿æ¥è¡Œä¸šåˆ†å¸ƒæŸ±çŠ¶å›¾
    - é‡ç‚¹å›½å®¶è¡Œä¸šæ„æˆå †å å›¾
    """
    
    setup_chinese_fonts()
    
    # åˆ›å»ºå¤§å›¾è¡¨
    fig = plt.figure(figsize=(20, 16))
    gs = fig.add_gridspec(3, 3, hspace=0.4, wspace=0.3)
    
    # 1. å‰10ä¸ªæµå‡ºå›½å®¶æ€»é‡å¯¹æ¯” (å·¦ä¸Š)
    ax1 = fig.add_subplot(gs[0, :2])
    countries = []
    counts = []
    for country, count in outflow_analysis['top_10_countries']:
        country_name = country_name_mapping.get(country, country)
        countries.append(f"{country_name}\n({country})")
        counts.append(count)
    
    bars = ax1.bar(range(len(countries)), counts, color=plt.cm.tab10(np.linspace(0, 1, len(countries))))
    ax1.set_title('ä¸­å›½äº§ä¸šé“¾æµå‡ºå‰10ä¸ªå›½å®¶\n(Top 10 Countries for China\'s Industrial Chain Outflow)', 
                 fontsize=14, fontweight='bold')
    ax1.set_ylabel('æµå‡ºè½¬ç§»æ•°é‡ (Outflow Transfer Count)', fontsize=12)
    ax1.set_xticks(range(len(countries)))
    ax1.set_xticklabels(countries, rotation=45, ha='right', fontsize=10)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, (bar, count) in enumerate(zip(bars, counts)):
        height = bar.get_height()
        percentage = count / outflow_analysis['total_outflow_count'] * 100
        ax1.annotate(f'{count}\n({percentage:.1f}%)', 
                    xy=(bar.get_x() + bar.get_width()/2, height),
                    xytext=(0, 3), textcoords="offset points", 
                    ha='center', va='bottom', fontsize=9)
    
    # 2. åŒºåŸŸåˆ†å¸ƒé¥¼å›¾ (å³ä¸Š)
    ax2 = fig.add_subplot(gs[0, 2])
    regional_data = outflow_analysis['regional_analysis']
    regions = list(regional_data.keys())
    region_counts = [regional_data[region]['total_count'] for region in regions]
    
    # åªæ˜¾ç¤ºå‰6ä¸ªåŒºåŸŸï¼Œå…¶ä»–åˆå¹¶ä¸º"å…¶ä»–"
    if len(regions) > 6:
        top_regions = regions[:6]
        top_counts = region_counts[:6]
        other_count = sum(region_counts[6:])
        top_regions.append('å…¶ä»–')
        top_counts.append(other_count)
    else:
        top_regions = regions
        top_counts = region_counts
    
    wedges, texts, autotexts = ax2.pie(top_counts, labels=top_regions, autopct='%1.1f%%', 
                                      startangle=90, textprops={'fontsize': 10})
    ax2.set_title('åŒºåŸŸæ‰¿æ¥åˆ†å¸ƒ\n(Regional Distribution)', fontsize=12, fontweight='bold')
    
    # 3. å‰5ä¸ªå›½å®¶çš„è¡Œä¸šæ„æˆå¯¹æ¯” (ä¸­é—´è¡Œï¼Œè·¨ä¸¤åˆ—)
    ax3 = fig.add_subplot(gs[1, :2])
    
    # é€‰æ‹©å‰5ä¸ªå›½å®¶è¿›è¡Œè¯¦ç»†åˆ†æ
    top_5_countries = outflow_analysis['top_10_countries'][:5]
    
    # è·å–è¿™äº›å›½å®¶æ¶‰åŠçš„æ‰€æœ‰è¡Œä¸š
    all_industries = set()
    for country, _ in top_5_countries:
        country_data = outflow_analysis['country_analysis'][country]
        all_industries.update(country_data['industry_distribution'].keys())
    
    # é€‰æ‹©å‰10ä¸ªæœ€é‡è¦çš„è¡Œä¸š
    industry_totals = defaultdict(int)
    for country, _ in top_5_countries:
        country_data = outflow_analysis['country_analysis'][country]
        for industry, count in country_data['industry_distribution'].items():
            industry_totals[industry] += count
    
    top_industries = sorted(industry_totals.items(), key=lambda x: x[1], reverse=True)[:10]
    
    # åˆ›å»ºå †å æŸ±çŠ¶å›¾æ•°æ®
    country_names = []
    industry_data = {industry: [] for industry, _ in top_industries}
    
    for country, _ in top_5_countries:
        country_name = country_name_mapping.get(country, country)
        country_names.append(country_name)
        country_data = outflow_analysis['country_analysis'][country]
        
        for industry, _ in top_industries:
            count = country_data['industry_distribution'].get(industry, 0)
            industry_data[industry].append(count)
    
    # ç»˜åˆ¶å †å æŸ±çŠ¶å›¾
    bottom = np.zeros(len(country_names))
    colors = plt.cm.tab10(np.linspace(0, 1, len(top_industries)))
    
    for i, (industry, _) in enumerate(top_industries):
        industry_name = industry_mapping.get(str(industry), f"è¡Œä¸š{industry}")
        bars = ax3.bar(country_names, industry_data[industry], bottom=bottom, 
                      label=f"{industry}: {industry_name[:10]}...", color=colors[i])
        bottom += industry_data[industry]
    
    ax3.set_title('å‰5ä¸ªå›½å®¶çš„è¡Œä¸šæ„æˆå¯¹æ¯”\n(Industry Composition of Top 5 Countries)', 
                 fontsize=14, fontweight='bold')
    ax3.set_ylabel('è½¬ç§»æ•°é‡ (Transfer Count)', fontsize=12)
    ax3.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)
    
    # 4. åŒºåŸŸè¡Œä¸šé›†ä¸­åº¦åˆ†æ (å³ä¸­)
    ax4 = fig.add_subplot(gs[1, 2])
    
    # è®¡ç®—å„åŒºåŸŸçš„è¡Œä¸šé›†ä¸­åº¦ï¼ˆHHIæŒ‡æ•°ï¼‰
    region_hhi = {}
    for region, data in regional_data.items():
        industry_dist = data['industry_distribution']
        total = sum(industry_dist.values())
        if total > 0:
            shares = [count / total for count in industry_dist.values()]
            hhi = sum(share**2 for share in shares)
            region_hhi[region] = hhi
    
    regions_hhi = list(region_hhi.keys())
    hhi_values = list(region_hhi.values())
    
    bars = ax4.barh(regions_hhi, hhi_values, color='lightcoral')
    ax4.set_title('å„åŒºåŸŸè¡Œä¸šé›†ä¸­åº¦\n(Regional Industry Concentration)', fontsize=12, fontweight='bold')
    ax4.set_xlabel('HHIæŒ‡æ•° (HHI Index)', fontsize=10)
    
    # æ·»åŠ HHIè§£é‡Š
    ax4.text(0.02, 0.98, 'HHI > 0.25: é«˜åº¦é›†ä¸­\n0.15-0.25: é€‚åº¦é›†ä¸­\n< 0.15: ç«äº‰å……åˆ†', 
             transform=ax4.transAxes, fontsize=8, verticalalignment='top',
             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
    
    # 5. é‡ç‚¹åŒºåŸŸçš„å‰5è¡Œä¸šåˆ†å¸ƒ (åº•éƒ¨è¡Œ)
    regional_analysis = outflow_analysis['regional_analysis']
    top_3_regions = [region for region, _ in outflow_analysis['summary']['top_3_regions']]
    
    for i, region in enumerate(top_3_regions):
        ax = fig.add_subplot(gs[2, i])
        
        region_data = regional_analysis[region]
        top_5_industries = region_data['top_10_industries'][:5]
        
        industries = []
        counts = []
        for industry, count in top_5_industries:
            industry_name = industry_mapping.get(str(industry), f"è¡Œä¸š{industry}")
            industries.append(f"{industry}\n{industry_name[:8]}")
            counts.append(count)
        
        bars = ax.bar(range(len(industries)), counts, color=plt.cm.Set3(np.linspace(0, 1, len(industries))))
        ax.set_title(f'{region}åŒºåŸŸ\nå‰5æ‰¿æ¥è¡Œä¸š', fontsize=12, fontweight='bold')
        ax.set_ylabel('è½¬ç§»æ•°é‡', fontsize=10)
        ax.set_xticks(range(len(industries)))
        ax.set_xticklabels(industries, rotation=45, ha='right', fontsize=8)
        
        # æ·»åŠ ç™¾åˆ†æ¯”æ ‡ç­¾
        total_region = region_data['total_count']
        for bar, count in zip(bars, counts):
            height = bar.get_height()
            percentage = count / total_region * 100
            ax.annotate(f'{percentage:.1f}%', 
                       xy=(bar.get_x() + bar.get_width()/2, height),
                       xytext=(0, 3), textcoords="offset points", 
                       ha='center', va='bottom', fontsize=8)
    
    plt.suptitle('ä¸­å›½äº§ä¸šé“¾æµå‡ºåˆ†æç»¼åˆæŠ¥å‘Š\nComprehensive Analysis of China\'s Industrial Chain Outflow', 
                fontsize=18, fontweight='bold', y=0.98)
    
    plt.tight_layout()
    plt.savefig(f'{output_path}/å›¾8_ä¸­å›½äº§ä¸šé“¾æµå‡ºç»¼åˆåˆ†æ.png', dpi=300, bbox_inches='tight')
    plt.savefig(f'{output_path}/Fig8_China_Outflow_Comprehensive_Analysis.png', dpi=300, bbox_inches='tight')
    plt.close()

def create_china_inflow_industry_charts(inflow_analysis, industry_mapping, country_name_mapping, output_path):
    """
    åˆ›å»ºæµå…¥ä¸­å›½çš„å‰10ä¸ªè¡Œä¸šå›½å®¶å æ¯”åˆ†æå›¾è¡¨
    
    å‚æ•°å«ä¹‰ï¼š
    - inflow_analysis: æµå…¥åˆ†æç»“æœ
    - industry_mapping: è¡Œä¸šæ˜ å°„å­—å…¸
    - country_name_mapping: å›½å®¶æ˜ å°„å­—å…¸
    - output_path: è¾“å‡ºè·¯å¾„
    
    å›¾è¡¨è¯´æ˜ï¼š
    - å‰10ä¸ªæµå…¥è¡Œä¸šçš„æ€»é‡å¯¹æ¯”
    - æ¯ä¸ªé‡ç‚¹è¡Œä¸šçš„å›½å®¶æ¥æºåˆ†å¸ƒ
    - è¡Œä¸šå›½å®¶å¤šæ ·æ€§åˆ†æ
    """
    
    setup_chinese_fonts()
    
    # åˆ›å»ºå¤§å›¾è¡¨
    fig = plt.figure(figsize=(20, 20))
    gs = fig.add_gridspec(4, 3, hspace=0.4, wspace=0.3)
    
    # 1. å‰10ä¸ªæµå…¥è¡Œä¸šæ€»é‡å¯¹æ¯” (é¡¶éƒ¨ï¼Œè·¨ä¸‰åˆ—)
    ax1 = fig.add_subplot(gs[0, :])
    
    industries = []
    counts = []
    percentages = []
    
    for industry_code, count in inflow_analysis['top_10_industries']:
        # ä¿®æ”¹è¿™é‡Œï¼šä½¿ç”¨ç®€åŒ–çš„è¡Œä¸šåç§°
        short_name = get_simplified_industry_name(industry_code, industry_mapping)
        industries.append(f"{industry_code}\n{short_name}")
        counts.append(count)
        percentage = count / inflow_analysis['total_inflow_count'] * 100
        percentages.append(percentage)
    
    bars = ax1.bar(range(len(industries)), counts, color=plt.cm.tab10(np.linspace(0, 1, len(industries))))
    ax1.set_title('æµå…¥ä¸­å›½çš„å‰10ä¸ªè¡Œä¸šåˆ†æ\n(Top 10 Industries Flowing into China)', 
                 fontsize=16, fontweight='bold')
    ax1.set_ylabel('æµå…¥è½¬ç§»æ•°é‡ (Inflow Transfer Count)', fontsize=12)
    ax1.set_xticks(range(len(industries)))
    ax1.set_xticklabels(industries, rotation=45, ha='right', fontsize=10)
    
    # æ·»åŠ æ•°å€¼å’Œç™¾åˆ†æ¯”æ ‡ç­¾
    for i, (bar, count, pct) in enumerate(zip(bars, counts, percentages)):
        height = bar.get_height()
        ax1.annotate(f'{count}\n({pct:.1f}%)', 
                    xy=(bar.get_x() + bar.get_width()/2, height),
                    xytext=(0, 3), textcoords="offset points", 
                    ha='center', va='bottom', fontsize=9)
    
    # 2-7. å‰6ä¸ªè¡Œä¸šçš„å›½å®¶æ¥æºåˆ†å¸ƒé¥¼å›¾
    top_6_industries = inflow_analysis['top_10_industries'][:6]
    
    for idx, (industry_code, total_count) in enumerate(top_6_industries):
        row = (idx // 3) + 1
        col = idx % 3
        ax = fig.add_subplot(gs[row, col])
        
        industry_data = inflow_analysis['industry_analysis'][industry_code]
        industry_name = industry_data['industry_name']
        
        # è·å–å‰5ä¸ªå›½å®¶ï¼Œå…¶ä»–åˆå¹¶ä¸º"å…¶ä»–"
        top_5_countries = industry_data['top_5_countries']
        
        countries = []
        counts_pie = []
        
        for country, country_name, count, percentage in top_5_countries:
            countries.append(f"{country_name}\n({percentage:.1f}%)")
            counts_pie.append(count)
        
        # è®¡ç®—å…¶ä»–å›½å®¶çš„æ•°é‡
        top_5_total = sum(counts_pie)
        other_count = total_count - top_5_total
        if other_count > 0:
            countries.append(f"å…¶ä»–\n({other_count/total_count*100:.1f}%)")
            counts_pie.append(other_count)
        
        # åˆ›å»ºé¥¼å›¾
        wedges, texts, autotexts = ax.pie(counts_pie, labels=countries, autopct='',
                                         startangle=90, textprops={'fontsize': 8})
        
        ax.set_title(f'è¡Œä¸š {industry_code}: {industry_name[:20]}\nå›½å®¶æ¥æºåˆ†å¸ƒ (æ€»è®¡: {total_count})', 
                    fontsize=11, fontweight='bold')
    
    # 8. è¡Œä¸šå›½å®¶å¤šæ ·æ€§åˆ†æ (å³ä¸‹)
    ax8 = fig.add_subplot(gs[3, :])
    
    # è®¡ç®—æ¯ä¸ªè¡Œä¸šçš„å›½å®¶å¤šæ ·æ€§æŒ‡æ ‡
    industries_diversity = []
    country_counts = []
    hhi_values = []
    industry_names = []
    
    for industry_code, _ in inflow_analysis['top_10_industries']:
        industry_data = inflow_analysis['industry_analysis'][industry_code]
        industry_name = industry_mapping.get(str(industry_code), f"è¡Œä¸š{industry_code}")
        
        # å›½å®¶æ•°é‡
        country_count = industry_data['country_count']
        
        # è®¡ç®—HHIæŒ‡æ•°
        country_dist = industry_data['country_distribution']
        total = sum(country_dist.values())
        shares = [count / total for count in country_dist.values()]
        hhi = sum(share**2 for share in shares)
        
        industries_diversity.append(f"{industry_code}")
        industry_names.append(industry_name[:10])
        country_counts.append(country_count)
        hhi_values.append(hhi)
    
    # åˆ›å»ºåŒè½´å›¾
    ax8_twin = ax8.twinx()
    
    x_pos = range(len(industries_diversity))
    bars1 = ax8.bar([x - 0.2 for x in x_pos], country_counts, width=0.4, 
                   label='æ¶‰åŠå›½å®¶æ•°', color='lightblue', alpha=0.7)
    
    line = ax8_twin.plot(x_pos, hhi_values, 'ro-', linewidth=2, markersize=6,
                        label='é›†ä¸­åº¦æŒ‡æ•°(HHI)', color='red')
    
    ax8.set_title('å„è¡Œä¸šçš„å›½å®¶æ¥æºå¤šæ ·æ€§åˆ†æ\n(Country Source Diversity Analysis by Industry)', 
                 fontsize=14, fontweight='bold')
    ax8.set_xlabel('è¡Œä¸šä»£ç  (Industry Code)', fontsize=12)
    ax8.set_ylabel('æ¶‰åŠå›½å®¶æ•°é‡ (Number of Countries)', fontsize=12)
    ax8_twin.set_ylabel('é›†ä¸­åº¦æŒ‡æ•° HHI (Concentration Index)', fontsize=12)
    
    ax8.set_xticks(x_pos)
    ax8.set_xticklabels([f"{code}\n{name}" for code, name in zip(industries_diversity, industry_names)], 
                       rotation=45, ha='right', fontsize=9)
    
    # åˆå¹¶å›¾ä¾‹
    lines1, labels1 = ax8.get_legend_handles_labels()
    lines2, labels2 = ax8_twin.get_legend_handles_labels()
    ax8.legend(lines1 + lines2, labels1 + labels2, loc='upper left', fontsize=10)
    
    ax8.grid(True, alpha=0.3)
    
    plt.suptitle('æµå…¥ä¸­å›½äº§ä¸šé“¾çš„è¡Œä¸šå›½å®¶åˆ†å¸ƒåˆ†æ\nCountry Distribution Analysis of Industries Flowing into China', 
                fontsize=18, fontweight='bold', y=0.98)
    
    plt.tight_layout()
    plt.savefig(f'{output_path}/å›¾9_æµå…¥ä¸­å›½è¡Œä¸šå›½å®¶åˆ†æ.png', dpi=300, bbox_inches='tight')
    plt.savefig(f'{output_path}/Fig9_China_Inflow_Industry_Country_Analysis.png', dpi=300, bbox_inches='tight')
    plt.close()

# æ‰§è¡Œæ–°çš„åˆ†æå’Œå¯è§†åŒ–
print("\n" + "="*80)
print("=== å¼€å§‹ç”Ÿæˆä¸­å›½äº§ä¸šé“¾æµå‡ºæµå…¥ä¸“é¡¹åˆ†æ ===")
print("="*80)

# 1. åˆ†æä¸­å›½äº§ä¸šé“¾æµå‡ºçš„è¯¦ç»†åˆ†å¸ƒ
outflow_analysis = analyze_detailed_china_outflow_by_country_and_region(
    supply_chains_contains_cn_node, 
    company_to_country, 
    industry_mapping, 
    country_name_mapping
)

# 2. åˆ†ææµå…¥ä¸­å›½çš„å‰10ä¸ªè¡Œä¸šçš„å›½å®¶åˆ†å¸ƒ
inflow_analysis = analyze_detailed_china_inflow_by_industry(
    supply_chains_contains_cn_node, 
    company_to_country, 
    industry_mapping, 
    country_name_mapping
)

# 3. ç”Ÿæˆä¸­å›½äº§ä¸šé“¾æµå‡ºç»¼åˆå›¾è¡¨
create_china_outflow_comprehensive_charts(
    outflow_analysis, 
    industry_mapping, 
    country_name_mapping, 
    ".\è°ƒç”¨æ–‡ä»¶\ç”¨äºè¡Œä¸šåˆ†ç±»åˆ†æçš„å¯è§†åŒ–è¡¨\å­¦æœ¯æŠ¥å‘Šå›¾è¡¨"
)

# 4. ç”Ÿæˆæµå…¥ä¸­å›½è¡Œä¸šå›½å®¶åˆ†æå›¾è¡¨
create_china_inflow_industry_charts(
    inflow_analysis, 
    industry_mapping, 
    country_name_mapping, 
    ".\è°ƒç”¨æ–‡ä»¶\ç”¨äºè¡Œä¸šåˆ†ç±»åˆ†æçš„å¯è§†åŒ–è¡¨\å­¦æœ¯æŠ¥å‘Šå›¾è¡¨"
)

# 5. è¾“å‡ºè¯¦ç»†çš„æ–‡å­—åˆ†ææŠ¥å‘Š
print("\n" + "="*60)
print("=== ä¸­å›½äº§ä¸šé“¾æµå‡ºåˆ†ææŠ¥å‘Š ===")
print("="*60)

print(f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
print(f"   æ€»æµå‡ºè½¬ç§»æ•°: {outflow_analysis['total_outflow_count']}")
print(f"   æ¶‰åŠå›½å®¶æ•°: {outflow_analysis['summary']['total_countries']}")
print(f"   æ¶‰åŠåŒºåŸŸæ•°: {outflow_analysis['summary']['total_regions']}")
print(f"   æ¶‰åŠè¡Œä¸šæ•°: {outflow_analysis['summary']['total_industries']}")

print(f"\nğŸ† å‰10ä¸ªæ‰¿æ¥å›½å®¶:")
for i, (country, count) in enumerate(outflow_analysis['top_10_countries'], 1):
    country_data = outflow_analysis['country_analysis'][country]
    country_name = country_data['country_name']
    region = country_data['region']
    percentage = country_data['percentage_of_total_outflow']
    print(f"   {i:2d}. {country_name} ({country}) - {region}")
    print(f"       æµå‡ºæ•°é‡: {count} ({percentage:.2f}%)")
    
    # æ˜¾ç¤ºè¯¥å›½æ‰¿æ¥çš„å‰3ä¸ªè¡Œä¸š
    top_3_industries = country_data['top_5_industries'][:3]
    print(f"       ä¸»è¦æ‰¿æ¥è¡Œä¸š: ", end="")
    for j, (industry, ind_count) in enumerate(top_3_industries):
        industry_name = industry_mapping.get(str(industry), f"è¡Œä¸š{industry}")
        if j > 0:
            print(", ", end="")
        print(f"{industry}({industry_name[:10]}, {ind_count}æ¬¡)", end="")
    print()

print(f"\nğŸŒ åŒºåŸŸæ‰¿æ¥åˆ†æ:")
for region, data in outflow_analysis['regional_analysis'].items():
    print(f"   {region}: {data['total_count']}æ¬¡ ({data['percentage_of_total_outflow']:.2f}%)")
    
    # æ˜¾ç¤ºè¯¥åŒºåŸŸæ‰¿æ¥çš„å‰3ä¸ªè¡Œä¸š
    top_3_industries = data['top_10_industries'][:3]
    print(f"      ä¸»è¦æ‰¿æ¥è¡Œä¸š: ", end="")
    for j, (industry, count) in enumerate(top_3_industries):
        industry_name = industry_mapping.get(str(industry), f"è¡Œä¸š{industry}")
        if j > 0:
            print(", ", end="")
        print(f"{industry}({industry_name[:10]}, {count}æ¬¡)", end="")
    print()

print("\n" + "="*60)
print("=== æµå…¥ä¸­å›½äº§ä¸šé“¾åˆ†ææŠ¥å‘Š ===")
print("="*60)

print(f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
print(f"   æ€»æµå…¥è½¬ç§»æ•°: {inflow_analysis['total_inflow_count']}")
print(f"   æ¶‰åŠè¡Œä¸šæ•°: {inflow_analysis['summary']['total_industries']}")
print(f"   æ¶‰åŠå›½å®¶æ•°: {inflow_analysis['summary']['total_countries']}")
print(f"   å¹³å‡æ¯è¡Œä¸šæ¶‰åŠå›½å®¶æ•°: {inflow_analysis['summary']['average_countries_per_industry']:.1f}")

print(f"\nğŸ† å‰10ä¸ªæµå…¥è¡Œä¸š:")
for i, (industry_code, count) in enumerate(inflow_analysis['top_10_industries'], 1):
    industry_data = inflow_analysis['industry_analysis'][industry_code]
    industry_name = industry_data['industry_name']
    percentage = industry_data['percentage_of_total_inflow']
    country_count = industry_data['country_count']
    
    print(f"   {i:2d}. è¡Œä¸š{industry_code}: {industry_name}")
    print(f"       æµå…¥æ•°é‡: {count} ({percentage:.2f}%)")
    print(f"       æ¥æºå›½å®¶æ•°: {country_count}")
    
    # æ˜¾ç¤ºè¯¥è¡Œä¸šçš„å‰3ä¸ªæ¥æºå›½
    top_3_countries = industry_data['top_5_countries'][:3]
    print(f"       ä¸»è¦æ¥æºå›½: ", end="")
    for j, (country, country_name, c_count, c_percentage) in enumerate(top_3_countries):
        if j > 0:
            print(", ", end="")
        print(f"{country_name}({c_count}æ¬¡, {c_percentage:.1f}%)", end="")
    print()

print("\n" + "="*80)
print("=== ä¸­å›½äº§ä¸šé“¾æµå‡ºæµå…¥ä¸“é¡¹åˆ†æå®Œæˆ ===")
print("="*80)
print("""
æ–°å¢å›¾è¡¨æ–‡ä»¶ï¼š
8. å›¾8_ä¸­å›½äº§ä¸šé“¾æµå‡ºç»¼åˆåˆ†æ.png - ä¸­å›½äº§ä¸šé“¾æµå‡ºçš„å›½å®¶å’ŒåŒºåŸŸåˆ†æ
9. å›¾9_æµå…¥ä¸­å›½è¡Œä¸šå›½å®¶åˆ†æ.png - æµå…¥ä¸­å›½å‰10è¡Œä¸šçš„å›½å®¶æ¥æºåˆ†æ

åˆ†æå†…å®¹åŒ…æ‹¬ï¼š
- ä¸­å›½äº§ä¸šé“¾æµå‡ºå‰10ä¸ªå›½å®¶çš„è¡Œä¸šæ„æˆ
- æŒ‰åŒºåŸŸåˆ’åˆ†çš„äº§ä¸šæ‰¿æ¥åˆ†æï¼ˆä¸œå—äºšã€åŒ—ç¾ã€æ¬§æ´²ç­‰ï¼‰
- å„åŒºåŸŸæ‰¿æ¥çš„ä¸»è¦è¡Œä¸šç±»å‹å’Œå æ¯”
- æµå…¥ä¸­å›½å‰10ä¸ªè¡Œä¸šçš„å›½å®¶æ¥æºåˆ†å¸ƒ
- å„è¡Œä¸šæ¥æºå›½å®¶çš„å¤šæ ·æ€§åˆ†æ
""")